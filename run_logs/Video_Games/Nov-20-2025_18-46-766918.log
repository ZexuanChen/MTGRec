Thu 20 Nov 2025 18:46:21 INFO  Device: cuda
Thu 20 Nov 2025 18:46:21 INFO  Config: {'rand_seed': 2024, 'reproducibility': True, 'num_proc': 1, 'data_dir': 'datasets/Video_Games', 'log_dir': 'run_logs/', 'tensorboard_log_dir': 'tensorboard/', 'ckpt_dir': 'ckpt/Video_Games/Nov-20-2025_18-46-8bf284', 'stage': 'pretrain', 'pretrained_model': '', 'epoch_per_stage': [60, 20, 20, 20, 20, 20, 20], 'tau': 5.0, 'load_best_for_next_stage': False, 'train_batch_size': 256, 'eval_batch_size': 256, 'lr': 0.005, 'weight_decay': 0.05, 'warmup_steps': 10000, 'steps': None, 'epochs': 200, 'max_grad_norm': 1.0, 'eval_interval': 1, 'save_interval': 10, 'patience': 50, 'topk': [5, 10], 'metrics': ['ndcg', 'recall'], 'val_metric': 'ndcg@10', 'val_ratio': 1.0, 'val_delay': 199, 'n_codebooks': 3, 'codebook_size': 256, 'expand_final': True, 'token_prefix': 'rqvae/sentence-t5-base_256,256,256,256', 'token_suffix': 'sem_ids', 'n_user_tokens': 1, 'max_item_seq_len': 20, 'num_beams': 20, 'test_num_beams': None, 'num_layers': 7, 'num_decoder_layers': 7, 'd_model': 128, 'd_ff': 512, 'num_heads': 4, 'd_kv': 64, 'dropout_rate': 0.1, 'activation_function': 'relu', 'feed_forward_proj': 'relu', 'results_dir': None, 'sem_id_epochs': [9976, 9977, 9978, 9979, 9980, 9981, 9982, 9983, 9984, 9985, 9986, 9987, 9988, 9989, 9990, 9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 'run_local_time': 'Nov-20-2025_18-46', 'ckpt_name': 'Nov-20-2025_18-46-8bf284', 'dataset': 'Video_Games', 'device': device(type='cuda'), 'use_ddp': False, 'accelerator': <accelerate.accelerator.Accelerator object at 0x7957817ab9a0>}
Thu 20 Nov 2025 18:46:21 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9976.sem_ids...
Thu 20 Nov 2025 18:46:21 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9977.sem_ids...
Thu 20 Nov 2025 18:46:21 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9978.sem_ids...
Thu 20 Nov 2025 18:46:21 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9979.sem_ids...
Thu 20 Nov 2025 18:46:22 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9980.sem_ids...
Thu 20 Nov 2025 18:46:22 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9981.sem_ids...
Thu 20 Nov 2025 18:46:22 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9982.sem_ids...
Thu 20 Nov 2025 18:46:22 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9983.sem_ids...
Thu 20 Nov 2025 18:46:22 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9984.sem_ids...
Thu 20 Nov 2025 18:46:22 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9985.sem_ids...
Thu 20 Nov 2025 18:46:22 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9986.sem_ids...
Thu 20 Nov 2025 18:46:22 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9987.sem_ids...
Thu 20 Nov 2025 18:46:23 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9988.sem_ids...
Thu 20 Nov 2025 18:46:23 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9989.sem_ids...
Thu 20 Nov 2025 18:46:23 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9990.sem_ids...
Thu 20 Nov 2025 18:46:23 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9991.sem_ids...
Thu 20 Nov 2025 18:46:23 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9992.sem_ids...
Thu 20 Nov 2025 18:46:23 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9993.sem_ids...
Thu 20 Nov 2025 18:46:23 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9994.sem_ids...
Thu 20 Nov 2025 18:46:24 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9995.sem_ids...
Thu 20 Nov 2025 18:46:24 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9996.sem_ids...
Thu 20 Nov 2025 18:46:24 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9997.sem_ids...
Thu 20 Nov 2025 18:46:24 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9998.sem_ids...
Thu 20 Nov 2025 18:46:24 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_9999.sem_ids...
Thu 20 Nov 2025 18:46:24 INFO  [TOKENIZER] Loading semantic IDs from datasets/Video_Games/rqvae/sentence-t5-base_256,256,256,256_10000.sem_ids...
Thu 20 Nov 2025 18:46:29 INFO  MTGRec(
  (t5): T5ForConditionalGeneration(
    (shared): Embedding(1027, 128)
    (encoder): T5Stack(
      (embed_tokens): Embedding(1027, 128)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
                (relative_attention_bias): Embedding(32, 4)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-6): 6 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (decoder): T5Stack(
      (embed_tokens): Embedding(1027, 128)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
                (relative_attention_bias): Embedding(32, 4)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerCrossAttention(
              (EncDecAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-6): 6 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerCrossAttention(
              (EncDecAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (lm_head): Linear(in_features=128, out_features=1027, bias=False)
  )
)
Thu 20 Nov 2025 18:46:29 INFO  #Embedding parameters: 131456
#Non-embedding parameters: 4592512
#Total trainable parameters: 4723968

Thu 20 Nov 2025 18:48:53 INFO  [Epoch 1] Train Loss: 3.342456340444594
Thu 20 Nov 2025 18:51:21 INFO  [Epoch 2] Train Loss: 2.4881276167267536
Thu 20 Nov 2025 18:53:47 INFO  [Epoch 3] Train Loss: 2.3086121628873597
Thu 20 Nov 2025 18:56:11 INFO  [Epoch 4] Train Loss: 2.2243443770068034
Thu 20 Nov 2025 18:58:38 INFO  [Epoch 5] Train Loss: 2.1840662622543836
Thu 20 Nov 2025 19:01:05 INFO  [Epoch 6] Train Loss: 2.154827000781836
Thu 20 Nov 2025 19:03:30 INFO  [Epoch 7] Train Loss: 2.1297973002015853
Thu 20 Nov 2025 19:05:56 INFO  [Epoch 8] Train Loss: 2.103929345154394
Thu 20 Nov 2025 19:08:23 INFO  [Epoch 9] Train Loss: 2.086932207914393
Thu 20 Nov 2025 19:10:47 INFO  [Epoch 10] Train Loss: 2.074748675680529
Thu 20 Nov 2025 19:10:47 INFO  [Epoch 10] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_10.pth
Thu 20 Nov 2025 19:13:14 INFO  [Epoch 11] Train Loss: 2.063753857288121
Thu 20 Nov 2025 19:15:40 INFO  [Epoch 12] Train Loss: 2.054828517743059
Thu 20 Nov 2025 19:18:05 INFO  [Epoch 13] Train Loss: 2.04848450606394
Thu 20 Nov 2025 19:20:30 INFO  [Epoch 14] Train Loss: 2.0404498421202297
Thu 20 Nov 2025 19:22:57 INFO  [Epoch 15] Train Loss: 2.0332544820534215
Thu 20 Nov 2025 19:25:22 INFO  [Epoch 16] Train Loss: 2.028941106784758
Thu 20 Nov 2025 19:27:49 INFO  [Epoch 17] Train Loss: 2.0271425483654824
Thu 20 Nov 2025 19:30:15 INFO  [Epoch 18] Train Loss: 2.0230475668166137
Thu 20 Nov 2025 19:32:40 INFO  [Epoch 19] Train Loss: 2.0174853557210173
Thu 20 Nov 2025 19:35:06 INFO  [Epoch 20] Train Loss: 2.0143065600436625
Thu 20 Nov 2025 19:35:06 INFO  [Epoch 20] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_20.pth
Thu 20 Nov 2025 19:37:34 INFO  [Epoch 21] Train Loss: 2.012282103760362
Thu 20 Nov 2025 19:39:58 INFO  [Epoch 22] Train Loss: 2.009753776102913
Thu 20 Nov 2025 19:42:24 INFO  [Epoch 23] Train Loss: 2.007814961050468
Thu 20 Nov 2025 19:44:51 INFO  [Epoch 24] Train Loss: 2.006492736774522
Thu 20 Nov 2025 19:47:16 INFO  [Epoch 25] Train Loss: 2.0031613045332515
Thu 20 Nov 2025 19:49:41 INFO  [Epoch 26] Train Loss: 2.001728555007791
Thu 20 Nov 2025 19:52:08 INFO  [Epoch 27] Train Loss: 1.9995953957891832
Thu 20 Nov 2025 19:54:34 INFO  [Epoch 28] Train Loss: 1.9979833319035276
Thu 20 Nov 2025 19:57:01 INFO  [Epoch 29] Train Loss: 1.9980975982075033
Thu 20 Nov 2025 19:59:28 INFO  [Epoch 30] Train Loss: 1.9956639720896496
Thu 20 Nov 2025 19:59:28 INFO  [Epoch 30] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_30.pth
Thu 20 Nov 2025 20:01:54 INFO  [Epoch 31] Train Loss: 1.994385339406006
Thu 20 Nov 2025 20:04:19 INFO  [Epoch 32] Train Loss: 1.9933984391247443
Thu 20 Nov 2025 20:06:45 INFO  [Epoch 33] Train Loss: 1.992086317893621
Thu 20 Nov 2025 20:09:11 INFO  [Epoch 34] Train Loss: 1.9901772515999305
Thu 20 Nov 2025 20:11:35 INFO  [Epoch 35] Train Loss: 1.9894997876813514
Thu 20 Nov 2025 20:14:02 INFO  [Epoch 36] Train Loss: 1.988452147850659
Thu 20 Nov 2025 20:16:28 INFO  [Epoch 37] Train Loss: 1.9858654538406828
Thu 20 Nov 2025 20:18:52 INFO  [Epoch 38] Train Loss: 1.9846794448188834
Thu 20 Nov 2025 20:21:20 INFO  [Epoch 39] Train Loss: 1.9853360349147016
Thu 20 Nov 2025 20:23:45 INFO  [Epoch 40] Train Loss: 1.9819720499073676
Thu 20 Nov 2025 20:23:46 INFO  [Epoch 40] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_40.pth
Thu 20 Nov 2025 20:26:11 INFO  [Epoch 41] Train Loss: 1.9829497463339545
Thu 20 Nov 2025 20:28:37 INFO  [Epoch 42] Train Loss: 1.98044049745591
Thu 20 Nov 2025 20:31:03 INFO  [Epoch 43] Train Loss: 1.9794900096866614
Thu 20 Nov 2025 20:33:29 INFO  [Epoch 44] Train Loss: 1.9776848328504784
Thu 20 Nov 2025 20:35:57 INFO  [Epoch 45] Train Loss: 1.9774995646996847
Thu 20 Nov 2025 20:38:22 INFO  [Epoch 46] Train Loss: 1.9745546744481937
Thu 20 Nov 2025 20:40:48 INFO  [Epoch 47] Train Loss: 1.97478266071859
Thu 20 Nov 2025 20:43:15 INFO  [Epoch 48] Train Loss: 1.9730371431839513
Thu 20 Nov 2025 20:45:39 INFO  [Epoch 49] Train Loss: 1.9715626355418827
Thu 20 Nov 2025 20:48:06 INFO  [Epoch 50] Train Loss: 1.9706591343557514
Thu 20 Nov 2025 20:48:06 INFO  [Epoch 50] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_50.pth
Thu 20 Nov 2025 20:50:32 INFO  [Epoch 51] Train Loss: 1.9691665831334804
Thu 20 Nov 2025 20:52:57 INFO  [Epoch 52] Train Loss: 1.968296141122759
Thu 20 Nov 2025 20:55:24 INFO  [Epoch 53] Train Loss: 1.9679987164768014
Thu 20 Nov 2025 20:57:54 INFO  [Epoch 54] Train Loss: 1.968722794909735
Thu 20 Nov 2025 21:00:18 INFO  [Epoch 55] Train Loss: 1.9643128545357913
Thu 20 Nov 2025 21:02:42 INFO  [Epoch 56] Train Loss: 1.9637864855150458
Thu 20 Nov 2025 21:05:06 INFO  [Epoch 57] Train Loss: 1.9615799937123957
Thu 20 Nov 2025 21:07:32 INFO  [Epoch 58] Train Loss: 1.9612804245074282
Thu 20 Nov 2025 21:09:56 INFO  [Epoch 59] Train Loss: 1.9595733870640686
Thu 20 Nov 2025 21:12:20 INFO  [Epoch 60] Train Loss: 1.9584490144229765
Thu 20 Nov 2025 21:12:21 INFO  [Epoch 60] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_60.pth
Thu 20 Nov 2025 21:12:21 INFO  Best epoch: 0, Best val score: -1
Thu 20 Nov 2025 21:12:21 INFO  [Epoch 61] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284.pth
Thu 20 Nov 2025 21:12:21 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Thu 20 Nov 2025 22:25:13 INFO  Influence scores: tensor([[0.4431, 0.4224, 0.3983, 0.4282, 0.3812, 0.3795, 0.4131, 0.3723, 0.4021,
         0.4075, 0.3642, 0.3900, 0.3919, 0.3689, 0.4001, 0.3897, 0.3955, 0.3943,
         0.3765, 0.3602, 0.3714, 0.3813, 0.3620, 0.3924, 0.3693],
        [0.3972, 0.4683, 0.4117, 0.4052, 0.3816, 0.3855, 0.4122, 0.3803, 0.3923,
         0.3989, 0.3607, 0.3836, 0.3908, 0.3644, 0.4112, 0.3920, 0.3997, 0.3888,
         0.3720, 0.3653, 0.3779, 0.3789, 0.3684, 0.3936, 0.3724],
        [0.3954, 0.4335, 0.4274, 0.4026, 0.3866, 0.3822, 0.4173, 0.3813, 0.4034,
         0.4099, 0.3692, 0.3903, 0.3987, 0.3744, 0.4138, 0.4016, 0.4070, 0.3989,
         0.3804, 0.3716, 0.3830, 0.3863, 0.3697, 0.3961, 0.3730],
        [0.4095, 0.4119, 0.3869, 0.4410, 0.3854, 0.3781, 0.4189, 0.3774, 0.4037,
         0.4029, 0.3660, 0.3939, 0.3962, 0.3706, 0.4064, 0.3919, 0.3981, 0.3960,
         0.3820, 0.3603, 0.3710, 0.3803, 0.3625, 0.3922, 0.3686],
        [0.3760, 0.4031, 0.3852, 0.3988, 0.3967, 0.3797, 0.4169, 0.3768, 0.4031,
         0.4046, 0.3647, 0.3937, 0.3961, 0.3738, 0.4107, 0.3934, 0.3995, 0.3928,
         0.3786, 0.3610, 0.3712, 0.3775, 0.3588, 0.3840, 0.3605],
        [0.3724, 0.4039, 0.3783, 0.3904, 0.3770, 0.3941, 0.4141, 0.3722, 0.3959,
         0.4047, 0.3623, 0.3885, 0.3929, 0.3696, 0.4047, 0.3880, 0.3948, 0.3852,
         0.3693, 0.3548, 0.3659, 0.3719, 0.3570, 0.3829, 0.3587],
        [0.3656, 0.3902, 0.3729, 0.3895, 0.3741, 0.3732, 0.4300, 0.3673, 0.3997,
         0.4036, 0.3590, 0.3923, 0.3971, 0.3692, 0.4051, 0.3897, 0.3959, 0.3891,
         0.3751, 0.3532, 0.3650, 0.3737, 0.3516, 0.3818, 0.3562],
        [0.3627, 0.3967, 0.3756, 0.3864, 0.3726, 0.3700, 0.4054, 0.4180, 0.4025,
         0.4053, 0.3746, 0.3863, 0.4014, 0.3795, 0.4233, 0.4002, 0.4090, 0.4046,
         0.3806, 0.3749, 0.3840, 0.3872, 0.3789, 0.4037, 0.3773],
        [0.3597, 0.3752, 0.3641, 0.3802, 0.3661, 0.3626, 0.4063, 0.3709, 0.4281,
         0.4164, 0.3660, 0.3941, 0.4019, 0.3825, 0.4114, 0.3973, 0.4045, 0.4024,
         0.3800, 0.3631, 0.3739, 0.3827, 0.3605, 0.3859, 0.3604],
        [0.3680, 0.3849, 0.3737, 0.3834, 0.3705, 0.3736, 0.4137, 0.3756, 0.4182,
         0.4480, 0.3794, 0.4046, 0.4157, 0.3968, 0.4214, 0.4088, 0.4185, 0.4123,
         0.3894, 0.3735, 0.3876, 0.3962, 0.3749, 0.4009, 0.3747],
        [0.3543, 0.3769, 0.3634, 0.3749, 0.3600, 0.3610, 0.3984, 0.3750, 0.3980,
         0.4098, 0.3939, 0.3981, 0.4065, 0.3840, 0.4121, 0.4069, 0.4111, 0.4034,
         0.3890, 0.3734, 0.3812, 0.3874, 0.3757, 0.4023, 0.3753],
        [0.3457, 0.3654, 0.3499, 0.3686, 0.3548, 0.3517, 0.3968, 0.3529, 0.3927,
         0.3996, 0.3636, 0.4270, 0.3987, 0.3808, 0.4105, 0.4022, 0.4064, 0.4010,
         0.3871, 0.3661, 0.3765, 0.3911, 0.3642, 0.3936, 0.3700],
        [0.3450, 0.3695, 0.3553, 0.3687, 0.3541, 0.3530, 0.3985, 0.3651, 0.3962,
         0.4084, 0.3684, 0.3957, 0.4280, 0.3888, 0.4245, 0.4106, 0.4228, 0.4121,
         0.3927, 0.3774, 0.3907, 0.3979, 0.3766, 0.4057, 0.3767],
        [0.3458, 0.3670, 0.3548, 0.3669, 0.3552, 0.3532, 0.3945, 0.3664, 0.4017,
         0.4132, 0.3698, 0.4022, 0.4127, 0.4123, 0.4331, 0.4140, 0.4270, 0.4211,
         0.3946, 0.3844, 0.3980, 0.4064, 0.3841, 0.4093, 0.3833],
        [0.3307, 0.3668, 0.3468, 0.3554, 0.3454, 0.3417, 0.3829, 0.3632, 0.3829,
         0.3906, 0.3507, 0.3840, 0.4005, 0.3857, 0.4532, 0.4047, 0.4240, 0.4144,
         0.3874, 0.3837, 0.4023, 0.4036, 0.3863, 0.4098, 0.3858],
        [0.3439, 0.3726, 0.3604, 0.3659, 0.3536, 0.3512, 0.3937, 0.3653, 0.3952,
         0.4041, 0.3718, 0.4019, 0.4130, 0.3928, 0.4317, 0.4396, 0.4373, 0.4289,
         0.4068, 0.3981, 0.4073, 0.4142, 0.3934, 0.4204, 0.3918],
        [0.3335, 0.3630, 0.3487, 0.3552, 0.3424, 0.3405, 0.3824, 0.3572, 0.3849,
         0.3969, 0.3586, 0.3886, 0.4076, 0.3885, 0.4336, 0.4199, 0.4475, 0.4290,
         0.4019, 0.3962, 0.4130, 0.4178, 0.3977, 0.4234, 0.3959],
        [0.3302, 0.3507, 0.3395, 0.3519, 0.3355, 0.3306, 0.3757, 0.3522, 0.3815,
         0.3897, 0.3503, 0.3830, 0.3966, 0.3814, 0.4225, 0.4107, 0.4280, 0.4433,
         0.4028, 0.3927, 0.4047, 0.4187, 0.3908, 0.4216, 0.3923],
        [0.3336, 0.3549, 0.3416, 0.3590, 0.3411, 0.3344, 0.3811, 0.3494, 0.3790,
         0.3868, 0.3560, 0.3887, 0.3975, 0.3753, 0.4160, 0.4093, 0.4216, 0.4227,
         0.4369, 0.3955, 0.4059, 0.4183, 0.3962, 0.4290, 0.4009],
        [0.3331, 0.3642, 0.3492, 0.3537, 0.3402, 0.3367, 0.3762, 0.3586, 0.3796,
         0.3885, 0.3576, 0.3853, 0.3985, 0.3823, 0.4289, 0.4176, 0.4327, 0.4302,
         0.4128, 0.4278, 0.4316, 0.4322, 0.4181, 0.4404, 0.4141],
        [0.3245, 0.3558, 0.3397, 0.3444, 0.3301, 0.3276, 0.3675, 0.3472, 0.3705,
         0.3814, 0.3448, 0.3752, 0.3901, 0.3740, 0.4256, 0.4051, 0.4279, 0.4210,
         0.4023, 0.4107, 0.4494, 0.4388, 0.4282, 0.4469, 0.4263],
        [0.3170, 0.3412, 0.3270, 0.3365, 0.3195, 0.3162, 0.3597, 0.3345, 0.3622,
         0.3729, 0.3340, 0.3726, 0.3813, 0.3657, 0.4110, 0.3962, 0.4161, 0.4177,
         0.3972, 0.3944, 0.4231, 0.4563, 0.4164, 0.4491, 0.4265],
        [0.3228, 0.3548, 0.3348, 0.3434, 0.3245, 0.3248, 0.3609, 0.3504, 0.3629,
         0.3762, 0.3457, 0.3700, 0.3836, 0.3683, 0.4177, 0.3988, 0.4195, 0.4145,
         0.4000, 0.4045, 0.4362, 0.4408, 0.4478, 0.4609, 0.4391],
        [0.3241, 0.3504, 0.3318, 0.3435, 0.3202, 0.3211, 0.3618, 0.3443, 0.3593,
         0.3725, 0.3429, 0.3696, 0.3822, 0.3625, 0.4105, 0.3968, 0.4159, 0.4149,
         0.4023, 0.3972, 0.4266, 0.4443, 0.4310, 0.4820, 0.4497],
        [0.3105, 0.3400, 0.3194, 0.3300, 0.3079, 0.3081, 0.3468, 0.3296, 0.3445,
         0.3561, 0.3264, 0.3567, 0.3657, 0.3482, 0.3984, 0.3793, 0.3995, 0.3971,
         0.3852, 0.3819, 0.4149, 0.4323, 0.4198, 0.4594, 0.4522]],
       device='cuda:0')
Thu 20 Nov 2025 22:25:13 INFO  Mean influence score: [0.3902077376842499, 0.3901129961013794, 0.39414718747138977, 0.3900820016860962, 0.3862856924533844, 0.381977915763855, 0.38079962134361267, 0.39041945338249207, 0.3838520348072052, 0.3945714831352234, 0.3868861794471741, 0.3806661069393158, 0.3872935473918915, 0.3908325135707855, 0.38329795002937317, 0.39420509338378906, 0.3889581263065338, 0.38307154178619385, 0.3852359354496002, 0.3916082978248596, 0.3862025737762451, 0.3777691423892975, 0.38411185145378113, 0.3822946846485138, 0.3683992028236389]
Thu 20 Nov 2025 22:25:13 INFO  Stage 0 selected prob: [0.04003259539604187, 0.040031835436820984, 0.04006415233016014, 0.040031589567661285, 0.04000120982527733, 0.03996675834059715, 0.03995734080672264, 0.04003429040312767, 0.039981741458177567, 0.04006754979491234, 0.040006011724472046, 0.03995627537369728, 0.0400092676281929, 0.040037598460912704, 0.039977312088012695, 0.04006461426615715, 0.0400225929915905, 0.03997550159692764, 0.039992813020944595, 0.04004381224513054, 0.040000542998313904, 0.03993312641978264, 0.03998381644487381, 0.03996929153800011, 0.039858363568782806]
Thu 20 Nov 2025 22:27:54 INFO  [Epoch 61] Train Loss: 1.9578078658999623
Thu 20 Nov 2025 22:30:36 INFO  [Epoch 62] Train Loss: 1.9549554089321592
Thu 20 Nov 2025 22:33:21 INFO  [Epoch 63] Train Loss: 1.955044995921459
Thu 20 Nov 2025 22:36:10 INFO  [Epoch 64] Train Loss: 1.9542422812417668
Thu 20 Nov 2025 22:38:55 INFO  [Epoch 65] Train Loss: 1.9516183630955266
Thu 20 Nov 2025 22:41:43 INFO  [Epoch 66] Train Loss: 1.9499542603276412
Thu 20 Nov 2025 22:44:32 INFO  [Epoch 67] Train Loss: 1.9497796764820239
Thu 20 Nov 2025 22:47:16 INFO  [Epoch 68] Train Loss: 1.9471533156384833
Thu 20 Nov 2025 22:50:03 INFO  [Epoch 69] Train Loss: 1.9456001872836852
Thu 20 Nov 2025 22:52:51 INFO  [Epoch 70] Train Loss: 1.9455758756652302
Thu 20 Nov 2025 22:52:52 INFO  [Epoch 70] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_70.pth
Thu 20 Nov 2025 22:55:39 INFO  [Epoch 71] Train Loss: 1.944044554383138
Thu 20 Nov 2025 22:58:23 INFO  [Epoch 72] Train Loss: 1.9418317672713843
Thu 20 Nov 2025 23:01:06 INFO  [Epoch 73] Train Loss: 1.941520287205814
Thu 20 Nov 2025 23:03:41 INFO  [Epoch 74] Train Loss: 1.9385526986310841
Thu 20 Nov 2025 23:06:30 INFO  [Epoch 75] Train Loss: 1.9382785391278248
Thu 20 Nov 2025 23:09:15 INFO  [Epoch 76] Train Loss: 1.936306541893473
Thu 20 Nov 2025 23:11:59 INFO  [Epoch 77] Train Loss: 1.9346168865108122
Thu 20 Nov 2025 23:14:24 INFO  [Epoch 78] Train Loss: 1.9335569119131244
Thu 20 Nov 2025 23:16:46 INFO  [Epoch 79] Train Loss: 1.9309094842796621
Thu 20 Nov 2025 23:19:09 INFO  [Epoch 80] Train Loss: 1.9296149551638304
Thu 20 Nov 2025 23:19:09 INFO  [Epoch 80] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_80.pth
Thu 20 Nov 2025 23:19:09 INFO  Best epoch: 0, Best val score: -1
Thu 20 Nov 2025 23:19:09 INFO  [Epoch 81] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284.pth
Thu 20 Nov 2025 23:19:09 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Fri 21 Nov 2025 00:29:43 INFO  Influence scores: tensor([[0.3659, 0.3051, 0.3212, 0.3118, 0.2774, 0.2858, 0.2868, 0.2527, 0.2736,
         0.2896, 0.2956, 0.2970, 0.2498, 0.2215, 0.1842, 0.2572, 0.2170, 0.2096,
         0.2243, 0.2213, 0.1945, 0.2236, 0.2190, 0.2304, 0.2118],
        [0.3125, 0.3524, 0.3339, 0.2850, 0.2776, 0.2885, 0.2850, 0.2582, 0.2615,
         0.2786, 0.2925, 0.2897, 0.2476, 0.2155, 0.1922, 0.2572, 0.2180, 0.2000,
         0.2181, 0.2239, 0.1974, 0.2168, 0.2214, 0.2273, 0.2117],
        [0.3052, 0.3092, 0.3459, 0.2768, 0.2763, 0.2803, 0.2841, 0.2540, 0.2680,
         0.2845, 0.2957, 0.2898, 0.2484, 0.2191, 0.1875, 0.2609, 0.2196, 0.2034,
         0.2204, 0.2244, 0.1967, 0.2179, 0.2168, 0.2230, 0.2054],
        [0.3129, 0.2783, 0.2943, 0.3102, 0.2664, 0.2685, 0.2784, 0.2451, 0.2618,
         0.2703, 0.2844, 0.2853, 0.2401, 0.2094, 0.1775, 0.2463, 0.2061, 0.1989,
         0.2166, 0.2085, 0.1816, 0.2089, 0.2055, 0.2163, 0.1978],
        [0.2730, 0.2650, 0.2883, 0.2602, 0.2751, 0.2660, 0.2721, 0.2399, 0.2568,
         0.2678, 0.2802, 0.2813, 0.2357, 0.2080, 0.1760, 0.2434, 0.2026, 0.1892,
         0.2082, 0.2041, 0.1756, 0.2005, 0.1958, 0.2024, 0.1848],
        [0.2788, 0.2753, 0.2908, 0.2604, 0.2649, 0.2932, 0.2786, 0.2447, 0.2599,
         0.2780, 0.2882, 0.2861, 0.2428, 0.2138, 0.1814, 0.2487, 0.2085, 0.1919,
         0.2080, 0.2082, 0.1808, 0.2053, 0.2046, 0.2113, 0.1932],
        [0.2638, 0.2556, 0.2787, 0.2540, 0.2547, 0.2623, 0.2908, 0.2335, 0.2575,
         0.2703, 0.2781, 0.2836, 0.2415, 0.2065, 0.1752, 0.2436, 0.2030, 0.1898,
         0.2085, 0.2001, 0.1740, 0.2016, 0.1926, 0.2041, 0.1845],
        [0.2391, 0.2388, 0.2583, 0.2304, 0.2318, 0.2378, 0.2432, 0.2641, 0.2400,
         0.2503, 0.2722, 0.2547, 0.2260, 0.1962, 0.1717, 0.2306, 0.1953, 0.1816,
         0.1922, 0.1971, 0.1685, 0.1896, 0.1967, 0.2009, 0.1808],
        [0.2511, 0.2304, 0.2613, 0.2369, 0.2377, 0.2421, 0.2567, 0.2295, 0.2808,
         0.2772, 0.2775, 0.2780, 0.2385, 0.2149, 0.1740, 0.2440, 0.2056, 0.1967,
         0.2057, 0.2024, 0.1756, 0.2034, 0.1947, 0.2008, 0.1815],
        [0.2588, 0.2406, 0.2703, 0.2387, 0.2424, 0.2532, 0.2632, 0.2339, 0.2703,
         0.3100, 0.2917, 0.2886, 0.2515, 0.2281, 0.1842, 0.2551, 0.2195, 0.2065,
         0.2155, 0.2130, 0.1888, 0.2158, 0.2091, 0.2151, 0.1956],
        [0.2420, 0.2321, 0.2586, 0.2292, 0.2323, 0.2409, 0.2475, 0.2321, 0.2476,
         0.2690, 0.3079, 0.2827, 0.2418, 0.2145, 0.1726, 0.2532, 0.2113, 0.1956,
         0.2155, 0.2135, 0.1820, 0.2061, 0.2105, 0.2166, 0.1966],
        [0.2462, 0.2317, 0.2571, 0.2338, 0.2373, 0.2429, 0.2569, 0.2193, 0.2533,
         0.2702, 0.2867, 0.3230, 0.2448, 0.2230, 0.1822, 0.2605, 0.2176, 0.2059,
         0.2254, 0.2179, 0.1887, 0.2224, 0.2088, 0.2196, 0.2024],
        [0.2353, 0.2257, 0.2513, 0.2244, 0.2261, 0.2341, 0.2494, 0.2243, 0.2484,
         0.2685, 0.2803, 0.2795, 0.2677, 0.2218, 0.1895, 0.2586, 0.2253, 0.2083,
         0.2206, 0.2188, 0.1939, 0.2188, 0.2113, 0.2207, 0.1994],
        [0.2351, 0.2231, 0.2512, 0.2220, 0.2271, 0.2338, 0.2443, 0.2239, 0.2539,
         0.2745, 0.2820, 0.2871, 0.2503, 0.2449, 0.1968, 0.2616, 0.2299, 0.2155,
         0.2221, 0.2251, 0.2004, 0.2259, 0.2183, 0.2232, 0.2048],
        [0.2295, 0.2294, 0.2490, 0.2204, 0.2253, 0.2316, 0.2431, 0.2290, 0.2432,
         0.2584, 0.2694, 0.2761, 0.2489, 0.2263, 0.2294, 0.2585, 0.2344, 0.2163,
         0.2224, 0.2301, 0.2104, 0.2296, 0.2263, 0.2299, 0.2124],
        [0.2354, 0.2274, 0.2548, 0.2228, 0.2259, 0.2327, 0.2440, 0.2219, 0.2451,
         0.2636, 0.2839, 0.2869, 0.2504, 0.2249, 0.1924, 0.2885, 0.2382, 0.2238,
         0.2355, 0.2396, 0.2099, 0.2349, 0.2290, 0.2368, 0.2148],
        [0.2249, 0.2190, 0.2445, 0.2138, 0.2165, 0.2232, 0.2352, 0.2175, 0.2388,
         0.2590, 0.2730, 0.2759, 0.2487, 0.2238, 0.2007, 0.2700, 0.2537, 0.2291,
         0.2341, 0.2410, 0.2195, 0.2415, 0.2363, 0.2419, 0.2213],
        [0.2191, 0.2026, 0.2309, 0.2076, 0.2048, 0.2093, 0.2242, 0.2063, 0.2316,
         0.2484, 0.2598, 0.2658, 0.2332, 0.2121, 0.1844, 0.2570, 0.2301, 0.2394,
         0.2321, 0.2316, 0.2061, 0.2381, 0.2244, 0.2362, 0.2126],
        [0.2207, 0.2070, 0.2339, 0.2118, 0.2095, 0.2113, 0.2280, 0.2021, 0.2257,
         0.2435, 0.2650, 0.2706, 0.2309, 0.2040, 0.1751, 0.2552, 0.2219, 0.2190,
         0.2675, 0.2368, 0.2079, 0.2385, 0.2318, 0.2451, 0.2225],
        [0.2361, 0.2314, 0.2558, 0.2228, 0.2247, 0.2299, 0.2385, 0.2272, 0.2423,
         0.2598, 0.2815, 0.2823, 0.2489, 0.2263, 0.2031, 0.2775, 0.2480, 0.2368,
         0.2551, 0.2821, 0.2472, 0.2649, 0.2665, 0.2684, 0.2477],
        [0.2331, 0.2292, 0.2520, 0.2197, 0.2206, 0.2263, 0.2363, 0.2224, 0.2390,
         0.2592, 0.2743, 0.2785, 0.2473, 0.2248, 0.2064, 0.2713, 0.2498, 0.2348,
         0.2507, 0.2708, 0.2716, 0.2779, 0.2823, 0.2817, 0.2654],
        [0.2307, 0.2172, 0.2424, 0.2158, 0.2130, 0.2184, 0.2313, 0.2117, 0.2347,
         0.2547, 0.2663, 0.2799, 0.2402, 0.2193, 0.1949, 0.2650, 0.2399, 0.2357,
         0.2493, 0.2569, 0.2468, 0.2990, 0.2736, 0.2875, 0.2706],
        [0.2293, 0.2262, 0.2437, 0.2158, 0.2121, 0.2211, 0.2254, 0.2214, 0.2286,
         0.2506, 0.2733, 0.2692, 0.2362, 0.2147, 0.1940, 0.2617, 0.2372, 0.2243,
         0.2451, 0.2616, 0.2541, 0.2760, 0.2989, 0.2920, 0.2770],
        [0.2359, 0.2269, 0.2454, 0.2215, 0.2133, 0.2231, 0.2323, 0.2203, 0.2294,
         0.2521, 0.2744, 0.2746, 0.2409, 0.2146, 0.1914, 0.2646, 0.2382, 0.2314,
         0.2541, 0.2590, 0.2494, 0.2855, 0.2876, 0.3221, 0.2946],
        [0.2322, 0.2261, 0.2427, 0.2182, 0.2108, 0.2196, 0.2275, 0.2156, 0.2253,
         0.2466, 0.2683, 0.2727, 0.2352, 0.2103, 0.1906, 0.2575, 0.2321, 0.2232,
         0.2466, 0.2534, 0.2474, 0.2831, 0.2866, 0.3084, 0.3087]],
       device='cuda:0')
Fri 21 Nov 2025 00:29:43 INFO  Mean influence score: [0.32983601093292236, 0.3286253809928894, 0.3299305737018585, 0.3232893943786621, 0.31727054715156555, 0.31755200028419495, 0.3134719729423523, 0.3129270672798157, 0.3131283223628998, 0.32374781370162964, 0.315779447555542, 0.3146633505821228, 0.31691572070121765, 0.32020843029022217, 0.31613096594810486, 0.32361355423927307, 0.3196532130241394, 0.3118072748184204, 0.31366994976997375, 0.3265743851661682, 0.3239949643611908, 0.3170223534107208, 0.32039111852645874, 0.3210873603820801, 0.3117835819721222]
Fri 21 Nov 2025 00:29:43 INFO  Stage 1 selected prob: [0.040084172040224075, 0.040074463933706284, 0.04008492827415466, 0.04003171622753143, 0.039983559399843216, 0.03998580947518349, 0.03995319455862045, 0.03994883969426155, 0.039950449019670486, 0.04003538936376572, 0.03997163474559784, 0.03996271640062332, 0.03998072072863579, 0.040007058531045914, 0.03997444733977318, 0.04003431648015976, 0.04000261798501015, 0.039939895272254944, 0.039954774081707, 0.04005802795290947, 0.0400373712182045, 0.039981573820114136, 0.04000852257013321, 0.04001409187912941, 0.03993970900774002]
Fri 21 Nov 2025 00:32:06 INFO  [Epoch 81] Train Loss: 1.9283396648854363
Fri 21 Nov 2025 00:34:31 INFO  [Epoch 82] Train Loss: 1.9280166810658907
Fri 21 Nov 2025 00:36:55 INFO  [Epoch 83] Train Loss: 1.9243071622945167
Fri 21 Nov 2025 00:39:19 INFO  [Epoch 84] Train Loss: 1.9240431366164712
Fri 21 Nov 2025 00:41:41 INFO  [Epoch 85] Train Loss: 1.9223852586792243
Fri 21 Nov 2025 00:44:08 INFO  [Epoch 86] Train Loss: 1.9207445998679717
Fri 21 Nov 2025 00:46:32 INFO  [Epoch 87] Train Loss: 1.9183971655184697
Fri 21 Nov 2025 00:48:53 INFO  [Epoch 88] Train Loss: 1.9173531775654054
Fri 21 Nov 2025 00:51:17 INFO  [Epoch 89] Train Loss: 1.9160718622700128
Fri 21 Nov 2025 00:53:38 INFO  [Epoch 90] Train Loss: 1.9131218289891725
Fri 21 Nov 2025 00:53:38 INFO  [Epoch 90] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_90.pth
Fri 21 Nov 2025 00:56:02 INFO  [Epoch 91] Train Loss: 1.912526654000448
Fri 21 Nov 2025 00:58:26 INFO  [Epoch 92] Train Loss: 1.9102136313800187
Fri 21 Nov 2025 01:00:49 INFO  [Epoch 93] Train Loss: 1.908585536146256
Fri 21 Nov 2025 01:03:12 INFO  [Epoch 94] Train Loss: 1.9070632044643048
Fri 21 Nov 2025 01:05:35 INFO  [Epoch 95] Train Loss: 1.90447636316872
Fri 21 Nov 2025 01:07:58 INFO  [Epoch 96] Train Loss: 1.9033676471029009
Fri 21 Nov 2025 01:10:20 INFO  [Epoch 97] Train Loss: 1.9015898323082094
Fri 21 Nov 2025 01:12:43 INFO  [Epoch 98] Train Loss: 1.9002879074986838
Fri 21 Nov 2025 01:15:06 INFO  [Epoch 99] Train Loss: 1.8976934557370697
Fri 21 Nov 2025 01:17:29 INFO  [Epoch 100] Train Loss: 1.8954344351549406
Fri 21 Nov 2025 01:17:29 INFO  [Epoch 100] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_100.pth
Fri 21 Nov 2025 01:17:29 INFO  Best epoch: 0, Best val score: -1
Fri 21 Nov 2025 01:17:30 INFO  [Epoch 101] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284.pth
Fri 21 Nov 2025 01:17:30 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Fri 21 Nov 2025 02:31:14 INFO  Influence scores: tensor([[ 1.1712e-01,  1.0755e-01,  1.3393e-01,  8.5967e-02,  2.4950e-01,
          7.6553e-02,  2.4904e-02,  6.3162e-02,  3.4882e-02,  6.1039e-02,
          7.7238e-02,  9.4414e-02,  3.3688e-02,  4.3750e-02,  7.5108e-02,
          7.6166e-02,  6.2436e-02,  5.9828e-02,  6.1339e-02,  9.2252e-02,
          4.6215e-02,  3.6064e-02,  4.7319e-02,  6.7891e-02,  1.6710e-01],
        [ 5.7553e-02,  1.6166e-01,  1.4791e-01,  5.5482e-02,  2.4948e-01,
          8.3846e-02,  2.5001e-02,  7.0716e-02,  2.1455e-02,  4.8470e-02,
          7.4691e-02,  8.5530e-02,  3.3021e-02,  3.9004e-02,  8.5199e-02,
          7.5846e-02,  6.4089e-02,  4.7800e-02,  5.5005e-02,  9.4935e-02,
          4.9788e-02,  2.7804e-02,  5.1020e-02,  6.4699e-02,  1.6728e-01],
        [ 4.5660e-02,  1.1026e-01,  1.6096e-01,  4.2937e-02,  2.4718e-01,
          6.9522e-02,  2.3205e-02,  6.4789e-02,  3.0060e-02,  5.5022e-02,
          7.7780e-02,  8.6073e-02,  3.4820e-02,  4.3347e-02,  8.0501e-02,
          8.0868e-02,  6.6552e-02,  5.4642e-02,  5.8760e-02,  9.6492e-02,
          5.0275e-02,  3.0351e-02,  4.6268e-02,  6.1227e-02,  1.6115e-01],
        [ 7.0717e-02,  8.9881e-02,  1.1603e-01,  9.7545e-02,  2.4871e-01,
          7.0691e-02,  2.8043e-02,  6.7069e-02,  3.4000e-02,  5.1462e-02,
          7.6618e-02,  9.4268e-02,  3.5795e-02,  4.3537e-02,  7.9104e-02,
          7.6472e-02,  6.2890e-02,  6.0029e-02,  6.5493e-02,  9.0566e-02,
          4.3761e-02,  3.2331e-02,  4.5692e-02,  6.5803e-02,  1.6346e-01],
        [ 2.9769e-02,  8.1371e-02,  1.1768e-01,  4.5519e-02,  2.6822e-01,
          7.5774e-02,  3.1289e-02,  7.2352e-02,  3.8213e-02,  5.7941e-02,
          8.0862e-02,  9.8547e-02,  4.0669e-02,  5.1041e-02,  8.8728e-02,
          8.2858e-02,  6.8913e-02,  5.9323e-02,  6.4243e-02,  9.5328e-02,
          4.7763e-02,  3.2160e-02,  4.4999e-02,  5.8911e-02,  1.5860e-01],
        [ 3.1681e-02,  9.0601e-02,  1.1416e-01,  4.1272e-02,  2.4996e-01,
          1.0211e-01,  3.2130e-02,  7.1059e-02,  3.4891e-02,  6.3037e-02,
          8.3656e-02,  9.7266e-02,  4.1622e-02,  5.0692e-02,  8.6850e-02,
          8.1416e-02,  6.9306e-02,  5.4867e-02,  5.7464e-02,  9.2987e-02,
          4.7564e-02,  3.0471e-02,  4.8489e-02,  6.2840e-02,  1.6190e-01],
        [ 2.3331e-02,  7.3282e-02,  1.0988e-01,  4.0334e-02,  2.4724e-01,
          7.3693e-02,  5.4895e-02,  6.6186e-02,  4.0130e-02,  6.2095e-02,
          8.0464e-02,  1.0404e-01,  4.8986e-02,  5.1662e-02,  8.9135e-02,
          8.5192e-02,  7.1723e-02,  6.1773e-02,  6.7052e-02,  9.3612e-02,
          4.8048e-02,  3.5672e-02,  4.2762e-02,  6.4288e-02,  1.6093e-01],
        [ 7.4862e-04,  5.9453e-02,  9.2556e-02,  2.0220e-02,  2.2990e-01,
          5.2850e-02,  6.8014e-03,  1.0962e-01,  2.9141e-02,  4.8705e-02,
          8.4545e-02,  7.8304e-02,  3.8779e-02,  4.8011e-02,  9.1774e-02,
          7.7468e-02,  6.8565e-02,  6.0445e-02,  5.8671e-02,  1.0049e-01,
          5.0538e-02,  3.0329e-02,  5.7754e-02,  6.8711e-02,  1.6574e-01],
        [ 7.6337e-03,  4.3583e-02,  9.1025e-02,  2.1496e-02,  2.2845e-01,
          5.1079e-02,  1.5391e-02,  6.2972e-02,  7.1174e-02,  7.2718e-02,
          8.1899e-02,  9.8787e-02,  4.7053e-02,  6.3073e-02,  8.8735e-02,
          8.6046e-02,  7.5642e-02,  7.2607e-02,  6.6194e-02,  9.8525e-02,
          5.1547e-02,  3.8966e-02,  4.7643e-02,  6.0908e-02,  1.5789e-01],
        [ 6.8696e-03,  4.4938e-02,  9.0607e-02,  1.3445e-02,  2.2449e-01,
          5.3563e-02,  1.1989e-02,  5.7244e-02,  4.7245e-02,  9.8399e-02,
          8.5972e-02,  9.9801e-02,  5.0986e-02,  6.5544e-02,  8.8438e-02,
          8.6503e-02,  7.9214e-02,  7.1095e-02,  6.4076e-02,  9.8110e-02,
          5.4175e-02,  4.0886e-02,  5.1544e-02,  6.4541e-02,  1.6168e-01],
        [-6.0900e-03,  4.2240e-02,  8.3839e-02,  8.1073e-03,  2.1690e-01,
          4.4865e-02,  1.4354e-04,  6.2923e-02,  2.6034e-02,  5.6099e-02,
          1.1099e-01,  9.6474e-02,  4.6134e-02,  5.6492e-02,  8.3279e-02,
          9.2487e-02,  7.7180e-02,  6.6422e-02,  7.1083e-02,  1.0534e-01,
          5.3738e-02,  3.7583e-02,  6.0077e-02,  7.3952e-02,  1.6984e-01],
        [-7.9498e-04,  4.0532e-02,  8.0821e-02,  1.3935e-02,  2.2311e-01,
          4.7383e-02,  1.2612e-02,  4.5533e-02,  3.2424e-02,  5.7814e-02,
          8.5105e-02,  1.4464e-01,  4.9929e-02,  6.6280e-02,  9.2705e-02,
          9.9600e-02,  8.3771e-02,  7.5547e-02,  8.0366e-02,  1.0685e-01,
          5.8610e-02,  5.5196e-02,  5.5879e-02,  7.5404e-02,  1.7532e-01],
        [-1.5217e-02,  3.4907e-02,  7.6211e-02,  2.1131e-03,  2.1305e-01,
          3.6435e-02,  1.7040e-03,  5.2066e-02,  2.5871e-02,  5.5626e-02,
          8.0629e-02,  9.4945e-02,  7.4027e-02,  6.2501e-02,  9.8994e-02,
          9.7516e-02,  9.2084e-02,  7.8534e-02,  7.7344e-02,  1.1103e-01,
          6.5743e-02,  5.0683e-02,  6.0475e-02,  7.7952e-02,  1.7501e-01],
        [-1.7351e-02,  2.8301e-02,  7.1627e-02, -3.2440e-03,  2.0818e-01,
          3.4063e-02, -6.7624e-03,  5.0153e-02,  3.0172e-02,  5.9257e-02,
          7.9639e-02,  9.9259e-02,  5.0491e-02,  8.7580e-02,  1.0513e-01,
          9.7082e-02,  9.3309e-02,  8.4021e-02,  7.4550e-02,  1.1389e-01,
          6.9238e-02,  5.5877e-02,  6.5348e-02,  7.6997e-02,  1.7504e-01],
        [-1.9659e-02,  3.9693e-02,  7.3430e-02, -1.3720e-03,  2.1120e-01,
          3.4726e-02, -4.1045e-03,  5.7968e-02,  2.1724e-02,  4.6081e-02,
          7.1466e-02,  9.1043e-02,  5.1300e-02,  7.0382e-02,  1.4512e-01,
          1.0029e-01,  1.0407e-01,  8.9402e-02,  8.0602e-02,  1.2774e-01,
          8.8083e-02,  6.6519e-02,  8.1663e-02,  9.1120e-02,  1.9183e-01],
        [-2.2638e-02,  2.8092e-02,  7.1939e-02, -7.1278e-03,  2.0356e-01,
          2.7637e-02, -1.0552e-02,  4.1813e-02,  1.6479e-02,  4.2496e-02,
          7.7993e-02,  9.5464e-02,  4.7840e-02,  6.0262e-02,  9.8959e-02,
          1.2585e-01,  1.0210e-01,  9.0941e-02,  8.8228e-02,  1.2797e-01,
          7.7139e-02,  6.3357e-02,  7.3809e-02,  8.9979e-02,  1.8488e-01],
        [-2.7620e-02,  2.3389e-02,  6.4720e-02, -1.2512e-02,  1.9645e-01,
          2.2157e-02, -1.6696e-02,  3.9969e-02,  1.2844e-02,  4.2034e-02,
          7.0068e-02,  8.6282e-02,  4.9391e-02,  6.2775e-02,  1.0903e-01,
          1.0876e-01,  1.2124e-01,  9.8223e-02,  8.8592e-02,  1.3251e-01,
          9.0786e-02,  7.3668e-02,  8.5026e-02,  9.8716e-02,  1.9468e-01],
        [-2.3072e-02,  1.5115e-02,  6.0896e-02, -8.0298e-03,  1.9566e-01,
          1.6771e-02, -1.8131e-02,  3.9121e-02,  1.7368e-02,  4.2054e-02,
          6.6973e-02,  8.7106e-02,  4.3648e-02,  6.1824e-02,  1.0219e-01,
          1.0565e-01,  1.0580e-01,  1.2360e-01,  9.8806e-02,  1.3529e-01,
          8.8079e-02,  8.2545e-02,  8.4432e-02,  1.0440e-01,  1.9794e-01],
        [-2.2195e-02,  2.1567e-02,  6.4218e-02, -2.6915e-03,  2.0014e-01,
          1.8726e-02, -1.3939e-02,  3.7311e-02,  9.8243e-03,  3.4102e-02,
          7.0276e-02,  9.0603e-02,  4.1923e-02,  5.1743e-02,  9.3815e-02,
          1.0295e-01,  9.6005e-02,  9.8435e-02,  1.3839e-01,  1.3919e-01,
          8.8805e-02,  8.0608e-02,  9.0423e-02,  1.1364e-01,  2.0710e-01],
        [-2.8707e-02,  2.4596e-02,  6.4894e-02, -1.4368e-02,  1.9416e-01,
          1.6965e-02, -2.3863e-02,  4.2084e-02,  6.0773e-03,  3.1998e-02,
          6.8554e-02,  8.0692e-02,  3.8430e-02,  5.4326e-02,  1.0313e-01,
          1.0576e-01,  1.0305e-01,  9.7630e-02,  1.0198e-01,  1.7031e-01,
          1.1306e-01,  9.0297e-02,  1.1086e-01,  1.1916e-01,  2.1595e-01],
        [-3.2679e-02,  2.1913e-02,  5.9816e-02, -1.8577e-02,  1.8825e-01,
          1.2295e-02, -2.7823e-02,  3.5101e-02,  1.1233e-03,  3.0018e-02,
          5.8665e-02,  7.5010e-02,  3.4855e-02,  5.0927e-02,  1.0540e-01,
          9.6992e-02,  1.0314e-01,  9.3523e-02,  9.4492e-02,  1.5481e-01,
          1.3934e-01,  1.0272e-01,  1.2750e-01,  1.3256e-01,  2.3349e-01],
        [-3.2248e-02,  1.0723e-02,  5.2286e-02, -2.0330e-02,  1.8390e-01,
          6.0096e-03, -2.9841e-02,  2.4519e-02, -1.0967e-03,  2.6812e-02,
          5.2653e-02,  8.1055e-02,  3.0556e-02,  4.8256e-02,  9.4100e-02,
          9.3922e-02,  9.6202e-02,  9.7349e-02,  9.6150e-02,  1.4201e-01,
          1.1313e-01,  1.3145e-01,  1.1886e-01,  1.4188e-01,  2.4151e-01],
        [-4.2183e-02,  1.3049e-02,  4.6112e-02, -2.8088e-02,  1.7540e-01,
          1.5562e-03, -4.4595e-02,  3.1482e-02, -1.4482e-02,  1.6018e-02,
          5.3643e-02,  5.9973e-02,  1.8332e-02,  3.5418e-02,  8.8104e-02,
          8.2359e-02,  8.5981e-02,  7.8516e-02,  8.4710e-02,  1.4162e-01,
          1.1622e-01,  9.7287e-02,  1.4403e-01,  1.4073e-01,  2.4373e-01],
        [-2.7925e-02,  2.0046e-02,  5.4877e-02, -1.5439e-02,  1.8107e-01,
          1.0054e-02, -2.9743e-02,  3.4316e-02, -8.2502e-03,  2.1697e-02,
          5.9992e-02,  7.2470e-02,  2.8969e-02,  4.0030e-02,  9.0425e-02,
          9.2030e-02,  9.3134e-02,  9.1048e-02,  1.0081e-01,  1.4326e-01,
          1.1535e-01,  1.1398e-01,  1.3410e-01,  1.8126e-01,  2.6872e-01],
        [-2.9211e-02,  2.2512e-02,  5.5182e-02, -1.6067e-02,  1.8319e-01,
          9.9967e-03, -3.2213e-02,  3.2019e-02, -1.0116e-02,  1.9240e-02,
          5.6658e-02,  7.3357e-02,  2.5575e-02,  3.9495e-02,  9.2285e-02,
          8.7541e-02,  9.0247e-02,  8.5529e-02,  9.5634e-02,  1.4077e-01,
          1.1662e-01,  1.1444e-01,  1.3687e-01,  1.6898e-01,  2.8884e-01]],
       device='cuda:0')
Fri 21 Nov 2025 02:31:14 INFO  Mean influence score: [0.2652704417705536, 0.26377204060554504, 0.26413512229919434, 0.25953203439712524, 0.2548721730709076, 0.25515562295913696, 0.25210970640182495, 0.24998782575130463, 0.2508697211742401, 0.2588532865047455, 0.2521657943725586, 0.2526027262210846, 0.2534639835357666, 0.25592318177223206, 0.25422564148902893, 0.2586000859737396, 0.25584840774536133, 0.2501479685306549, 0.25178709626197815, 0.2617315948009491, 0.2596719563007355, 0.2537454664707184, 0.25443771481513977, 0.2574473023414612, 0.25035083293914795]
Fri 21 Nov 2025 02:31:14 INFO  Stage 2 selected prob: [0.04007526859641075, 0.04006326198577881, 0.04006616771221161, 0.04002930223941803, 0.039992015808820724, 0.03999428078532219, 0.039969924837350845, 0.03995296731591225, 0.03996001183986664, 0.04002387076616287, 0.03997037559747696, 0.03997386619448662, 0.039980754256248474, 0.040000420063734055, 0.03998684138059616, 0.04002184420824051, 0.0399998277425766, 0.03995424509048462, 0.03996734693646431, 0.04004691541194916, 0.040030427277088165, 0.039983004331588745, 0.03998853638768196, 0.04001261666417122, 0.03995586931705475]
Fri 21 Nov 2025 02:33:50 INFO  [Epoch 101] Train Loss: 1.894332253967473
Fri 21 Nov 2025 02:36:25 INFO  [Epoch 102] Train Loss: 1.892844361745713
Fri 21 Nov 2025 02:39:01 INFO  [Epoch 103] Train Loss: 1.889954036324641
Fri 21 Nov 2025 02:41:40 INFO  [Epoch 104] Train Loss: 1.889181144794442
Fri 21 Nov 2025 02:44:18 INFO  [Epoch 105] Train Loss: 1.8868488071622995
Fri 21 Nov 2025 02:46:56 INFO  [Epoch 106] Train Loss: 1.8837652593620955
Fri 21 Nov 2025 02:49:36 INFO  [Epoch 107] Train Loss: 1.8823164590997585
Fri 21 Nov 2025 02:52:16 INFO  [Epoch 108] Train Loss: 1.880313343810759
Fri 21 Nov 2025 02:54:54 INFO  [Epoch 109] Train Loss: 1.8776753940062174
Fri 21 Nov 2025 02:57:34 INFO  [Epoch 110] Train Loss: 1.875510418104389
Fri 21 Nov 2025 02:57:34 INFO  [Epoch 110] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_110.pth
Fri 21 Nov 2025 03:00:12 INFO  [Epoch 111] Train Loss: 1.8738799027839683
Fri 21 Nov 2025 03:02:49 INFO  [Epoch 112] Train Loss: 1.8729080136678393
Fri 21 Nov 2025 03:05:22 INFO  [Epoch 113] Train Loss: 1.869180937301238
Fri 21 Nov 2025 03:08:02 INFO  [Epoch 114] Train Loss: 1.867695909727034
Fri 21 Nov 2025 03:10:40 INFO  [Epoch 115] Train Loss: 1.8662348173875145
Fri 21 Nov 2025 03:13:19 INFO  [Epoch 116] Train Loss: 1.8630790854282822
Fri 21 Nov 2025 03:15:57 INFO  [Epoch 117] Train Loss: 1.8610583029428505
Fri 21 Nov 2025 03:18:33 INFO  [Epoch 118] Train Loss: 1.8594583079046265
Fri 21 Nov 2025 03:21:08 INFO  [Epoch 119] Train Loss: 1.857069007850982
Fri 21 Nov 2025 03:23:40 INFO  [Epoch 120] Train Loss: 1.8541265352697447
Fri 21 Nov 2025 03:23:40 INFO  [Epoch 120] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_120.pth
Fri 21 Nov 2025 03:23:40 INFO  Best epoch: 0, Best val score: -1
Fri 21 Nov 2025 03:23:40 INFO  [Epoch 121] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284.pth
Fri 21 Nov 2025 03:23:40 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Fri 21 Nov 2025 04:38:00 INFO  Influence scores: tensor([[ 1.6996e-01,  1.4699e-01,  1.4810e-01,  1.6847e-01,  1.0949e-01,
          1.1019e-01,  1.1740e-01,  8.8745e-02,  6.9647e-02,  1.0356e-01,
          8.3695e-02,  6.9834e-02,  7.0702e-02,  4.9326e-02,  8.1173e-02,
          3.7087e-02,  6.3817e-02,  7.3777e-02,  2.4375e-02,  3.6798e-02,
          3.9356e-02,  2.0892e-02, -9.1571e-03,  2.9251e-02, -1.5144e-04],
        [ 1.0881e-01,  2.2421e-01,  1.7674e-01,  1.4375e-01,  1.2139e-01,
          1.3096e-01,  1.2733e-01,  1.0809e-01,  6.4641e-02,  1.0012e-01,
          9.0246e-02,  7.0653e-02,  8.0357e-02,  5.4180e-02,  1.0475e-01,
          4.6285e-02,  7.7458e-02,  7.0704e-02,  2.8542e-02,  5.0226e-02,
          5.6357e-02,  2.4088e-02,  6.0453e-03,  3.7086e-02,  1.2974e-02],
        [ 9.8955e-02,  1.6496e-01,  1.9356e-01,  1.3265e-01,  1.2172e-01,
          1.1798e-01,  1.2735e-01,  1.0266e-01,  7.3774e-02,  1.0896e-01,
          9.6190e-02,  7.3144e-02,  8.3346e-02,  6.0384e-02,  9.9273e-02,
          5.3024e-02,  8.0476e-02,  7.8006e-02,  3.3317e-02,  5.2727e-02,
          5.6256e-02,  2.6274e-02,  3.6189e-04,  3.3860e-02,  5.9930e-03],
        [ 1.2523e-01,  1.3750e-01,  1.3855e-01,  1.9289e-01,  1.2192e-01,
          1.1489e-01,  1.3110e-01,  1.0341e-01,  7.7449e-02,  1.0208e-01,
          9.3386e-02,  8.1275e-02,  8.2715e-02,  5.8953e-02,  9.5722e-02,
          4.7452e-02,  7.5031e-02,  8.3874e-02,  3.9749e-02,  4.5443e-02,
          4.8008e-02,  2.7255e-02, -2.0883e-03,  3.7122e-02,  7.6339e-03],
        [ 8.5965e-02,  1.3648e-01,  1.4870e-01,  1.4142e-01,  1.5182e-01,
          1.3001e-01,  1.4113e-01,  1.1798e-01,  8.8055e-02,  1.1582e-01,
          1.0629e-01,  9.3476e-02,  9.5676e-02,  7.5791e-02,  1.1503e-01,
          6.2287e-02,  9.0117e-02,  9.0164e-02,  4.5831e-02,  5.9182e-02,
          6.1055e-02,  3.4937e-02,  4.8918e-03,  3.8255e-02,  1.0347e-02],
        [ 8.5728e-02,  1.4370e-01,  1.4246e-01,  1.3342e-01,  1.2812e-01,
          1.5722e-01,  1.3993e-01,  1.1364e-01,  8.2088e-02,  1.1966e-01,
          1.0742e-01,  9.0358e-02,  9.5374e-02,  7.4153e-02,  1.1129e-01,
          5.9741e-02,  8.9446e-02,  8.4238e-02,  3.6892e-02,  5.4447e-02,
          5.8856e-02,  3.1766e-02,  7.0839e-03,  4.0829e-02,  1.2402e-02],
        [ 7.6402e-02,  1.2442e-01,  1.3579e-01,  1.3239e-01,  1.2280e-01,
          1.2407e-01,  1.6567e-01,  1.0723e-01,  8.7475e-02,  1.1854e-01,
          1.0193e-01,  9.6151e-02,  1.0149e-01,  7.2716e-02,  1.1275e-01,
          6.1533e-02,  9.0364e-02,  9.0971e-02,  4.6649e-02,  5.2943e-02,
          5.7908e-02,  3.5618e-02, -5.1464e-04,  4.1329e-02,  9.9242e-03],
        [ 5.5756e-02,  1.1363e-01,  1.2016e-01,  1.1406e-01,  1.0841e-01,
          1.0620e-01,  1.1624e-01,  1.5936e-01,  7.8317e-02,  1.0696e-01,
          1.0771e-01,  7.2519e-02,  9.3953e-02,  7.2546e-02,  1.1824e-01,
          5.5896e-02,  8.9893e-02,  9.0197e-02,  3.8960e-02,  6.1913e-02,
          6.2026e-02,  3.1937e-02,  1.6724e-02,  4.6630e-02,  1.5489e-02],
        [ 5.9398e-02,  9.0764e-02,  1.1244e-01,  1.0980e-01,  9.9857e-02,
          9.6044e-02,  1.1804e-01,  1.0074e-01,  1.1983e-01,  1.2782e-01,
          9.9740e-02,  8.7408e-02,  9.6932e-02,  8.2002e-02,  1.0852e-01,
          5.9857e-02,  9.0429e-02,  9.8635e-02,  4.0637e-02,  5.5200e-02,
          5.7171e-02,  3.5189e-02,  4.6449e-04,  3.4356e-02,  2.5899e-03],
        [ 6.1061e-02,  9.5458e-02,  1.1581e-01,  1.0322e-01,  9.7263e-02,
          1.0241e-01,  1.1842e-01,  9.8472e-02,  9.6339e-02,  1.6357e-01,
          1.1087e-01,  9.2763e-02,  1.0801e-01,  9.2237e-02,  1.1312e-01,
          6.7287e-02,  1.0141e-01,  1.0265e-01,  4.4272e-02,  6.1018e-02,
          6.6330e-02,  4.3574e-02,  1.1082e-02,  4.5292e-02,  1.2054e-02],
        [ 5.3182e-02,  9.7219e-02,  1.1538e-01,  1.0602e-01,  9.8749e-02,
          1.0095e-01,  1.1309e-01,  1.1073e-01,  7.9865e-02,  1.2274e-01,
          1.4674e-01,  1.0045e-01,  1.0931e-01,  9.0009e-02,  1.1465e-01,
          7.9737e-02,  1.0591e-01,  1.0385e-01,  5.9103e-02,  7.6255e-02,
          7.2745e-02,  4.6693e-02,  2.6247e-02,  6.0388e-02,  2.6801e-02],
        [ 5.3978e-02,  9.1434e-02,  1.0575e-01,  1.0763e-01,  9.9763e-02,
          9.7996e-02,  1.2051e-01,  8.8212e-02,  8.2151e-02,  1.1747e-01,
          1.1245e-01,  1.5045e-01,  1.0794e-01,  9.5163e-02,  1.2241e-01,
          8.3811e-02,  1.0896e-01,  1.1207e-01,  6.7043e-02,  7.4248e-02,
          7.4950e-02,  6.2348e-02,  1.8836e-02,  6.0097e-02,  3.1502e-02],
        [ 3.6648e-02,  8.3773e-02,  9.9083e-02,  9.1715e-02,  8.4703e-02,
          8.5973e-02,  1.0846e-01,  9.3039e-02,  7.3589e-02,  1.1558e-01,
          1.0533e-01,  9.0783e-02,  1.3743e-01,  9.1018e-02,  1.2853e-01,
          8.0464e-02,  1.1836e-01,  1.1219e-01,  6.0104e-02,  7.6310e-02,
          8.1741e-02,  5.6408e-02,  2.1963e-02,  6.0695e-02,  2.6564e-02],
        [ 3.6797e-02,  7.9026e-02,  9.7302e-02,  8.8702e-02,  8.5019e-02,
          8.4430e-02,  1.0076e-01,  9.3168e-02,  7.9964e-02,  1.2092e-01,
          1.0607e-01,  9.9180e-02,  1.1165e-01,  1.2139e-01,  1.3650e-01,
          8.2742e-02,  1.2153e-01,  1.2128e-01,  5.9923e-02,  8.2209e-02,
          8.7057e-02,  6.3300e-02,  2.9003e-02,  6.0896e-02,  3.0202e-02],
        [ 2.2678e-02,  8.2284e-02,  8.8346e-02,  8.0748e-02,  7.8780e-02,
          7.5938e-02,  9.4142e-02,  9.1367e-02,  6.1277e-02,  9.5259e-02,
          8.5369e-02,  7.9752e-02,  1.0277e-01,  9.0513e-02,  1.7498e-01,
          7.4730e-02,  1.2336e-01,  1.1723e-01,  5.8016e-02,  8.6826e-02,
          1.0071e-01,  6.7081e-02,  3.9460e-02,  6.8589e-02,  4.1837e-02],
        [ 3.1137e-02,  7.7829e-02,  9.7089e-02,  8.4534e-02,  8.0241e-02,
          7.8647e-02,  9.7580e-02,  8.3780e-02,  6.5757e-02,  1.0356e-01,
          1.0456e-01,  9.6284e-02,  1.0891e-01,  9.1678e-02,  1.3027e-01,
          1.1747e-01,  1.3141e-01,  1.2932e-01,  7.6280e-02,  9.8355e-02,
          9.7096e-02,  7.3653e-02,  3.9709e-02,  7.6849e-02,  4.1648e-02],
        [ 2.2344e-02,  7.1497e-02,  8.6593e-02,  7.5748e-02,  7.0222e-02,
          7.0012e-02,  8.7870e-02,  7.9755e-02,  5.8407e-02,  1.0004e-01,
          9.3086e-02,  8.2670e-02,  1.0798e-01,  9.1595e-02,  1.4004e-01,
          9.3122e-02,  1.5208e-01,  1.3467e-01,  7.3528e-02,  1.0103e-01,
          1.1077e-01,  8.2473e-02,  5.0953e-02,  8.4388e-02,  5.1557e-02],
        [ 2.3953e-02,  5.8451e-02,  7.7617e-02,  7.6923e-02,  6.3985e-02,
          5.9265e-02,  8.2532e-02,  7.3950e-02,  5.9341e-02,  9.4837e-02,
          8.4838e-02,  7.8976e-02,  9.6820e-02,  8.4999e-02,  1.2738e-01,
          8.5030e-02,  1.2837e-01,  1.6032e-01,  8.0807e-02,  9.8939e-02,
          1.0178e-01,  8.7036e-02,  4.4036e-02,  8.5694e-02,  4.8858e-02],
        [ 2.0592e-02,  6.1275e-02,  7.8423e-02,  7.9007e-02,  6.5596e-02,
          5.7297e-02,  8.3836e-02,  6.7367e-02,  4.7920e-02,  8.1814e-02,
          8.5240e-02,  8.0304e-02,  8.9218e-02,  7.0027e-02,  1.1533e-01,
          7.7774e-02,  1.1336e-01,  1.2733e-01,  1.2553e-01,  1.0189e-01,
          1.0076e-01,  8.4388e-02,  4.9372e-02,  9.3584e-02,  5.8520e-02],
        [ 1.7396e-02,  6.8256e-02,  8.3122e-02,  6.9630e-02,  6.3674e-02,
          5.9161e-02,  7.5218e-02,  7.6508e-02,  4.6409e-02,  8.3462e-02,
          8.7636e-02,  7.2933e-02,  9.0342e-02,  7.7217e-02,  1.2902e-01,
          8.4153e-02,  1.2504e-01,  1.2868e-01,  8.5037e-02,  1.4181e-01,
          1.3217e-01,  9.7631e-02,  7.6717e-02,  1.0301e-01,  7.1053e-02],
        [ 1.2253e-02,  6.5889e-02,  7.7456e-02,  6.4761e-02,  5.6384e-02,
          5.4335e-02,  7.1588e-02,  6.7765e-02,  4.1314e-02,  8.0221e-02,
          7.5730e-02,  6.5615e-02,  8.7003e-02,  7.2684e-02,  1.3237e-01,
          7.3986e-02,  1.2591e-01,  1.2379e-01,  7.6726e-02,  1.2348e-01,
          1.6500e-01,  1.1171e-01,  9.6779e-02,  1.2017e-01,  9.3401e-02],
        [ 1.4583e-02,  5.4363e-02,  6.9294e-02,  6.4094e-02,  5.1373e-02,
          4.8072e-02,  6.9848e-02,  5.8333e-02,  4.0209e-02,  7.8314e-02,
          7.0268e-02,  7.2055e-02,  8.2562e-02,  6.9846e-02,  1.2041e-01,
          7.1297e-02,  1.1824e-01,  1.3043e-01,  8.1298e-02,  1.1021e-01,
          1.3334e-01,  1.4718e-01,  8.6724e-02,  1.3088e-01,  1.0342e-01],
        [ 1.0688e-02,  6.3516e-02,  6.9800e-02,  6.1475e-02,  4.8062e-02,
          5.0147e-02,  6.0513e-02,  7.0221e-02,  3.1309e-02,  7.2556e-02,
          7.7101e-02,  5.7057e-02,  7.5082e-02,  6.2871e-02,  1.1959e-01,
          6.4969e-02,  1.1365e-01,  1.1355e-01,  7.2978e-02,  1.1576e-01,
          1.4501e-01,  1.1369e-01,  1.2287e-01,  1.3581e-01,  1.1091e-01],
        [ 1.4994e-02,  6.1201e-02,  6.9413e-02,  6.6426e-02,  4.6480e-02,
          4.8954e-02,  6.6755e-02,  6.4569e-02,  2.9495e-02,  7.0504e-02,
          7.4624e-02,  6.1533e-02,  7.7144e-02,  5.8639e-02,  1.1351e-01,
          6.5445e-02,  1.1065e-01,  1.1935e-01,  8.1169e-02,  1.0715e-01,
          1.3291e-01,  1.2190e-01,  1.0103e-01,  1.7140e-01,  1.2945e-01],
        [ 1.2176e-02,  6.2095e-02,  6.7860e-02,  6.4168e-02,  4.5847e-02,
          4.7898e-02,  6.2639e-02,  6.0306e-02,  2.6191e-02,  6.5009e-02,
          6.8617e-02,  6.0443e-02,  7.1082e-02,  5.4968e-02,  1.1408e-01,
          5.8391e-02,  1.0597e-01,  1.1137e-01,  7.4213e-02,  1.0256e-01,
          1.3382e-01,  1.2224e-01,  1.0291e-01,  1.5649e-01,  1.5216e-01]],
       device='cuda:0')
Fri 21 Nov 2025 04:38:00 INFO  Mean influence score: [0.2365342080593109, 0.236555814743042, 0.23661579191684723, 0.23265951871871948, 0.2297661304473877, 0.22976066172122955, 0.22697265446186066, 0.2244875133037567, 0.22481082379817963, 0.23243315517902374, 0.2273256778717041, 0.2278808206319809, 0.22784103453159332, 0.23028257489204407, 0.2282535880804062, 0.2327631711959839, 0.2301790565252304, 0.22469019889831543, 0.22578273713588715, 0.23500342667102814, 0.2332022488117218, 0.22781355679035187, 0.2281728833913803, 0.2308802753686905, 0.22449016571044922]
Fri 21 Nov 2025 04:38:00 INFO  Stage 3 selected prob: [0.040053848177194595, 0.040054019540548325, 0.040054500102996826, 0.040022820234298706, 0.039999667555093765, 0.039999622851610184, 0.03997732326388359, 0.03995746374130249, 0.039960041642189026, 0.040021009743213654, 0.039980147033929825, 0.03998458757996559, 0.03998427093029022, 0.04000380262732506, 0.03998757153749466, 0.04002365469932556, 0.0400029718875885, 0.03995908051729202, 0.039967816323041916, 0.04004158824682236, 0.04002716392278671, 0.03998405113816261, 0.03998691961169243, 0.04000858590006828, 0.03995748236775398]
Fri 21 Nov 2025 04:40:33 INFO  [Epoch 121] Train Loss: 1.8520743693854358
Fri 21 Nov 2025 04:43:04 INFO  [Epoch 122] Train Loss: 1.8498173137429137
Fri 21 Nov 2025 04:45:38 INFO  [Epoch 123] Train Loss: 1.847478949252703
Fri 21 Nov 2025 04:48:11 INFO  [Epoch 124] Train Loss: 1.84522001571867
Fri 21 Nov 2025 04:50:44 INFO  [Epoch 125] Train Loss: 1.8428483390785093
Fri 21 Nov 2025 04:53:12 INFO  [Epoch 126] Train Loss: 1.8407804144970699
Fri 21 Nov 2025 04:55:43 INFO  [Epoch 127] Train Loss: 1.838222961398165
Fri 21 Nov 2025 04:58:13 INFO  [Epoch 128] Train Loss: 1.8357236087322235
Fri 21 Nov 2025 05:00:45 INFO  [Epoch 129] Train Loss: 1.8334064583175431
Fri 21 Nov 2025 05:03:16 INFO  [Epoch 130] Train Loss: 1.8308388872726544
Fri 21 Nov 2025 05:03:16 INFO  [Epoch 130] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_130.pth
Fri 21 Nov 2025 05:05:46 INFO  [Epoch 131] Train Loss: 1.828108363285028
Fri 21 Nov 2025 05:08:13 INFO  [Epoch 132] Train Loss: 1.8253697786321972
Fri 21 Nov 2025 05:10:43 INFO  [Epoch 133] Train Loss: 1.8232040668776597
Fri 21 Nov 2025 05:13:14 INFO  [Epoch 134] Train Loss: 1.8203412351345925
Fri 21 Nov 2025 05:15:46 INFO  [Epoch 135] Train Loss: 1.8181836607373358
Fri 21 Nov 2025 05:18:20 INFO  [Epoch 136] Train Loss: 1.8152426549711742
Fri 21 Nov 2025 05:20:51 INFO  [Epoch 137] Train Loss: 1.812602254357117
Fri 21 Nov 2025 05:23:16 INFO  [Epoch 138] Train Loss: 1.8095252351641196
Fri 21 Nov 2025 05:25:44 INFO  [Epoch 139] Train Loss: 1.8070134368067083
Fri 21 Nov 2025 05:28:13 INFO  [Epoch 140] Train Loss: 1.8044898794194446
Fri 21 Nov 2025 05:28:13 INFO  [Epoch 140] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_140.pth
Fri 21 Nov 2025 05:28:13 INFO  Best epoch: 0, Best val score: -1
Fri 21 Nov 2025 05:28:13 INFO  [Epoch 141] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284.pth
Fri 21 Nov 2025 05:28:13 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Fri 21 Nov 2025 06:44:23 INFO  Influence scores: tensor([[0.3382, 0.2713, 0.1882, 0.2748, 0.1827, 0.1885, 0.1649, 0.1650, 0.1351,
         0.1308, 0.1657, 0.1371, 0.1173, 0.1325, 0.1308, 0.1097, 0.1235, 0.1186,
         0.1084, 0.1395, 0.0794, 0.1081, 0.1217, 0.1631, 0.1471],
        [0.2423, 0.3525, 0.2075, 0.2229, 0.1802, 0.1965, 0.1621, 0.1706, 0.1142,
         0.1111, 0.1573, 0.1201, 0.1133, 0.1219, 0.1416, 0.1051, 0.1223, 0.0983,
         0.0959, 0.1413, 0.0822, 0.0945, 0.1227, 0.1556, 0.1447],
        [0.2370, 0.2838, 0.2384, 0.2157, 0.1882, 0.1888, 0.1696, 0.1713, 0.1343,
         0.1316, 0.1711, 0.1315, 0.1259, 0.1379, 0.1433, 0.1221, 0.1358, 0.1164,
         0.1099, 0.1515, 0.0898, 0.1064, 0.1232, 0.1584, 0.1438],
        [0.2649, 0.2429, 0.1588, 0.2905, 0.1812, 0.1778, 0.1669, 0.1681, 0.1305,
         0.1138, 0.1621, 0.1342, 0.1170, 0.1282, 0.1324, 0.1069, 0.1218, 0.1168,
         0.1114, 0.1339, 0.0722, 0.0983, 0.1137, 0.1552, 0.1391],
        [0.1981, 0.2251, 0.1565, 0.2049, 0.2032, 0.1809, 0.1651, 0.1683, 0.1298,
         0.1177, 0.1611, 0.1339, 0.1186, 0.1335, 0.1399, 0.1102, 0.1253, 0.1091,
         0.1044, 0.1353, 0.0716, 0.0923, 0.1039, 0.1387, 0.1248],
        [0.1998, 0.2361, 0.1526, 0.1970, 0.1755, 0.2179, 0.1663, 0.1664, 0.1255,
         0.1248, 0.1655, 0.1315, 0.1205, 0.1335, 0.1382, 0.1091, 0.1255, 0.1034,
         0.0940, 0.1311, 0.0706, 0.0905, 0.1092, 0.1443, 0.1303],
        [0.1863, 0.2118, 0.1433, 0.1956, 0.1692, 0.1756, 0.1979, 0.1581, 0.1324,
         0.1235, 0.1592, 0.1397, 0.1285, 0.1339, 0.1389, 0.1130, 0.1288, 0.1119,
         0.1066, 0.1305, 0.0707, 0.0954, 0.0998, 0.1447, 0.1268],
        [0.1669, 0.2022, 0.1278, 0.1790, 0.1542, 0.1581, 0.1401, 0.2270, 0.1237,
         0.1127, 0.1712, 0.1125, 0.1238, 0.1370, 0.1527, 0.1105, 0.1339, 0.1174,
         0.1017, 0.1469, 0.0827, 0.0970, 0.1290, 0.1581, 0.1403],
        [0.1702, 0.1759, 0.1214, 0.1732, 0.1483, 0.1489, 0.1459, 0.1566, 0.1788,
         0.1417, 0.1637, 0.1360, 0.1303, 0.1520, 0.1417, 0.1182, 0.1369, 0.1281,
         0.1066, 0.1393, 0.0786, 0.1032, 0.1091, 0.1433, 0.1264],
        [0.1675, 0.1754, 0.1201, 0.1593, 0.1391, 0.1505, 0.1408, 0.1482, 0.1441,
         0.1811, 0.1713, 0.1366, 0.1379, 0.1577, 0.1412, 0.1212, 0.1439, 0.1275,
         0.1056, 0.1403, 0.0828, 0.1071, 0.1145, 0.1497, 0.1308],
        [0.1534, 0.1728, 0.1114, 0.1576, 0.1324, 0.1412, 0.1270, 0.1572, 0.1165,
         0.1225, 0.2098, 0.1383, 0.1329, 0.1476, 0.1372, 0.1299, 0.1431, 0.1243,
         0.1179, 0.1529, 0.0838, 0.1044, 0.1278, 0.1645, 0.1445],
        [0.1556, 0.1666, 0.1024, 0.1611, 0.1375, 0.1393, 0.1398, 0.1301, 0.1218,
         0.1184, 0.1699, 0.2037, 0.1332, 0.1579, 0.1489, 0.1381, 0.1487, 0.1356,
         0.1291, 0.1542, 0.0897, 0.1268, 0.1218, 0.1651, 0.1521],
        [0.1361, 0.1599, 0.0969, 0.1442, 0.1192, 0.1267, 0.1253, 0.1394, 0.1127,
         0.1176, 0.1615, 0.1300, 0.1727, 0.1541, 0.1585, 0.1353, 0.1626, 0.1384,
         0.1239, 0.1579, 0.1000, 0.1206, 0.1274, 0.1675, 0.1462],
        [0.1331, 0.1493, 0.0909, 0.1370, 0.1172, 0.1222, 0.1132, 0.1358, 0.1186,
         0.1219, 0.1600, 0.1389, 0.1384, 0.1895, 0.1668, 0.1360, 0.1644, 0.1465,
         0.1208, 0.1629, 0.1049, 0.1283, 0.1337, 0.1661, 0.1502],
        [0.1313, 0.1691, 0.0957, 0.1417, 0.1237, 0.1264, 0.1177, 0.1491, 0.1071,
         0.1041, 0.1476, 0.1280, 0.1400, 0.1647, 0.2296, 0.1406, 0.1806, 0.1556,
         0.1318, 0.1833, 0.1344, 0.1452, 0.1606, 0.1879, 0.1769],
        [0.1250, 0.1496, 0.0907, 0.1319, 0.1103, 0.1137, 0.1085, 0.1246, 0.0996,
         0.0997, 0.1575, 0.1344, 0.1345, 0.1509, 0.1583, 0.1785, 0.1771, 0.1579,
         0.1403, 0.1834, 0.1168, 0.1404, 0.1470, 0.1853, 0.1635],
        [0.1204, 0.1476, 0.0853, 0.1283, 0.1052, 0.1102, 0.1035, 0.1274, 0.0980,
         0.1029, 0.1496, 0.1247, 0.1405, 0.1584, 0.1780, 0.1569, 0.2099, 0.1715,
         0.1450, 0.1930, 0.1405, 0.1578, 0.1676, 0.2009, 0.1811],
        [0.1281, 0.1373, 0.0800, 0.1357, 0.1042, 0.1033, 0.1023, 0.1261, 0.1042,
         0.1013, 0.1461, 0.1261, 0.1317, 0.1553, 0.1680, 0.1522, 0.1865, 0.2088,
         0.1593, 0.1969, 0.1357, 0.1702, 0.1655, 0.2086, 0.1849],
        [0.1278, 0.1435, 0.0814, 0.1409, 0.1092, 0.1033, 0.1064, 0.1198, 0.0926,
         0.0883, 0.1502, 0.1307, 0.1255, 0.1399, 0.1529, 0.1446, 0.1692, 0.1689,
         0.2162, 0.2008, 0.1347, 0.1659, 0.1712, 0.2190, 0.1967],
        [0.1208, 0.1506, 0.0855, 0.1249, 0.1015, 0.1017, 0.0911, 0.1272, 0.0870,
         0.0862, 0.1455, 0.1162, 0.1223, 0.1438, 0.1669, 0.1486, 0.1790, 0.1684,
         0.1618, 0.2482, 0.1707, 0.1806, 0.2024, 0.2285, 0.2099],
        [0.1162, 0.1477, 0.0796, 0.1194, 0.0949, 0.0972, 0.0875, 0.1185, 0.0827,
         0.0848, 0.1333, 0.1091, 0.1192, 0.1407, 0.1724, 0.1383, 0.1811, 0.1625,
         0.1525, 0.2264, 0.2109, 0.1984, 0.2273, 0.2490, 0.2375],
        [0.1159, 0.1323, 0.0686, 0.1184, 0.0879, 0.0891, 0.0854, 0.1056, 0.0799,
         0.0806, 0.1265, 0.1172, 0.1133, 0.1372, 0.1571, 0.1343, 0.1714, 0.1702,
         0.1563, 0.2083, 0.1718, 0.2445, 0.2165, 0.2625, 0.2503],
        [0.1203, 0.1514, 0.0744, 0.1230, 0.0886, 0.0974, 0.0786, 0.1270, 0.0745,
         0.0794, 0.1395, 0.1021, 0.1091, 0.1325, 0.1617, 0.1309, 0.1708, 0.1550,
         0.1524, 0.2206, 0.1916, 0.2067, 0.2683, 0.2760, 0.2663],
        [0.1261, 0.1489, 0.0745, 0.1290, 0.0873, 0.0971, 0.0869, 0.1205, 0.0720,
         0.0772, 0.1388, 0.1082, 0.1119, 0.1278, 0.1529, 0.1329, 0.1682, 0.1621,
         0.1620, 0.2105, 0.1762, 0.2169, 0.2405, 0.3223, 0.2909],
        [0.1284, 0.1552, 0.0778, 0.1304, 0.0923, 0.0999, 0.0873, 0.1201, 0.0735,
         0.0760, 0.1373, 0.1127, 0.1088, 0.1298, 0.1588, 0.1283, 0.1650, 0.1554,
         0.1570, 0.2086, 0.1807, 0.2205, 0.2469, 0.3077, 0.3249]],
       device='cuda:0')
Fri 21 Nov 2025 06:44:23 INFO  Mean influence score: [0.22996269166469574, 0.22943218052387238, 0.22998346388339996, 0.22573207318782806, 0.22245891392230988, 0.222477525472641, 0.2197982370853424, 0.21746806800365448, 0.2176579385995865, 0.2247108817100525, 0.2198851853609085, 0.22071513533592224, 0.22030234336853027, 0.22257950901985168, 0.22147440910339355, 0.22496356070041656, 0.2230111062526703, 0.21802690625190735, 0.21896713972091675, 0.22764982283115387, 0.22605903446674347, 0.22083251178264618, 0.2214851975440979, 0.22411148250102997, 0.21839404106140137]
Fri 21 Nov 2025 06:44:23 INFO  Stage 4 selected prob: [0.04005793109536171, 0.040053676813840866, 0.04005809500813484, 0.0400240495800972, 0.039997853338718414, 0.03999800607562065, 0.0399765744805336, 0.03995794802904129, 0.03995946794748306, 0.04001587629318237, 0.03997727110981941, 0.03998391330242157, 0.039980605244636536, 0.03999881446361542, 0.039989981800317764, 0.04001789167523384, 0.04000227153301239, 0.039962418377399445, 0.03996993228793144, 0.04003940150141716, 0.04002666845917702, 0.039984848350286484, 0.03999006375670433, 0.040011074393987656, 0.03996535390615463]
Fri 21 Nov 2025 06:46:58 INFO  [Epoch 141] Train Loss: 1.8020145840741493
Fri 21 Nov 2025 06:49:35 INFO  [Epoch 142] Train Loss: 1.7992082218060623
Fri 21 Nov 2025 06:52:11 INFO  [Epoch 143] Train Loss: 1.7965596745143066
Fri 21 Nov 2025 06:54:48 INFO  [Epoch 144] Train Loss: 1.793246300927
Fri 21 Nov 2025 06:57:24 INFO  [Epoch 145] Train Loss: 1.7906923465517037
Fri 21 Nov 2025 07:00:01 INFO  [Epoch 146] Train Loss: 1.7884860588201685
Fri 21 Nov 2025 07:02:38 INFO  [Epoch 147] Train Loss: 1.7852787249451898
Fri 21 Nov 2025 07:05:15 INFO  [Epoch 148] Train Loss: 1.7828555784860634
Fri 21 Nov 2025 07:07:54 INFO  [Epoch 149] Train Loss: 1.7801201567916796
Fri 21 Nov 2025 07:10:31 INFO  [Epoch 150] Train Loss: 1.7771136374086947
Fri 21 Nov 2025 07:10:31 INFO  [Epoch 150] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_150.pth
Fri 21 Nov 2025 07:13:09 INFO  [Epoch 151] Train Loss: 1.7733190855349352
Fri 21 Nov 2025 07:15:46 INFO  [Epoch 152] Train Loss: 1.7700046024727545
Fri 21 Nov 2025 07:18:24 INFO  [Epoch 153] Train Loss: 1.767702306502114
Fri 21 Nov 2025 07:21:00 INFO  [Epoch 154] Train Loss: 1.764379180018506
Fri 21 Nov 2025 07:23:39 INFO  [Epoch 155] Train Loss: 1.7617595352836557
Fri 21 Nov 2025 07:26:18 INFO  [Epoch 156] Train Loss: 1.7575385508965342
Fri 21 Nov 2025 07:28:58 INFO  [Epoch 157] Train Loss: 1.7551714616852838
Fri 21 Nov 2025 07:31:34 INFO  [Epoch 158] Train Loss: 1.7519172384011699
Fri 21 Nov 2025 07:34:13 INFO  [Epoch 159] Train Loss: 1.7491984023895963
Fri 21 Nov 2025 07:36:50 INFO  [Epoch 160] Train Loss: 1.745335453783223
Fri 21 Nov 2025 07:36:50 INFO  [Epoch 160] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_160.pth
Fri 21 Nov 2025 07:36:50 INFO  Best epoch: 0, Best val score: -1
Fri 21 Nov 2025 07:36:51 INFO  [Epoch 161] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284.pth
Fri 21 Nov 2025 07:36:51 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Fri 21 Nov 2025 08:55:24 INFO  Influence scores: tensor([[ 1.0009e-01,  3.5920e-02,  3.7619e-02,  5.0401e-02, -1.3780e-02,
          5.9567e-03, -5.4516e-04, -5.6371e-02, -1.6880e-02, -2.7072e-02,
         -9.8080e-02, -6.8193e-02, -7.9757e-02, -7.9779e-02, -7.4314e-02,
         -5.3603e-02, -6.5070e-02, -5.1935e-02, -2.6864e-02, -7.6517e-02,
         -4.7399e-02, -6.0796e-02, -4.9842e-02,  3.5860e-03, -2.1501e-02],
        [-2.4505e-02,  1.4086e-01,  6.1148e-02, -1.4937e-02, -1.9211e-02,
          1.4341e-02, -8.2699e-03, -4.9334e-02, -4.7137e-02, -5.5925e-02,
         -1.1167e-01, -9.1777e-02, -8.8304e-02, -9.5821e-02, -6.0766e-02,
         -5.9009e-02, -6.6269e-02, -7.8663e-02, -4.1978e-02, -7.4444e-02,
         -4.2792e-02, -7.9306e-02, -4.7449e-02, -5.2149e-03, -2.3803e-02],
        [-3.8487e-02,  4.5615e-02,  9.4121e-02, -3.0306e-02, -1.6534e-02,
         -3.3433e-03, -5.0084e-03, -5.4862e-02, -2.8254e-02, -3.7079e-02,
         -1.0019e-01, -8.4246e-02, -7.8996e-02, -8.2548e-02, -6.6780e-02,
         -4.4972e-02, -5.8401e-02, -6.2498e-02, -3.1628e-02, -6.8492e-02,
         -3.9315e-02, -7.1582e-02, -5.5086e-02, -9.6696e-03, -3.1610e-02],
        [ 1.3703e-02,  9.1363e-03,  9.6348e-03,  8.2689e-02, -4.5871e-03,
          2.8749e-03,  1.1534e-02, -4.3903e-02, -1.2837e-02, -3.8726e-02,
         -9.3522e-02, -6.1066e-02, -7.0723e-02, -7.5813e-02, -6.0200e-02,
         -4.7085e-02, -5.7910e-02, -4.4756e-02, -1.2264e-02, -7.4168e-02,
         -4.5031e-02, -6.1952e-02, -4.8717e-02,  3.9294e-03, -1.9266e-02],
        [-7.0478e-02, -1.3503e-02,  4.2999e-03, -2.4698e-02,  2.2841e-02,
          5.5556e-03,  6.7982e-03, -4.1375e-02, -1.4236e-02, -3.5640e-02,
         -9.5323e-02, -6.2581e-02, -6.9655e-02, -6.9259e-02, -5.1689e-02,
         -4.3335e-02, -5.4303e-02, -5.4746e-02, -2.0965e-02, -7.1636e-02,
         -4.3394e-02, -6.7767e-02, -5.7825e-02, -1.4564e-02, -3.4777e-02],
        [-7.5769e-02, -5.4263e-03, -7.9279e-03, -4.2769e-02, -2.0011e-02,
          4.7681e-02,  2.6037e-03, -5.1010e-02, -2.5028e-02, -3.1342e-02,
         -9.6470e-02, -7.2616e-02, -7.2939e-02, -7.5020e-02, -6.2011e-02,
         -5.0696e-02, -5.9788e-02, -6.8379e-02, -4.0899e-02, -8.2395e-02,
         -5.1017e-02, -7.5364e-02, -5.6294e-02, -1.2993e-02, -3.4451e-02],
        [-8.2749e-02, -2.9876e-02, -1.1526e-02, -3.6073e-02, -2.1788e-02,
         -3.4647e-04,  5.1566e-02, -5.5617e-02, -9.9877e-03, -2.8074e-02,
         -9.7841e-02, -5.3931e-02, -5.6834e-02, -6.9286e-02, -5.3818e-02,
         -3.9823e-02, -5.1102e-02, -5.0788e-02, -1.8032e-02, -7.8280e-02,
         -4.4462e-02, -6.4035e-02, -6.3371e-02, -7.0432e-03, -3.2657e-02],
        [-1.1029e-01, -3.9603e-02, -2.9126e-02, -6.0634e-02, -3.8468e-02,
         -2.1340e-02, -2.2992e-02,  4.5019e-02, -1.9089e-02, -3.7412e-02,
         -7.7876e-02, -8.6597e-02, -5.9254e-02, -6.0806e-02, -3.2739e-02,
         -3.9546e-02, -3.9871e-02, -4.1058e-02, -2.1538e-02, -5.3234e-02,
         -2.6116e-02, -5.9581e-02, -2.2995e-02,  1.4203e-02, -1.2274e-02],
        [-1.0794e-01, -7.8759e-02, -4.2870e-02, -6.9045e-02, -5.0775e-02,
         -3.6441e-02, -1.7599e-02, -5.7036e-02,  5.0235e-02, -3.6958e-03,
         -9.2717e-02, -6.0125e-02, -5.4676e-02, -4.5881e-02, -5.1068e-02,
         -3.3298e-02, -4.0428e-02, -3.0171e-02, -1.9733e-02, -6.7644e-02,
         -3.5911e-02, -5.3527e-02, -5.2290e-02, -8.5828e-03, -3.4003e-02],
        [-1.1899e-01, -8.5975e-02, -5.1861e-02, -9.2796e-02, -6.9434e-02,
         -4.1073e-02, -3.2829e-02, -7.4179e-02, -4.1116e-03,  3.7498e-02,
         -9.0742e-02, -6.8104e-02, -5.3595e-02, -4.6335e-02, -5.9627e-02,
         -3.8136e-02, -3.9467e-02, -3.9667e-02, -2.9984e-02, -7.3666e-02,
         -3.6944e-02, -5.6733e-02, -5.0576e-02, -7.1433e-03, -3.5693e-02],
        [-1.2911e-01, -7.9587e-02, -5.2384e-02, -8.7291e-02, -6.7633e-02,
         -4.2747e-02, -4.0027e-02, -5.3514e-02, -2.9371e-02, -2.7437e-02,
         -3.0995e-02, -5.5640e-02, -5.0703e-02, -4.8679e-02, -5.6046e-02,
         -1.6450e-02, -3.1048e-02, -3.5360e-02, -3.4053e-03, -4.8198e-02,
         -2.5959e-02, -5.1916e-02, -2.5264e-02,  1.9353e-02, -9.8458e-03],
        [-1.1993e-01, -8.0828e-02, -5.8500e-02, -7.6096e-02, -5.6728e-02,
         -4.0586e-02, -1.8265e-02, -8.3434e-02, -1.6738e-02, -2.8145e-02,
         -7.7366e-02,  3.8104e-02, -4.5547e-02, -2.9768e-02, -3.5423e-02,
         -1.1974e-03, -1.9415e-02, -1.5661e-02,  1.9167e-02, -4.2390e-02,
         -1.4335e-02, -1.9195e-02, -2.9607e-02,  2.4670e-02,  4.2465e-03],
        [-1.4817e-01, -9.4890e-02, -7.0428e-02, -1.0239e-01, -8.2619e-02,
         -6.0508e-02, -4.0982e-02, -7.4804e-02, -3.2866e-02, -3.2629e-02,
         -9.2042e-02, -6.4991e-02,  3.1534e-03, -3.8533e-02, -2.4568e-02,
         -7.7828e-03, -2.8584e-03, -1.3120e-02,  7.5030e-03, -3.7591e-02,
         -1.6932e-03, -2.6886e-02, -2.2755e-02,  2.7607e-02, -2.6590e-03],
        [-1.5524e-01, -1.0989e-01, -8.1259e-02, -1.1513e-01, -8.8154e-02,
         -6.9793e-02, -5.9955e-02, -8.1818e-02, -2.8862e-02, -2.9579e-02,
         -9.7167e-02, -5.6373e-02, -4.4275e-02,  4.9509e-03, -1.7079e-02,
         -1.0106e-02, -3.6055e-03, -6.4448e-03, -7.0682e-04, -3.5430e-02,
          4.4754e-04, -2.1986e-02, -1.7879e-02,  2.1091e-02, -1.9179e-03],
        [-1.6571e-01, -9.0803e-02, -8.1724e-02, -1.1568e-01, -8.6456e-02,
         -7.1679e-02, -5.9846e-02, -7.1294e-02, -5.0548e-02, -6.0793e-02,
         -1.1814e-01, -7.6408e-02, -4.6092e-02, -3.2444e-02,  5.7571e-02,
         -1.0829e-02,  1.2675e-02, -6.1628e-04,  8.0468e-03, -1.6581e-02,
          3.2144e-02, -5.5020e-03,  8.6733e-03,  4.4195e-02,  2.6662e-02],
        [-1.6498e-01, -1.0913e-01, -7.9486e-02, -1.2095e-01, -9.7475e-02,
         -7.9872e-02, -6.5400e-02, -9.6862e-02, -5.1977e-02, -5.7678e-02,
         -9.8965e-02, -6.2695e-02, -4.9498e-02, -4.4328e-02, -2.9713e-02,
          4.4859e-02,  1.2025e-02,  6.8554e-03,  2.6619e-02, -1.0567e-02,
          1.4968e-02, -7.3898e-03, -2.4688e-03,  4.4869e-02,  1.4192e-02],
        [-1.7820e-01, -1.1875e-01, -9.4993e-02, -1.3363e-01, -1.1060e-01,
         -9.1922e-02, -7.8777e-02, -9.9501e-02, -6.1989e-02, -6.1279e-02,
         -1.1665e-01, -8.2350e-02, -4.7239e-02, -4.1095e-02, -9.8376e-03,
          8.8097e-03,  4.7423e-02,  1.8097e-02,  2.3341e-02, -3.8454e-03,
          3.8383e-02,  8.0677e-03,  1.6329e-02,  5.8778e-02,  2.9983e-02],
        [-1.6160e-01, -1.2649e-01, -9.3622e-02, -1.1650e-01, -1.0600e-01,
         -9.3822e-02, -7.2460e-02, -9.5165e-02, -4.6113e-02, -5.6057e-02,
         -1.1360e-01, -7.3262e-02, -5.2227e-02, -3.8757e-02, -1.6691e-02,
          9.8222e-03,  2.2912e-02,  7.3534e-02,  4.9553e-02,  5.6095e-03,
          3.7761e-02,  3.0265e-02,  1.9700e-02,  7.5239e-02,  4.0767e-02],
        [-1.5918e-01, -1.1400e-01, -8.7373e-02, -1.0640e-01, -9.7096e-02,
         -9.0482e-02, -6.4122e-02, -1.0029e-01, -5.8786e-02, -7.1482e-02,
         -1.0695e-01, -6.3968e-02, -5.7075e-02, -5.6624e-02, -3.1421e-02,
          4.3683e-03,  4.4825e-03,  2.5595e-02,  1.2995e-01,  1.4554e-02,
          4.0883e-02,  2.8469e-02,  3.0523e-02,  9.1064e-02,  5.8893e-02],
        [-1.7977e-01, -1.1663e-01, -9.3618e-02, -1.3791e-01, -1.1547e-01,
         -1.0196e-01, -9.3834e-02, -9.9481e-02, -7.6365e-02, -8.1802e-02,
         -1.2081e-01, -9.2862e-02, -7.0104e-02, -5.9703e-02, -2.4877e-02,
         -3.0861e-04,  9.7481e-03,  1.2746e-02,  4.6382e-02,  6.5639e-02,
          7.5882e-02,  3.7044e-02,  6.1632e-02,  9.4186e-02,  6.6102e-02],
        [-1.8342e-01, -1.1793e-01, -9.8839e-02, -1.4188e-01, -1.2120e-01,
         -1.0539e-01, -9.4571e-02, -1.0720e-01, -7.9469e-02, -8.0648e-02,
         -1.3306e-01, -9.7928e-02, -6.9187e-02, -5.9426e-02, -1.3219e-02,
         -1.0647e-02,  1.5982e-02,  9.5406e-03,  3.7557e-02,  4.1417e-02,
          1.3229e-01,  6.5720e-02,  9.7558e-02,  1.2474e-01,  1.0492e-01],
        [-1.7344e-01, -1.3011e-01, -1.0543e-01, -1.3581e-01, -1.2343e-01,
         -1.0746e-01, -9.0269e-02, -1.1826e-01, -7.4892e-02, -7.8178e-02,
         -1.3540e-01, -8.1019e-02, -7.1517e-02, -5.9595e-02, -2.7805e-02,
         -9.5111e-03,  8.5620e-03,  2.6158e-02,  4.9815e-02,  2.5880e-02,
          8.9458e-02,  1.3031e-01,  9.0908e-02,  1.4924e-01,  1.2888e-01],
        [-1.8106e-01, -1.1653e-01, -1.0746e-01, -1.4149e-01, -1.3092e-01,
         -1.0580e-01, -1.0766e-01, -9.8921e-02, -9.1702e-02, -8.8920e-02,
         -1.2634e-01, -1.0892e-01, -8.4369e-02, -7.3214e-02, -3.0084e-02,
         -2.1416e-02,  2.4482e-05, -3.1290e-03,  3.5062e-02,  3.2561e-02,
          1.0341e-01,  7.2621e-02,  1.4750e-01,  1.5665e-01,  1.3904e-01],
        [-1.7103e-01, -1.1785e-01, -1.0602e-01, -1.3200e-01, -1.3294e-01,
         -1.0678e-01, -9.7032e-02, -1.0853e-01, -9.3460e-02, -9.1597e-02,
         -1.2828e-01, -1.0025e-01, -8.0613e-02, -7.9409e-02, -4.0382e-02,
         -1.9490e-02, -4.1130e-03,  7.7935e-03,  4.9279e-02,  2.0670e-02,
          8.5936e-02,  8.5816e-02,  1.1103e-01,  2.1385e-01,  1.6685e-01],
        [-1.6537e-01, -1.0809e-01, -1.0008e-01, -1.2638e-01, -1.2502e-01,
         -1.0052e-01, -9.4359e-02, -1.0709e-01, -8.9977e-02, -9.1482e-02,
         -1.2875e-01, -9.1161e-02, -8.1923e-02, -7.4196e-02, -2.9101e-02,
         -2.2471e-02, -4.4289e-03,  2.3603e-03,  4.6144e-02,  2.0962e-02,
          9.4663e-02,  9.5448e-02,  1.2272e-01,  1.9651e-01,  2.1532e-01]],
       device='cuda:0')
Fri 21 Nov 2025 08:55:24 INFO  Mean influence score: [0.22030183672904968, 0.21944019198417664, 0.2199859619140625, 0.2162223905324936, 0.21272365748882294, 0.21252094209194183, 0.21011215448379517, 0.20794707536697388, 0.2079201638698578, 0.2144627571105957, 0.2100863754749298, 0.21126727759838104, 0.2105501890182495, 0.21264025568962097, 0.2117774486541748, 0.21499677002429962, 0.21309256553649902, 0.20856857299804688, 0.20956428349018097, 0.21768562495708466, 0.2163206934928894, 0.21138037741184235, 0.21184758841991425, 0.21446917951107025, 0.2091469168663025]
Fri 21 Nov 2025 08:55:24 INFO  Stage 5 selected prob: [0.040058434009552, 0.04005153477191925, 0.040055904537439346, 0.04002576693892479, 0.03999776765704155, 0.03999614715576172, 0.039976879954338074, 0.03995957598090172, 0.039959363639354706, 0.040011681616306305, 0.03997667878866196, 0.03998611494898796, 0.039980385452508926, 0.039997100830078125, 0.039990201592445374, 0.04001595452427864, 0.04000071436166763, 0.039964545518159866, 0.03997250273823738, 0.040037479251623154, 0.040026552975177765, 0.03998702019453049, 0.03999076038599014, 0.04001173749566078, 0.03996916860342026]
Fri 21 Nov 2025 08:58:00 INFO  [Epoch 161] Train Loss: 1.7423206881321536
Fri 21 Nov 2025 09:00:37 INFO  [Epoch 162] Train Loss: 1.7393296207355256
Fri 21 Nov 2025 09:03:14 INFO  [Epoch 163] Train Loss: 1.736036949118592
Fri 21 Nov 2025 09:05:51 INFO  [Epoch 164] Train Loss: 1.733152773274418
Fri 21 Nov 2025 09:08:23 INFO  [Epoch 165] Train Loss: 1.7293464905046587
Fri 21 Nov 2025 09:11:01 INFO  [Epoch 166] Train Loss: 1.7257792750610808
Fri 21 Nov 2025 09:13:41 INFO  [Epoch 167] Train Loss: 1.7230115563943118
Fri 21 Nov 2025 09:16:22 INFO  [Epoch 168] Train Loss: 1.719526906443839
Fri 21 Nov 2025 09:19:05 INFO  [Epoch 169] Train Loss: 1.7160825841560328
Fri 21 Nov 2025 09:21:46 INFO  [Epoch 170] Train Loss: 1.7121642880343102
Fri 21 Nov 2025 09:21:46 INFO  [Epoch 170] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_170.pth
Fri 21 Nov 2025 09:24:25 INFO  [Epoch 171] Train Loss: 1.709079669536771
Fri 21 Nov 2025 09:27:03 INFO  [Epoch 172] Train Loss: 1.7058357254073426
Fri 21 Nov 2025 09:29:41 INFO  [Epoch 173] Train Loss: 1.7024085541834701
Fri 21 Nov 2025 09:32:21 INFO  [Epoch 174] Train Loss: 1.699342306228678
Fri 21 Nov 2025 09:35:03 INFO  [Epoch 175] Train Loss: 1.6962737758072186
Fri 21 Nov 2025 09:37:42 INFO  [Epoch 176] Train Loss: 1.6929679823658181
Fri 21 Nov 2025 09:40:24 INFO  [Epoch 177] Train Loss: 1.6897056548061518
Fri 21 Nov 2025 09:43:04 INFO  [Epoch 178] Train Loss: 1.686476207953162
Fri 21 Nov 2025 09:45:38 INFO  [Epoch 179] Train Loss: 1.6841599458548093
Fri 21 Nov 2025 09:48:12 INFO  [Epoch 180] Train Loss: 1.6804999873674975
Fri 21 Nov 2025 09:48:13 INFO  [Epoch 180] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_180.pth
Fri 21 Nov 2025 09:48:13 INFO  Best epoch: 0, Best val score: -1
Fri 21 Nov 2025 09:48:13 INFO  [Epoch 181] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284.pth
Fri 21 Nov 2025 09:48:13 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Fri 21 Nov 2025 11:06:26 INFO  Influence scores: tensor([[ 3.8501e-01,  1.9930e-01,  1.7084e-01,  2.7420e-01,  1.5224e-01,
          1.6217e-01,  2.4922e-01,  1.2037e-01,  1.3994e-01,  2.1779e-01,
          1.7721e-01,  2.4702e-01,  1.6376e-01,  1.3079e-01,  6.5551e-02,
          1.1410e-01,  1.1375e-01,  7.4022e-02,  8.9966e-02,  7.7188e-02,
          1.8130e-01,  1.4364e-01,  1.1247e-01,  1.5207e-01,  1.2562e-01],
        [ 2.1736e-01,  3.2416e-01,  1.9317e-01,  1.8422e-01,  1.3895e-01,
          1.6666e-01,  2.3196e-01,  1.2589e-01,  9.3291e-02,  1.7309e-01,
          1.5309e-01,  2.0833e-01,  1.4756e-01,  1.0418e-01,  7.8188e-02,
          9.7342e-02,  1.0423e-01,  2.8064e-02,  5.8480e-02,  7.1279e-02,
          1.7719e-01,  1.0977e-01,  1.0750e-01,  1.3266e-01,  1.1404e-01],
        [ 1.9791e-01,  1.9812e-01,  2.2863e-01,  1.6012e-01,  1.3652e-01,
          1.3889e-01,  2.3018e-01,  1.1252e-01,  1.1241e-01,  1.9149e-01,
          1.6290e-01,  2.1267e-01,  1.5174e-01,  1.1475e-01,  6.2440e-02,
          1.1012e-01,  1.0794e-01,  4.4567e-02,  6.7752e-02,  7.4389e-02,
          1.7626e-01,  1.1501e-01,  9.2910e-02,  1.2298e-01,  9.7765e-02],
        [ 2.6690e-01,  1.5503e-01,  1.2591e-01,  3.0851e-01,  1.5618e-01,
          1.4847e-01,  2.5701e-01,  1.3065e-01,  1.3880e-01,  1.9343e-01,
          1.7572e-01,  2.4850e-01,  1.6872e-01,  1.2815e-01,  7.5354e-02,
          1.1367e-01,  1.1445e-01,  7.5299e-02,  1.0081e-01,  7.3838e-02,
          1.7497e-01,  1.3428e-01,  1.0489e-01,  1.4546e-01,  1.1882e-01],
        [ 1.5549e-01,  1.2074e-01,  1.1338e-01,  1.6750e-01,  1.8829e-01,
          1.5061e-01,  2.4588e-01,  1.3207e-01,  1.3263e-01,  1.9469e-01,
          1.7230e-01,  2.4306e-01,  1.6633e-01,  1.3341e-01,  8.4601e-02,
          1.1517e-01,  1.1569e-01,  5.7803e-02,  8.3204e-02,  7.2669e-02,
          1.7342e-01,  1.2039e-01,  9.0947e-02,  1.1733e-01,  9.3988e-02],
        [ 1.4938e-01,  1.3261e-01,  9.9387e-02,  1.4308e-01,  1.3402e-01,
          2.0393e-01,  2.3899e-01,  1.1880e-01,  1.1770e-01,  1.9995e-01,
          1.6919e-01,  2.3055e-01,  1.6124e-01,  1.2509e-01,  7.1445e-02,
          1.0577e-01,  1.0775e-01,  3.9774e-02,  5.7476e-02,  5.8250e-02,
          1.6467e-01,  1.0966e-01,  9.1118e-02,  1.1793e-01,  9.3093e-02],
        [ 1.4302e-01,  1.0402e-01,  9.7514e-02,  1.5690e-01,  1.3555e-01,
          1.4550e-01,  3.0537e-01,  1.1814e-01,  1.3969e-01,  2.0777e-01,
          1.7164e-01,  2.5613e-01,  1.8497e-01,  1.3541e-01,  8.6306e-02,
          1.2213e-01,  1.2246e-01,  6.5477e-02,  9.0581e-02,  6.6477e-02,
          1.7409e-01,  1.2794e-01,  8.6488e-02,  1.3031e-01,  9.7807e-02],
        [ 1.0123e-01,  8.5483e-02,  6.9369e-02,  1.1880e-01,  1.0901e-01,
          1.1254e-01,  2.0508e-01,  2.3745e-01,  1.2448e-01,  1.8840e-01,
          1.8900e-01,  2.0726e-01,  1.7721e-01,  1.3919e-01,  1.0491e-01,
          1.1683e-01,  1.2940e-01,  6.9737e-02,  7.9630e-02,  9.2819e-02,
          1.8949e-01,  1.2575e-01,  1.3039e-01,  1.4867e-01,  1.1734e-01],
        [ 1.2023e-01,  4.5124e-02,  6.2929e-02,  1.2186e-01,  1.0657e-01,
          1.0682e-01,  2.2322e-01,  1.2057e-01,  2.2534e-01,  2.4531e-01,
          1.8427e-01,  2.5738e-01,  1.9312e-01,  1.7402e-01,  9.6171e-02,
          1.3871e-01,  1.4341e-01,  1.0060e-01,  9.5957e-02,  8.9329e-02,
          1.9415e-01,  1.4861e-01,  1.0793e-01,  1.3277e-01,  1.0290e-01],
        [ 1.0294e-01,  3.2702e-02,  4.7341e-02,  8.3734e-02,  7.4674e-02,
          9.4541e-02,  1.9834e-01,  9.0775e-02,  1.4972e-01,  2.9261e-01,
          1.7969e-01,  2.4064e-01,  1.8744e-01,  1.6565e-01,  7.5670e-02,
          1.2612e-01,  1.3739e-01,  8.1638e-02,  7.6629e-02,  7.5207e-02,
          1.8583e-01,  1.3931e-01,  1.0362e-01,  1.2824e-01,  9.4667e-02],
        [ 8.1884e-02,  3.4490e-02,  4.1236e-02,  8.6650e-02,  7.1830e-02,
          8.5215e-02,  1.8233e-01,  1.1134e-01,  1.1166e-01,  2.0187e-01,
          2.4701e-01,  2.4802e-01,  1.8565e-01,  1.5309e-01,  7.3290e-02,
          1.4523e-01,  1.3931e-01,  7.9431e-02,  1.0241e-01,  9.8915e-02,
          1.9111e-01,  1.3804e-01,  1.2739e-01,  1.5530e-01,  1.2003e-01],
        [ 8.9192e-02,  2.6713e-02,  2.8061e-02,  9.8460e-02,  8.1198e-02,
          8.5614e-02,  2.0667e-01,  6.9456e-02,  1.2364e-01,  1.9916e-01,
          1.8498e-01,  3.6135e-01,  1.8938e-01,  1.7432e-01,  9.6177e-02,
          1.6037e-01,  1.5239e-01,  1.0084e-01,  1.2378e-01,  1.0056e-01,
          2.0234e-01,  1.7566e-01,  1.1968e-01,  1.5816e-01,  1.3549e-01],
        [ 5.0854e-02,  1.0758e-02,  1.1455e-02,  6.0629e-02,  4.7528e-02,
          5.7837e-02,  1.7546e-01,  8.0929e-02,  1.0141e-01,  1.8978e-01,
          1.6594e-01,  2.2859e-01,  2.4689e-01,  1.6063e-01,  1.0919e-01,
          1.5171e-01,  1.7043e-01,  9.9367e-02,  1.0958e-01,  1.0587e-01,
          2.1480e-01,  1.6089e-01,  1.2648e-01,  1.6025e-01,  1.2374e-01],
        [ 4.3591e-02, -7.9136e-03, -1.6728e-04,  4.7234e-02,  4.1310e-02,
          4.8933e-02,  1.5339e-01,  7.1557e-02,  1.0987e-01,  1.9738e-01,
          1.6095e-01,  2.4299e-01,  1.8907e-01,  2.1820e-01,  1.1915e-01,
          1.4952e-01,  1.7023e-01,  1.1113e-01,  9.9596e-02,  1.0891e-01,
          2.1958e-01,  1.7126e-01,  1.3419e-01,  1.5323e-01,  1.2702e-01],
        [ 3.5836e-02,  2.3889e-02,  6.4940e-03,  5.3494e-02,  5.2494e-02,
          5.3491e-02,  1.6137e-01,  9.5009e-02,  9.0366e-02,  1.6408e-01,
          1.4108e-01,  2.2220e-01,  1.9448e-01,  1.7771e-01,  2.2425e-01,
          1.5467e-01,  1.9706e-01,  1.2328e-01,  1.1559e-01,  1.3955e-01,
          2.6536e-01,  1.9495e-01,  1.7374e-01,  1.8701e-01,  1.6882e-01],
        [ 2.8600e-02, -1.1072e-02, -2.9948e-03,  3.5838e-02,  2.5444e-02,
          3.0243e-02,  1.4155e-01,  4.9835e-02,  7.5746e-02,  1.5689e-01,
          1.5275e-01,  2.3054e-01,  1.7927e-01,  1.5015e-01,  9.9161e-02,
          2.1402e-01,  1.8680e-01,  1.2566e-01,  1.3025e-01,  1.3982e-01,
          2.3471e-01,  1.8725e-01,  1.4988e-01,  1.8150e-01,  1.4380e-01],
        [ 1.6874e-02, -1.8029e-02, -1.6032e-02,  2.4916e-02,  1.4217e-02,
          2.2212e-02,  1.3028e-01,  5.1508e-02,  6.9646e-02,  1.5857e-01,
          1.3752e-01,  2.1001e-01,  1.8644e-01,  1.5951e-01,  1.2961e-01,
          1.7543e-01,  2.3602e-01,  1.4376e-01,  1.3162e-01,  1.5241e-01,
          2.6889e-01,  2.1095e-01,  1.7970e-01,  2.0265e-01,  1.6887e-01],
        [ 4.6664e-02, -2.1623e-02, -8.9710e-03,  5.4334e-02,  2.7371e-02,
          2.6213e-02,  1.4454e-01,  6.1025e-02,  9.5359e-02,  1.7119e-01,
          1.4602e-01,  2.2901e-01,  1.8531e-01,  1.6904e-01,  1.2505e-01,
          1.8240e-01,  2.1158e-01,  2.1853e-01,  1.6903e-01,  1.6962e-01,
          2.7235e-01,  2.4439e-01,  1.8740e-01,  2.2783e-01,  1.8813e-01],
        [ 4.6594e-02, -1.0340e-02, -3.8840e-03,  6.5690e-02,  3.4854e-02,
          2.6544e-02,  1.5216e-01,  5.3497e-02,  7.5207e-02,  1.4789e-01,
          1.5291e-01,  2.3573e-01,  1.7837e-01,  1.4171e-01,  1.0162e-01,
          1.7123e-01,  1.8582e-01,  1.5506e-01,  2.6674e-01,  1.7839e-01,
          2.7268e-01,  2.3979e-01,  1.9928e-01,  2.4690e-01,  2.0914e-01],
        [ 1.7707e-02, -1.2779e-02, -1.1180e-02,  2.2025e-02,  1.0641e-02,
          1.1565e-02,  1.1343e-01,  5.3884e-02,  5.2492e-02,  1.3290e-01,
          1.3361e-01,  1.9837e-01,  1.6137e-01,  1.3866e-01,  1.1236e-01,
          1.6553e-01,  1.9169e-01,  1.3895e-01,  1.6317e-01,  2.4211e-01,
          3.1911e-01,  2.4982e-01,  2.3829e-01,  2.4943e-01,  2.1874e-01],
        [ 1.0013e-02, -1.5059e-02, -1.8276e-02,  1.5495e-02,  3.0250e-03,
          7.2045e-03,  1.1181e-01,  4.2243e-02,  4.8183e-02,  1.3417e-01,
          1.1580e-01,  1.9109e-01,  1.6023e-01,  1.3763e-01,  1.2697e-01,
          1.5078e-01,  1.9761e-01,  1.3243e-01,  1.4998e-01,  2.0771e-01,
          3.8580e-01,  2.8218e-01,  2.7969e-01,  2.8400e-01,  2.6533e-01],
        [ 3.1874e-02, -2.4892e-02, -2.2160e-02,  3.2126e-02,  6.1235e-03,
          1.0365e-02,  1.2490e-01,  3.5179e-02,  6.0946e-02,  1.4392e-01,
          1.2054e-01,  2.2023e-01,  1.6389e-01,  1.4624e-01,  1.1542e-01,
          1.6017e-01,  1.9772e-01,  1.6227e-01,  1.7262e-01,  1.9725e-01,
          3.4074e-01,  3.7203e-01,  2.7832e-01,  3.2256e-01,  3.0200e-01],
        [ 1.5169e-02, -1.3224e-02, -2.8520e-02,  1.6959e-02, -8.9661e-03,
          6.2449e-03,  9.6167e-02,  5.2929e-02,  3.3014e-02,  1.2346e-01,
          1.2504e-01,  1.7790e-01,  1.4266e-01,  1.2266e-01,  1.0539e-01,
          1.3850e-01,  1.7974e-01,  1.1775e-01,  1.4823e-01,  1.9935e-01,
          3.5333e-01,  2.9171e-01,  3.4343e-01,  3.2477e-01,  3.0914e-01],
        [ 3.7425e-02, -5.9520e-03, -1.8863e-02,  3.8374e-02, -2.9370e-03,
          1.2537e-02,  1.1948e-01,  5.0897e-02,  3.9213e-02,  1.2905e-01,
          1.3181e-01,  1.9656e-01,  1.5663e-01,  1.2237e-01,  1.0034e-01,
          1.5013e-01,  1.8431e-01,  1.3988e-01,  1.7457e-01,  1.9270e-01,
          3.3839e-01,  3.1816e-01,  3.0645e-01,  4.0712e-01,  3.5434e-01],
        [ 4.3943e-02,  9.1249e-03, -9.6003e-03,  4.6254e-02,  9.0946e-03,
          2.3485e-02,  1.2395e-01,  5.5093e-02,  4.6257e-02,  1.3134e-01,
          1.3408e-01,  2.1130e-01,  1.5638e-01,  1.3288e-01,  1.1800e-01,
          1.4817e-01,  1.8636e-01,  1.3613e-01,  1.7254e-01,  1.9445e-01,
          3.5382e-01,  3.3267e-01,  3.2478e-01,  3.8790e-01,  4.2267e-01]],
       device='cuda:0')
Fri 21 Nov 2025 11:06:26 INFO  Mean influence score: [0.21974590420722961, 0.2187034785747528, 0.21919876337051392, 0.21562716364860535, 0.21201299130916595, 0.21173621714115143, 0.20943766832351685, 0.20725436508655548, 0.20729126036167145, 0.21363097429275513, 0.20931404829025269, 0.21057121455669403, 0.20973873138427734, 0.21179355680942535, 0.21106620132923126, 0.214110866189003, 0.21226710081100464, 0.2079276442527771, 0.2089145928621292, 0.21687889099121094, 0.21556256711483002, 0.21076911687850952, 0.21111920475959778, 0.2138296514749527, 0.20864036679267883]
Fri 21 Nov 2025 11:06:26 INFO  Stage 6 selected prob: [0.04005971550941467, 0.04005136340856552, 0.04005533456802368, 0.04002673551440239, 0.03999780863523483, 0.03999559208750725, 0.03997721150517464, 0.03995975852012634, 0.03996005654335022, 0.040010757744312286, 0.039976224303245544, 0.039986275136470795, 0.03997962176799774, 0.03999605402350426, 0.03999023139476776, 0.0400145947933197, 0.039999838918447495, 0.03996513783931732, 0.03997303172945976, 0.040036752820014954, 0.040026213973760605, 0.03998786211013794, 0.03999066352844238, 0.04001234471797943, 0.03997083753347397]
Fri 21 Nov 2025 11:09:04 INFO  [Epoch 181] Train Loss: 1.6777075163761161
Fri 21 Nov 2025 11:11:38 INFO  [Epoch 182] Train Loss: 1.6754953693814258
Fri 21 Nov 2025 11:14:12 INFO  [Epoch 183] Train Loss: 1.6722786130822302
Fri 21 Nov 2025 11:16:44 INFO  [Epoch 184] Train Loss: 1.6696336889589154
Fri 21 Nov 2025 11:19:19 INFO  [Epoch 185] Train Loss: 1.6681746488947666
Fri 21 Nov 2025 11:21:57 INFO  [Epoch 186] Train Loss: 1.6650677628268606
Fri 21 Nov 2025 11:24:34 INFO  [Epoch 187] Train Loss: 1.6628917211731429
Fri 21 Nov 2025 11:27:09 INFO  [Epoch 188] Train Loss: 1.6608135823347394
Fri 21 Nov 2025 11:29:44 INFO  [Epoch 189] Train Loss: 1.658657419980723
Fri 21 Nov 2025 11:32:19 INFO  [Epoch 190] Train Loss: 1.6573441684476198
Fri 21 Nov 2025 11:32:19 INFO  [Epoch 190] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_190.pth
Fri 21 Nov 2025 11:34:54 INFO  [Epoch 191] Train Loss: 1.6556702415570328
Fri 21 Nov 2025 11:37:26 INFO  [Epoch 192] Train Loss: 1.6547020096116085
Fri 21 Nov 2025 11:39:59 INFO  [Epoch 193] Train Loss: 1.652698085172296
Fri 21 Nov 2025 11:42:35 INFO  [Epoch 194] Train Loss: 1.6524805199915837
Fri 21 Nov 2025 11:45:12 INFO  [Epoch 195] Train Loss: 1.6513102273798357
Fri 21 Nov 2025 11:47:49 INFO  [Epoch 196] Train Loss: 1.6504656016021162
Fri 21 Nov 2025 11:50:25 INFO  [Epoch 197] Train Loss: 1.6504236379185238
Fri 21 Nov 2025 11:52:58 INFO  [Epoch 198] Train Loss: 1.6500783764602596
Fri 21 Nov 2025 11:55:32 INFO  [Epoch 199] Train Loss: 1.6494340640582634
Fri 21 Nov 2025 11:58:06 INFO  [Epoch 200] Train Loss: 1.6493810350255156
Fri 21 Nov 2025 11:58:06 INFO  [Epoch 200] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284_200.pth
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val Results: OrderedDict([('ndcg@5', np.float64(0.03909375742077827)), ('ndcg@10', np.float64(0.0495757982134819)), ('recall@5', np.float64(0.059705366790294645)), ('recall@10', np.float64(0.09232646048069))])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_0 Results: OrderedDict([('ndcg@5', 0.03513435646891594), ('ndcg@10', 0.04427438601851463), ('recall@5', 0.05368185415863991), ('recall@10', 0.08218484371900558)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_1 Results: OrderedDict([('ndcg@5', 0.03587887063622475), ('ndcg@10', 0.045104146003723145), ('recall@5', 0.054652709513902664), ('recall@10', 0.08337730169296265)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_2 Results: OrderedDict([('ndcg@5', 0.037464920431375504), ('ndcg@10', 0.04722808301448822), ('recall@5', 0.057354215532541275), ('recall@10', 0.08776725083589554)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_3 Results: OrderedDict([('ndcg@5', 0.03723188862204552), ('ndcg@10', 0.04721841216087341), ('recall@5', 0.05718537047505379), ('recall@10', 0.0882737785577774)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_4 Results: OrderedDict([('ndcg@5', 0.03970245271921158), ('ndcg@10', 0.05013837665319443), ('recall@5', 0.06087883189320564), ('recall@10', 0.09340241551399231)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_5 Results: OrderedDict([('ndcg@5', 0.03925347328186035), ('ndcg@10', 0.04965793713927269), ('recall@5', 0.05986576899886131), ('recall@10', 0.09222050756216049)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_6 Results: OrderedDict([('ndcg@5', 0.04001354053616524), ('ndcg@10', 0.05072358623147011), ('recall@5', 0.06135370582342148), ('recall@10', 0.09473206847906113)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_7 Results: OrderedDict([('ndcg@5', 0.04005276784300804), ('ndcg@10', 0.05051753297448158), ('recall@5', 0.061163756996393204), ('recall@10', 0.09369789808988571)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_8 Results: OrderedDict([('ndcg@5', 0.04102271795272827), ('ndcg@10', 0.05171394348144531), ('recall@5', 0.06291551142930984), ('recall@10', 0.09617779403924942)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_9 Results: OrderedDict([('ndcg@5', 0.04042939469218254), ('ndcg@10', 0.05124473199248314), ('recall@5', 0.061796922236680984), ('recall@10', 0.09544965624809265)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_10 Results: OrderedDict([('ndcg@5', 0.0415339395403862), ('ndcg@10', 0.05259149894118309), ('recall@5', 0.06378083676099777), ('recall@10', 0.09822502732276917)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_11 Results: OrderedDict([('ndcg@5', 0.040158890187740326), ('ndcg@10', 0.05089598894119263), ('recall@5', 0.06159641966223717), ('recall@10', 0.09502754360437393)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_12 Results: OrderedDict([('ndcg@5', 0.0418582521378994), ('ndcg@10', 0.05299215391278267), ('recall@5', 0.06423460692167282), ('recall@10', 0.09890040010213852)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_13 Results: OrderedDict([('ndcg@5', 0.04156964644789696), ('ndcg@10', 0.052688803523778915), ('recall@5', 0.06356978416442871), ('recall@10', 0.09814060479402542)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_14 Results: OrderedDict([('ndcg@5', 0.04067336395382881), ('ndcg@10', 0.051712073385715485), ('recall@5', 0.06210295110940933), ('recall@10', 0.0963677391409874)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_15 Results: OrderedDict([('ndcg@5', 0.041662707924842834), ('ndcg@10', 0.052729181945323944), ('recall@5', 0.06390747427940369), ('recall@10', 0.09835165739059448)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_16 Results: OrderedDict([('ndcg@5', 0.04089627414941788), ('ndcg@10', 0.0522705502808094), ('recall@5', 0.06220848113298416), ('recall@10', 0.09758131206035614)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_17 Results: OrderedDict([('ndcg@5', 0.039917781949043274), ('ndcg@10', 0.0508396215736866), ('recall@5', 0.061068784445524216), ('recall@10', 0.09502754360437393)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_18 Results: OrderedDict([('ndcg@5', 0.03893128037452698), ('ndcg@10', 0.04953794553875923), ('recall@5', 0.05940144881606102), ('recall@10', 0.09239991009235382)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_19 Results: OrderedDict([('ndcg@5', 0.03922303393483162), ('ndcg@10', 0.050016894936561584), ('recall@5', 0.05986576899886131), ('recall@10', 0.09343408048152924)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_20 Results: OrderedDict([('ndcg@5', 0.03833857923746109), ('ndcg@10', 0.04901522025465965), ('recall@5', 0.05813511833548546), ('recall@10', 0.0913657397031784)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_21 Results: OrderedDict([('ndcg@5', 0.03703602775931358), ('ndcg@10', 0.04725652560591698), ('recall@5', 0.05624617636203766), ('recall@10', 0.08803106844425201)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_22 Results: OrderedDict([('ndcg@5', 0.03706647828221321), ('ndcg@10', 0.04730808362364769), ('recall@5', 0.05621451511979103), ('recall@10', 0.08808383345603943)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_23 Results: OrderedDict([('ndcg@5', 0.03656552731990814), ('ndcg@10', 0.046411365270614624), ('recall@5', 0.05537029728293419), ('recall@10', 0.0860154926776886)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Val_24 Results: OrderedDict([('ndcg@5', 0.03572776913642883), ('ndcg@10', 0.045307911932468414), ('recall@5', 0.05408285930752754), ('recall@10', 0.08392604440450668)])
Fri 21 Nov 2025 12:47:02 INFO  [Epoch 200] Saved model checkpoint to ckpt/Video_Games/Nov-20-2025_18-46-8bf284/Nov-20-2025_18-46-8bf284.pth
Fri 21 Nov 2025 12:47:02 INFO  Best epoch: 200, Best val score: 0.0495757982134819
