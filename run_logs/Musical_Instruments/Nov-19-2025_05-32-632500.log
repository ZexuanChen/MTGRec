Wed 19 Nov 2025 05:32:44 INFO  Device: cuda
Wed 19 Nov 2025 05:32:44 INFO  Config: {'rand_seed': 2024, 'reproducibility': True, 'num_proc': 1, 'data_dir': 'datasets/Musical_Instruments', 'log_dir': 'run_logs/', 'tensorboard_log_dir': 'tensorboard/', 'ckpt_dir': 'ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8', 'stage': 'pretrain', 'pretrained_model': '', 'epoch_per_stage': [60, 20, 20, 20, 20, 20, 20], 'tau': 1.0, 'load_best_for_next_stage': False, 'train_batch_size': 256, 'eval_batch_size': 256, 'lr': 0.005, 'weight_decay': 0.05, 'warmup_steps': 10000, 'steps': None, 'epochs': 200, 'max_grad_norm': 1.0, 'eval_interval': 1, 'save_interval': 10, 'patience': 50, 'topk': [5, 10], 'metrics': ['ndcg', 'recall'], 'val_metric': 'ndcg@10', 'val_ratio': 1.0, 'val_delay': 199, 'n_codebooks': 3, 'codebook_size': 256, 'expand_final': True, 'token_prefix': 'rqvae/sentence-t5-base_256,256,256,256', 'token_suffix': 'sem_ids', 'n_user_tokens': 1, 'max_item_seq_len': 20, 'num_beams': 20, 'test_num_beams': None, 'num_layers': 6, 'num_decoder_layers': 6, 'd_model': 128, 'd_ff': 512, 'num_heads': 4, 'd_kv': 64, 'dropout_rate': 0.1, 'activation_function': 'relu', 'feed_forward_proj': 'relu', 'results_dir': None, 'sem_id_epochs': [9976, 9977, 9978, 9979, 9980, 9981, 9982, 9983, 9984, 9985, 9986, 9987, 9988, 9989, 9990, 9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 'run_local_time': 'Nov-19-2025_05-32', 'ckpt_name': 'Nov-19-2025_05-32-b9dbc8', 'dataset': 'Musical_Instruments', 'device': device(type='cuda'), 'use_ddp': False, 'accelerator': <accelerate.accelerator.Accelerator object at 0x7bdd98bab9d0>}
Wed 19 Nov 2025 05:32:44 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9976.sem_ids...
Wed 19 Nov 2025 05:32:44 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9977.sem_ids...
Wed 19 Nov 2025 05:32:44 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9978.sem_ids...
Wed 19 Nov 2025 05:32:44 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9979.sem_ids...
Wed 19 Nov 2025 05:32:44 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9980.sem_ids...
Wed 19 Nov 2025 05:32:44 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9981.sem_ids...
Wed 19 Nov 2025 05:32:44 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9982.sem_ids...
Wed 19 Nov 2025 05:32:45 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9983.sem_ids...
Wed 19 Nov 2025 05:32:45 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9984.sem_ids...
Wed 19 Nov 2025 05:32:45 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9985.sem_ids...
Wed 19 Nov 2025 05:32:45 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9986.sem_ids...
Wed 19 Nov 2025 05:32:45 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9987.sem_ids...
Wed 19 Nov 2025 05:32:45 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9988.sem_ids...
Wed 19 Nov 2025 05:32:45 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9989.sem_ids...
Wed 19 Nov 2025 05:32:45 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9990.sem_ids...
Wed 19 Nov 2025 05:32:46 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9991.sem_ids...
Wed 19 Nov 2025 05:32:46 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9992.sem_ids...
Wed 19 Nov 2025 05:32:46 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9993.sem_ids...
Wed 19 Nov 2025 05:32:46 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9994.sem_ids...
Wed 19 Nov 2025 05:32:46 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9995.sem_ids...
Wed 19 Nov 2025 05:32:46 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9996.sem_ids...
Wed 19 Nov 2025 05:32:46 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9997.sem_ids...
Wed 19 Nov 2025 05:32:46 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9998.sem_ids...
Wed 19 Nov 2025 05:32:46 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9999.sem_ids...
Wed 19 Nov 2025 05:32:47 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_10000.sem_ids...
Wed 19 Nov 2025 05:32:49 INFO  MTGRec(
  (t5): T5ForConditionalGeneration(
    (shared): Embedding(1027, 128)
    (encoder): T5Stack(
      (embed_tokens): Embedding(1027, 128)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
                (relative_attention_bias): Embedding(32, 4)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-5): 5 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (decoder): T5Stack(
      (embed_tokens): Embedding(1027, 128)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
                (relative_attention_bias): Embedding(32, 4)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerCrossAttention(
              (EncDecAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-5): 5 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerCrossAttention(
              (EncDecAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (lm_head): Linear(in_features=128, out_features=1027, bias=False)
  )
)
Wed 19 Nov 2025 05:32:49 INFO  #Embedding parameters: 131456
#Non-embedding parameters: 3936512
#Total trainable parameters: 4067968

Wed 19 Nov 2025 05:34:16 INFO  [Epoch 1] Train Loss: 3.720107695170606
Wed 19 Nov 2025 05:35:40 INFO  [Epoch 2] Train Loss: 2.747522684534241
Wed 19 Nov 2025 05:37:07 INFO  [Epoch 3] Train Loss: 2.5393304912866106
Wed 19 Nov 2025 05:38:34 INFO  [Epoch 4] Train Loss: 2.4170190838826
Wed 19 Nov 2025 05:39:59 INFO  [Epoch 5] Train Loss: 2.3448485541181987
Wed 19 Nov 2025 05:41:24 INFO  [Epoch 6] Train Loss: 2.3182473964231214
Wed 19 Nov 2025 05:42:45 INFO  [Epoch 7] Train Loss: 2.2942707725458784
Wed 19 Nov 2025 05:44:10 INFO  [Epoch 8] Train Loss: 2.270003493782624
Wed 19 Nov 2025 05:45:34 INFO  [Epoch 9] Train Loss: 2.2443644752516816
Wed 19 Nov 2025 05:46:59 INFO  [Epoch 10] Train Loss: 2.2178103133261247
Wed 19 Nov 2025 05:46:59 INFO  [Epoch 10] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_10.pth
Wed 19 Nov 2025 05:48:24 INFO  [Epoch 11] Train Loss: 2.204419012076889
Wed 19 Nov 2025 05:49:47 INFO  [Epoch 12] Train Loss: 2.1905502663937924
Wed 19 Nov 2025 05:51:12 INFO  [Epoch 13] Train Loss: 2.1799560284919997
Wed 19 Nov 2025 05:52:35 INFO  [Epoch 14] Train Loss: 2.1708927910940576
Wed 19 Nov 2025 05:54:01 INFO  [Epoch 15] Train Loss: 2.165569611752761
Wed 19 Nov 2025 05:55:26 INFO  [Epoch 16] Train Loss: 2.1578013302243195
Wed 19 Nov 2025 05:56:51 INFO  [Epoch 17] Train Loss: 2.1531851058088933
Wed 19 Nov 2025 05:58:15 INFO  [Epoch 18] Train Loss: 2.1505318338384103
Wed 19 Nov 2025 05:59:40 INFO  [Epoch 19] Train Loss: 2.14633678006515
Wed 19 Nov 2025 06:01:03 INFO  [Epoch 20] Train Loss: 2.1434377026719624
Wed 19 Nov 2025 06:01:03 INFO  [Epoch 20] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_20.pth
Wed 19 Nov 2025 06:02:27 INFO  [Epoch 21] Train Loss: 2.137698792656652
Wed 19 Nov 2025 06:03:52 INFO  [Epoch 22] Train Loss: 2.1350275588915952
Wed 19 Nov 2025 06:05:18 INFO  [Epoch 23] Train Loss: 2.134971196254394
Wed 19 Nov 2025 06:06:43 INFO  [Epoch 24] Train Loss: 2.130265966787676
Wed 19 Nov 2025 06:08:10 INFO  [Epoch 25] Train Loss: 2.127564528514859
Wed 19 Nov 2025 06:09:35 INFO  [Epoch 26] Train Loss: 2.1304207406910005
Wed 19 Nov 2025 06:11:01 INFO  [Epoch 27] Train Loss: 2.1263620513852772
Wed 19 Nov 2025 06:12:26 INFO  [Epoch 28] Train Loss: 2.1231926976960676
Wed 19 Nov 2025 06:13:52 INFO  [Epoch 29] Train Loss: 2.1221987975658827
Wed 19 Nov 2025 06:15:17 INFO  [Epoch 30] Train Loss: 2.1199237705624543
Wed 19 Nov 2025 06:15:17 INFO  [Epoch 30] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_30.pth
Wed 19 Nov 2025 06:16:42 INFO  [Epoch 31] Train Loss: 2.1183790273026766
Wed 19 Nov 2025 06:18:06 INFO  [Epoch 32] Train Loss: 2.1158793459463228
Wed 19 Nov 2025 06:19:33 INFO  [Epoch 33] Train Loss: 2.1169991101550267
Wed 19 Nov 2025 06:20:59 INFO  [Epoch 34] Train Loss: 2.112792432353114
Wed 19 Nov 2025 06:22:22 INFO  [Epoch 35] Train Loss: 2.110792346708561
Wed 19 Nov 2025 06:23:48 INFO  [Epoch 36] Train Loss: 2.112656833358339
Wed 19 Nov 2025 06:25:11 INFO  [Epoch 37] Train Loss: 2.10860333877483
Wed 19 Nov 2025 06:26:37 INFO  [Epoch 38] Train Loss: 2.108800799665185
Wed 19 Nov 2025 06:28:03 INFO  [Epoch 39] Train Loss: 2.1116164646924847
Wed 19 Nov 2025 06:29:24 INFO  [Epoch 40] Train Loss: 2.10652090205945
Wed 19 Nov 2025 06:29:24 INFO  [Epoch 40] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_40.pth
Wed 19 Nov 2025 06:30:45 INFO  [Epoch 41] Train Loss: 2.106551451079362
Wed 19 Nov 2025 06:32:09 INFO  [Epoch 42] Train Loss: 2.10477315912412
Wed 19 Nov 2025 06:33:36 INFO  [Epoch 43] Train Loss: 2.1030492116925226
Wed 19 Nov 2025 06:35:01 INFO  [Epoch 44] Train Loss: 2.1025655001020107
Wed 19 Nov 2025 06:36:28 INFO  [Epoch 45] Train Loss: 2.1012652318281795
Wed 19 Nov 2025 06:37:55 INFO  [Epoch 46] Train Loss: 2.099064964680359
Wed 19 Nov 2025 06:39:20 INFO  [Epoch 47] Train Loss: 2.0983821945075443
Wed 19 Nov 2025 06:40:46 INFO  [Epoch 48] Train Loss: 2.096527810732763
Wed 19 Nov 2025 06:42:12 INFO  [Epoch 49] Train Loss: 2.0942003092733468
Wed 19 Nov 2025 06:43:40 INFO  [Epoch 50] Train Loss: 2.093412179199483
Wed 19 Nov 2025 06:43:40 INFO  [Epoch 50] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_50.pth
Wed 19 Nov 2025 06:45:02 INFO  [Epoch 51] Train Loss: 2.091416919599733
Wed 19 Nov 2025 06:46:28 INFO  [Epoch 52] Train Loss: 2.0901309939911243
Wed 19 Nov 2025 06:47:54 INFO  [Epoch 53] Train Loss: 2.0916579565610216
Wed 19 Nov 2025 06:49:21 INFO  [Epoch 54] Train Loss: 2.088414252298437
Wed 19 Nov 2025 06:50:49 INFO  [Epoch 55] Train Loss: 2.0853374479584166
Wed 19 Nov 2025 06:52:13 INFO  [Epoch 56] Train Loss: 2.0849781402898357
Wed 19 Nov 2025 06:53:42 INFO  [Epoch 57] Train Loss: 2.0875635400425696
Wed 19 Nov 2025 06:55:05 INFO  [Epoch 58] Train Loss: 2.082702865704793
Wed 19 Nov 2025 06:56:32 INFO  [Epoch 59] Train Loss: 2.0800679092040704
Wed 19 Nov 2025 06:57:56 INFO  [Epoch 60] Train Loss: 2.07864716911819
Wed 19 Nov 2025 06:57:56 INFO  [Epoch 60] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_60.pth
Wed 19 Nov 2025 06:57:56 INFO  Best epoch: 0, Best val score: -1
Wed 19 Nov 2025 06:57:56 INFO  [Epoch 61] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8.pth
Wed 19 Nov 2025 06:57:56 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Wed 19 Nov 2025 07:41:49 INFO  Influence scores: tensor([[0.1901, 0.1851, 0.1732, 0.1481, 0.1640, 0.1333, 0.1337, 0.1206, 0.1235,
         0.1044, 0.1380, 0.1102, 0.0964, 0.1075, 0.0807, 0.0711, 0.0561, 0.0486,
         0.0597, 0.0508, 0.0669, 0.0546, 0.0365, 0.0684, 0.0678],
        [0.1786, 0.2127, 0.1790, 0.1604, 0.1755, 0.1341, 0.1442, 0.1339, 0.1279,
         0.1105, 0.1525, 0.1198, 0.1064, 0.1192, 0.0942, 0.0844, 0.0702, 0.0606,
         0.0719, 0.0610, 0.0761, 0.0643, 0.0410, 0.0771, 0.0747],
        [0.1650, 0.1764, 0.2025, 0.1507, 0.1882, 0.1462, 0.1582, 0.1304, 0.1429,
         0.1239, 0.1628, 0.1254, 0.1127, 0.1273, 0.1007, 0.0896, 0.0749, 0.0703,
         0.0806, 0.0665, 0.0830, 0.0724, 0.0504, 0.0836, 0.0858],
        [0.1750, 0.1928, 0.1850, 0.1806, 0.1796, 0.1473, 0.1563, 0.1434, 0.1406,
         0.1243, 0.1619, 0.1289, 0.1172, 0.1299, 0.1032, 0.0907, 0.0755, 0.0679,
         0.0815, 0.0683, 0.0833, 0.0712, 0.0466, 0.0815, 0.0826],
        [0.1543, 0.1711, 0.1864, 0.1438, 0.2010, 0.1410, 0.1588, 0.1316, 0.1443,
         0.1217, 0.1652, 0.1253, 0.1102, 0.1275, 0.1013, 0.0909, 0.0781, 0.0709,
         0.0791, 0.0673, 0.0838, 0.0729, 0.0499, 0.0841, 0.0818],
        [0.1483, 0.1555, 0.1701, 0.1365, 0.1663, 0.1647, 0.1438, 0.1232, 0.1366,
         0.1272, 0.1551, 0.1335, 0.1210, 0.1316, 0.1037, 0.0890, 0.0739, 0.0702,
         0.0818, 0.0710, 0.0871, 0.0739, 0.0510, 0.0806, 0.0809],
        [0.1468, 0.1627, 0.1785, 0.1427, 0.1815, 0.1414, 0.1727, 0.1376, 0.1503,
         0.1334, 0.1737, 0.1324, 0.1214, 0.1358, 0.1116, 0.1013, 0.0864, 0.0778,
         0.0899, 0.0758, 0.0912, 0.0814, 0.0569, 0.0880, 0.0883],
        [0.1443, 0.1641, 0.1644, 0.1418, 0.1668, 0.1319, 0.1507, 0.1806, 0.1382,
         0.1259, 0.1615, 0.1329, 0.1235, 0.1375, 0.1154, 0.1043, 0.0895, 0.0680,
         0.0824, 0.0792, 0.0861, 0.0760, 0.0524, 0.0824, 0.0782],
        [0.1417, 0.1511, 0.1677, 0.1311, 0.1710, 0.1392, 0.1545, 0.1298, 0.1595,
         0.1329, 0.1679, 0.1333, 0.1195, 0.1341, 0.1103, 0.0983, 0.0838, 0.0773,
         0.0874, 0.0733, 0.0898, 0.0782, 0.0574, 0.0852, 0.0842],
        [0.1310, 0.1435, 0.1590, 0.1255, 0.1591, 0.1389, 0.1478, 0.1279, 0.1423,
         0.1515, 0.1691, 0.1365, 0.1299, 0.1428, 0.1208, 0.1069, 0.0911, 0.0816,
         0.0976, 0.0829, 0.0973, 0.0881, 0.0641, 0.0882, 0.0887],
        [0.1293, 0.1490, 0.1617, 0.1270, 0.1668, 0.1316, 0.1525, 0.1273, 0.1426,
         0.1341, 0.1921, 0.1399, 0.1291, 0.1473, 0.1260, 0.1122, 0.0977, 0.0907,
         0.1035, 0.0875, 0.1026, 0.0905, 0.0639, 0.0945, 0.0938],
        [0.1176, 0.1339, 0.1420, 0.1111, 0.1441, 0.1273, 0.1280, 0.1178, 0.1246,
         0.1191, 0.1567, 0.1629, 0.1415, 0.1486, 0.1217, 0.1057, 0.0895, 0.0852,
         0.0922, 0.0899, 0.1014, 0.0872, 0.0575, 0.0916, 0.0878],
        [0.1162, 0.1325, 0.1415, 0.1114, 0.1417, 0.1273, 0.1293, 0.1199, 0.1228,
         0.1233, 0.1575, 0.1535, 0.1569, 0.1514, 0.1269, 0.1117, 0.0928, 0.0839,
         0.0992, 0.0971, 0.1051, 0.0933, 0.0649, 0.0956, 0.0936],
        [0.1163, 0.1342, 0.1448, 0.1127, 0.1476, 0.1254, 0.1319, 0.1225, 0.1266,
         0.1249, 0.1647, 0.1491, 0.1395, 0.1734, 0.1342, 0.1166, 0.1042, 0.0954,
         0.1067, 0.0999, 0.1100, 0.0981, 0.0676, 0.0991, 0.0986],
        [0.1001, 0.1200, 0.1279, 0.0962, 0.1310, 0.1072, 0.1178, 0.1098, 0.1117,
         0.1121, 0.1521, 0.1315, 0.1247, 0.1428, 0.1527, 0.1327, 0.1163, 0.1002,
         0.1143, 0.1103, 0.1182, 0.1072, 0.0777, 0.1063, 0.1028],
        [0.0940, 0.1132, 0.1200, 0.0873, 0.1235, 0.0964, 0.1109, 0.1031, 0.1036,
         0.1035, 0.1437, 0.1204, 0.1148, 0.1303, 0.1376, 0.1466, 0.1164, 0.0903,
         0.1119, 0.1127, 0.1190, 0.1094, 0.0857, 0.1102, 0.1024],
        [0.0988, 0.1186, 0.1254, 0.0921, 0.1306, 0.1012, 0.1151, 0.1076, 0.1090,
         0.1070, 0.1491, 0.1239, 0.1155, 0.1377, 0.1408, 0.1355, 0.1354, 0.1012,
         0.1137, 0.1138, 0.1204, 0.1123, 0.0870, 0.1144, 0.1042],
        [0.1007, 0.1177, 0.1296, 0.0935, 0.1315, 0.1070, 0.1147, 0.0954, 0.1108,
         0.1063, 0.1503, 0.1271, 0.1140, 0.1366, 0.1324, 0.1183, 0.1098, 0.1334,
         0.1226, 0.1078, 0.1349, 0.1215, 0.0931, 0.1267, 0.1251],
        [0.1020, 0.1191, 0.1301, 0.0972, 0.1310, 0.1081, 0.1178, 0.0990, 0.1107,
         0.1115, 0.1527, 0.1244, 0.1195, 0.1384, 0.1375, 0.1291, 0.1118, 0.1128,
         0.1501, 0.1220, 0.1394, 0.1284, 0.0982, 0.1282, 0.1317],
        [0.0909, 0.1073, 0.1157, 0.0828, 0.1183, 0.0961, 0.1034, 0.0950, 0.0955,
         0.0959, 0.1355, 0.1203, 0.1160, 0.1294, 0.1308, 0.1296, 0.1109, 0.0963,
         0.1210, 0.1430, 0.1439, 0.1323, 0.0990, 0.1329, 0.1218],
        [0.0951, 0.1105, 0.1205, 0.0858, 0.1223, 0.1003, 0.1063, 0.0897, 0.1009,
         0.0986, 0.1393, 0.1201, 0.1117, 0.1282, 0.1274, 0.1241, 0.1061, 0.1130,
         0.1279, 0.1321, 0.1665, 0.1460, 0.1121, 0.1507, 0.1410],
        [0.0928, 0.1080, 0.1191, 0.0843, 0.1206, 0.0973, 0.1058, 0.0896, 0.0993,
         0.0987, 0.1359, 0.1160, 0.1097, 0.1258, 0.1262, 0.1242, 0.1075, 0.1076,
         0.1250, 0.1295, 0.1558, 0.1700, 0.1297, 0.1649, 0.1566],
        [0.0902, 0.1003, 0.1131, 0.0758, 0.1147, 0.0909, 0.0988, 0.0827, 0.0959,
         0.0921, 0.1273, 0.1038, 0.0982, 0.1125, 0.1133, 0.1176, 0.0997, 0.0974,
         0.1120, 0.1126, 0.1375, 0.1461, 0.1543, 0.1589, 0.1519],
        [0.0933, 0.1082, 0.1185, 0.0827, 0.1210, 0.0928, 0.1026, 0.0861, 0.0950,
         0.0886, 0.1301, 0.1094, 0.1012, 0.1165, 0.1147, 0.1146, 0.0986, 0.1022,
         0.1138, 0.1197, 0.1484, 0.1531, 0.1305, 0.1973, 0.1766],
        [0.0948, 0.1074, 0.1217, 0.0848, 0.1206, 0.0948, 0.1043, 0.0831, 0.0954,
         0.0908, 0.1304, 0.1080, 0.1022, 0.1182, 0.1134, 0.1093, 0.0907, 0.1025,
         0.1197, 0.1114, 0.1412, 0.1482, 0.1271, 0.1800, 0.2071]],
       device='cuda:0')
Wed 19 Nov 2025 07:41:49 INFO  Mean influence score: [0.10357856750488281, 0.11320839822292328, 0.11881441622972488, 0.12060744315385818, 0.11769216507673264, 0.11505705863237381, 0.1223740205168724, 0.11912132054567337, 0.11833376437425613, 0.12050054222345352, 0.12373340129852295, 0.11539925634860992, 0.11796867847442627, 0.12176143378019333, 0.11694019287824631, 0.11227689683437347, 0.11641000211238861, 0.11842936277389526, 0.12203168869018555, 0.11453739553689957, 0.11904200911521912, 0.11999429762363434, 0.11191253364086151, 0.11662331968545914, 0.11627774685621262]
Wed 19 Nov 2025 07:41:49 INFO  Stage 0 selected prob: [0.03945435583591461, 0.039836131036281586, 0.040060076862573624, 0.04013197124004364, 0.040015146136283875, 0.03990984335541725, 0.04020293056964874, 0.040072374045848846, 0.04004083573818207, 0.04012768343091011, 0.040257617831230164, 0.03992350399494171, 0.040026213973760605, 0.04017830640077591, 0.03998507186770439, 0.0397990383207798, 0.039963871240615845, 0.04004465416073799, 0.04018917307257652, 0.039889104664325714, 0.04006919637322426, 0.040107373148202896, 0.03978453949093819, 0.039972398430109024, 0.039958588778972626]
Wed 19 Nov 2025 07:43:18 INFO  [Epoch 61] Train Loss: 2.0777482390852917
Wed 19 Nov 2025 07:44:41 INFO  [Epoch 62] Train Loss: 2.078210693512452
Wed 19 Nov 2025 07:46:05 INFO  [Epoch 63] Train Loss: 2.0768884629707367
Wed 19 Nov 2025 07:47:30 INFO  [Epoch 64] Train Loss: 2.0773898648784495
Wed 19 Nov 2025 07:48:53 INFO  [Epoch 65] Train Loss: 2.075252324994022
Wed 19 Nov 2025 07:50:20 INFO  [Epoch 66] Train Loss: 2.073053936358224
Wed 19 Nov 2025 07:51:46 INFO  [Epoch 67] Train Loss: 2.072436489282736
Wed 19 Nov 2025 07:53:13 INFO  [Epoch 68] Train Loss: 2.07061129309849
Wed 19 Nov 2025 07:54:37 INFO  [Epoch 69] Train Loss: 2.0672098143080975
Wed 19 Nov 2025 07:56:01 INFO  [Epoch 70] Train Loss: 2.065470192067679
Wed 19 Nov 2025 07:56:01 INFO  [Epoch 70] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_70.pth
Wed 19 Nov 2025 07:57:27 INFO  [Epoch 71] Train Loss: 2.0636753162766364
Wed 19 Nov 2025 07:58:53 INFO  [Epoch 72] Train Loss: 2.062884047054759
Wed 19 Nov 2025 08:00:17 INFO  [Epoch 73] Train Loss: 2.0616014752966527
Wed 19 Nov 2025 08:01:42 INFO  [Epoch 74] Train Loss: 2.0592548883131956
Wed 19 Nov 2025 08:03:07 INFO  [Epoch 75] Train Loss: 2.0568085353717644
Wed 19 Nov 2025 08:04:34 INFO  [Epoch 76] Train Loss: 2.055985008403603
Wed 19 Nov 2025 08:05:59 INFO  [Epoch 77] Train Loss: 2.055263890300196
Wed 19 Nov 2025 08:07:26 INFO  [Epoch 78] Train Loss: 2.054091294456804
Wed 19 Nov 2025 08:08:47 INFO  [Epoch 79] Train Loss: 2.0509914140909706
Wed 19 Nov 2025 08:10:12 INFO  [Epoch 80] Train Loss: 2.049216853826677
Wed 19 Nov 2025 08:10:13 INFO  [Epoch 80] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_80.pth
Wed 19 Nov 2025 08:10:13 INFO  Best epoch: 0, Best val score: -1
Wed 19 Nov 2025 08:10:13 INFO  [Epoch 81] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8.pth
Wed 19 Nov 2025 08:10:13 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Wed 19 Nov 2025 08:56:03 INFO  Influence scores: tensor([[-0.0264, -0.0841, -0.0665, -0.0579, -0.0717, -0.0649, -0.0861, -0.1205,
         -0.0631, -0.0751, -0.0879, -0.0948, -0.1372, -0.1037, -0.1232, -0.1330,
         -0.1201, -0.0982, -0.1481, -0.1431, -0.1531, -0.1574, -0.1469, -0.1490,
         -0.1754],
        [-0.0508, -0.0637, -0.0725, -0.0567, -0.0714, -0.0744, -0.0866, -0.1167,
         -0.0709, -0.0795, -0.0846, -0.0960, -0.1380, -0.1021, -0.1204, -0.1302,
         -0.1163, -0.0971, -0.1464, -0.1437, -0.1541, -0.1591, -0.1535, -0.1512,
         -0.1787],
        [-0.0654, -0.1052, -0.0496, -0.0678, -0.0611, -0.0651, -0.0750, -0.1211,
         -0.0579, -0.0689, -0.0772, -0.0927, -0.1348, -0.0971, -0.1171, -0.1277,
         -0.1139, -0.0903, -0.1403, -0.1406, -0.1493, -0.1527, -0.1448, -0.1460,
         -0.1701],
        [-0.0583, -0.0903, -0.0695, -0.0387, -0.0707, -0.0650, -0.0770, -0.1123,
         -0.0610, -0.0693, -0.0781, -0.0901, -0.1310, -0.0951, -0.1154, -0.1269,
         -0.1141, -0.0931, -0.1402, -0.1401, -0.1500, -0.1546, -0.1486, -0.1493,
         -0.1737],
        [-0.0732, -0.1062, -0.0634, -0.0715, -0.0442, -0.0669, -0.0699, -0.1160,
         -0.0525, -0.0672, -0.0699, -0.0889, -0.1330, -0.0925, -0.1125, -0.1227,
         -0.1077, -0.0866, -0.1382, -0.1368, -0.1458, -0.1494, -0.1414, -0.1430,
         -0.1698],
        [-0.0771, -0.1199, -0.0780, -0.0765, -0.0776, -0.0387, -0.0826, -0.1237,
         -0.0562, -0.0573, -0.0773, -0.0759, -0.1179, -0.0855, -0.1085, -0.1207,
         -0.1090, -0.0831, -0.1327, -0.1288, -0.1384, -0.1445, -0.1372, -0.1422,
         -0.1669],
        [-0.0835, -0.1172, -0.0738, -0.0738, -0.0663, -0.0688, -0.0561, -0.1115,
         -0.0474, -0.0561, -0.0623, -0.0833, -0.1229, -0.0857, -0.1037, -0.1133,
         -0.1013, -0.0813, -0.1286, -0.1292, -0.1393, -0.1429, -0.1361, -0.1396,
         -0.1644],
        [-0.0841, -0.1131, -0.0852, -0.0740, -0.0773, -0.0738, -0.0758, -0.0601,
         -0.0555, -0.0606, -0.0711, -0.0789, -0.1169, -0.0797, -0.0968, -0.1057,
         -0.0933, -0.0853, -0.1324, -0.1224, -0.1398, -0.1427, -0.1365, -0.1404,
         -0.1681],
        [-0.0809, -0.1207, -0.0759, -0.0776, -0.0685, -0.0618, -0.0666, -0.1110,
         -0.0275, -0.0471, -0.0599, -0.0727, -0.1155, -0.0782, -0.0966, -0.1071,
         -0.0948, -0.0724, -0.1230, -0.1234, -0.1317, -0.1355, -0.1256, -0.1341,
         -0.1596],
        [-0.0932, -0.1298, -0.0885, -0.0862, -0.0839, -0.0644, -0.0763, -0.1165,
         -0.0480, -0.0291, -0.0597, -0.0707, -0.1068, -0.0717, -0.0882, -0.0989,
         -0.0881, -0.0688, -0.1138, -0.1148, -0.1251, -0.1275, -0.1210, -0.1307,
         -0.1557],
        [-0.1021, -0.1309, -0.0918, -0.0910, -0.0818, -0.0787, -0.0779, -0.1223,
         -0.0555, -0.0552, -0.0425, -0.0740, -0.1140, -0.0723, -0.0879, -0.0995,
         -0.0866, -0.0644, -0.1133, -0.1157, -0.1247, -0.1317, -0.1261, -0.1317,
         -0.1572],
        [-0.1057, -0.1386, -0.1037, -0.0999, -0.0970, -0.0747, -0.0954, -0.1256,
         -0.0653, -0.0624, -0.0711, -0.0411, -0.0913, -0.0624, -0.0845, -0.0979,
         -0.0886, -0.0627, -0.1174, -0.1053, -0.1187, -0.1265, -0.1252, -0.1255,
         -0.1533],
        [-0.1093, -0.1421, -0.1070, -0.1017, -0.1032, -0.0773, -0.0965, -0.1261,
         -0.0693, -0.0599, -0.0732, -0.0528, -0.0784, -0.0634, -0.0824, -0.0938,
         -0.0876, -0.0663, -0.1131, -0.1001, -0.1179, -0.1233, -0.1216, -0.1243,
         -0.1508],
        [-0.1117, -0.1423, -0.1061, -0.1019, -0.0993, -0.0813, -0.0954, -0.1243,
         -0.0687, -0.0614, -0.0681, -0.0599, -0.0985, -0.0400, -0.0761, -0.0906,
         -0.0768, -0.0557, -0.1064, -0.0998, -0.1137, -0.1203, -0.1197, -0.1223,
         -0.1483],
        [-0.1221, -0.1516, -0.1163, -0.1124, -0.1091, -0.0942, -0.1034, -0.1316,
         -0.0761, -0.0667, -0.0729, -0.0722, -0.1076, -0.0659, -0.0543, -0.0717,
         -0.0625, -0.0482, -0.0961, -0.0869, -0.1034, -0.1096, -0.1081, -0.1139,
         -0.1420],
        [-0.1295, -0.1585, -0.1249, -0.1218, -0.1178, -0.1055, -0.1119, -0.1393,
         -0.0856, -0.0759, -0.0826, -0.0849, -0.1186, -0.0785, -0.0701, -0.0560,
         -0.0624, -0.0585, -0.0964, -0.0824, -0.0996, -0.1027, -0.0976, -0.1072,
         -0.1388],
        [-0.1246, -0.1536, -0.1198, -0.1177, -0.1121, -0.1014, -0.1087, -0.1359,
         -0.0822, -0.0736, -0.0792, -0.0828, -0.1198, -0.0738, -0.0690, -0.0712,
         -0.0452, -0.0498, -0.0985, -0.0854, -0.1023, -0.1048, -0.1009, -0.1080,
         -0.1431],
        [-0.1287, -0.1603, -0.1220, -0.1231, -0.1158, -0.1025, -0.1143, -0.1525,
         -0.0858, -0.0805, -0.0832, -0.0837, -0.1246, -0.0792, -0.0817, -0.0926,
         -0.0750, -0.0219, -0.0943, -0.0953, -0.0917, -0.1006, -0.0987, -0.0993,
         -0.1266],
        [-0.1336, -0.1645, -0.1267, -0.1249, -0.1218, -0.1062, -0.1164, -0.1553,
         -0.0910, -0.0802, -0.0859, -0.0922, -0.1256, -0.0838, -0.0842, -0.0860,
         -0.0797, -0.0500, -0.0683, -0.0849, -0.0920, -0.0977, -0.0956, -0.1013,
         -0.1218],
        [-0.1363, -0.1686, -0.1339, -0.1313, -0.1272, -0.1101, -0.1239, -0.1518,
         -0.0982, -0.0881, -0.0952, -0.0882, -0.1207, -0.0844, -0.0822, -0.0785,
         -0.0725, -0.0573, -0.0923, -0.0561, -0.0801, -0.0853, -0.0880, -0.0889,
         -0.1241],
        [-0.1406, -0.1740, -0.1378, -0.1362, -0.1306, -0.1144, -0.1288, -0.1640,
         -0.1009, -0.0934, -0.0991, -0.0958, -0.1323, -0.0931, -0.0925, -0.0901,
         -0.0842, -0.0484, -0.0930, -0.0738, -0.0633, -0.0785, -0.0823, -0.0786,
         -0.1135],
        [-0.1419, -0.1758, -0.1377, -0.1376, -0.1322, -0.1165, -0.1295, -0.1640,
         -0.1023, -0.0926, -0.1028, -0.1000, -0.1338, -0.0957, -0.0946, -0.0903,
         -0.0835, -0.0542, -0.0957, -0.0767, -0.0747, -0.0519, -0.0617, -0.0617,
         -0.0947],
        [-0.1416, -0.1811, -0.1404, -0.1435, -0.1340, -0.1204, -0.1328, -0.1677,
         -0.1025, -0.0958, -0.1070, -0.1095, -0.1424, -0.1049, -0.1029, -0.0950,
         -0.0888, -0.0618, -0.1036, -0.0899, -0.0888, -0.0712, -0.0323, -0.0647,
         -0.0958],
        [-0.1450, -0.1796, -0.1420, -0.1437, -0.1357, -0.1254, -0.1364, -0.1712,
         -0.1110, -0.1063, -0.1124, -0.1107, -0.1464, -0.1078, -0.1092, -0.1050,
         -0.0967, -0.0633, -0.1097, -0.0913, -0.0861, -0.0724, -0.0645, -0.0336,
         -0.0773],
        [-0.1486, -0.1850, -0.1445, -0.1465, -0.1408, -0.1277, -0.1395, -0.1779,
         -0.1149, -0.1092, -0.1167, -0.1163, -0.1503, -0.1124, -0.1158, -0.1144,
         -0.1105, -0.0689, -0.1082, -0.1029, -0.0977, -0.0826, -0.0736, -0.0549,
         -0.0498]], device='cuda:0')
Wed 19 Nov 2025 08:56:03 INFO  Mean influence score: [0.007679799571633339, 0.012434684671461582, 0.01700325682759285, 0.01832655444741249, 0.017522644251585007, 0.01632065325975418, 0.02154911868274212, 0.020115718245506287, 0.02153477631509304, 0.022904932498931885, 0.02337229624390602, 0.01862267032265663, 0.019998015835881233, 0.02302400954067707, 0.020211752504110336, 0.01570366509258747, 0.018746400251984596, 0.018562056124210358, 0.019877834245562553, 0.01591537706553936, 0.01698407158255577, 0.01818140223622322, 0.011660811491310596, 0.01306106336414814, 0.01055885013192892]
Wed 19 Nov 2025 08:56:03 INFO  Stage 1 selected prob: [0.039605047553777695, 0.03979381173849106, 0.039976026862859726, 0.04002896696329117, 0.03999679535627365, 0.03994874656200409, 0.04015817493200302, 0.040100645273923874, 0.04015759378671646, 0.04021265357732773, 0.040231455117464066, 0.040040820837020874, 0.04009592533111572, 0.04021744057536125, 0.04010450094938278, 0.03992411121726036, 0.04004577174782753, 0.04003839194774628, 0.04009110853075981, 0.03993256390094757, 0.03997526317834854, 0.04002315551042557, 0.03976302966475487, 0.039818745106458664, 0.03971923887729645]
Wed 19 Nov 2025 08:57:34 INFO  [Epoch 81] Train Loss: 2.048606527148105
Wed 19 Nov 2025 08:59:08 INFO  [Epoch 82] Train Loss: 2.046942232601968
Wed 19 Nov 2025 09:00:38 INFO  [Epoch 83] Train Loss: 2.0452116534686575
Wed 19 Nov 2025 09:02:10 INFO  [Epoch 84] Train Loss: 2.042657507031864
Wed 19 Nov 2025 09:03:43 INFO  [Epoch 85] Train Loss: 2.0420877990097415
Wed 19 Nov 2025 09:05:14 INFO  [Epoch 86] Train Loss: 2.0394301077613455
Wed 19 Nov 2025 09:06:46 INFO  [Epoch 87] Train Loss: 2.0380553665606707
Wed 19 Nov 2025 09:08:18 INFO  [Epoch 88] Train Loss: 2.0362806699288547
Wed 19 Nov 2025 09:09:48 INFO  [Epoch 89] Train Loss: 2.034847933543564
Wed 19 Nov 2025 09:11:20 INFO  [Epoch 90] Train Loss: 2.0334268602645746
Wed 19 Nov 2025 09:11:20 INFO  [Epoch 90] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_90.pth
Wed 19 Nov 2025 09:12:51 INFO  [Epoch 91] Train Loss: 2.0306195415045503
Wed 19 Nov 2025 09:14:24 INFO  [Epoch 92] Train Loss: 2.0288813983756255
Wed 19 Nov 2025 09:15:56 INFO  [Epoch 93] Train Loss: 2.0271992192918766
Wed 19 Nov 2025 09:17:26 INFO  [Epoch 94] Train Loss: 2.0246394251914697
Wed 19 Nov 2025 09:18:59 INFO  [Epoch 95] Train Loss: 2.023826203942748
Wed 19 Nov 2025 09:20:31 INFO  [Epoch 96] Train Loss: 2.021803966391419
Wed 19 Nov 2025 09:22:03 INFO  [Epoch 97] Train Loss: 2.0197936543505626
Wed 19 Nov 2025 09:23:36 INFO  [Epoch 98] Train Loss: 2.0188374654996997
Wed 19 Nov 2025 09:25:06 INFO  [Epoch 99] Train Loss: 2.0155916222972627
Wed 19 Nov 2025 09:26:38 INFO  [Epoch 100] Train Loss: 2.0138526102970125
Wed 19 Nov 2025 09:26:38 INFO  [Epoch 100] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_100.pth
Wed 19 Nov 2025 09:26:38 INFO  Best epoch: 0, Best val score: -1
Wed 19 Nov 2025 09:26:38 INFO  [Epoch 101] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8.pth
Wed 19 Nov 2025 09:26:38 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Wed 19 Nov 2025 10:14:06 INFO  Influence scores: tensor([[-0.0435, -0.0603, -0.1327, -0.1280, -0.0892, -0.1751, -0.1128, -0.1276,
         -0.1270, -0.1374, -0.1394, -0.1577, -0.1565, -0.1930, -0.1421, -0.1734,
         -0.1725, -0.1954, -0.2012, -0.2416, -0.2316, -0.2174, -0.1733, -0.2502,
         -0.2063],
        [-0.0668, -0.0329, -0.1359, -0.1223, -0.0845, -0.1829, -0.1102, -0.1199,
         -0.1328, -0.1395, -0.1320, -0.1541, -0.1554, -0.1875, -0.1351, -0.1667,
         -0.1639, -0.1903, -0.1962, -0.2375, -0.2285, -0.2157, -0.1778, -0.2496,
         -0.2078],
        [-0.0877, -0.0845, -0.1122, -0.1404, -0.0767, -0.1778, -0.1006, -0.1318,
         -0.1229, -0.1320, -0.1264, -0.1565, -0.1558, -0.1867, -0.1372, -0.1690,
         -0.1662, -0.1866, -0.1931, -0.2390, -0.2282, -0.2149, -0.1727, -0.2474,
         -0.2009],
        [-0.0769, -0.0654, -0.1345, -0.1046, -0.0868, -0.1742, -0.1008, -0.1174,
         -0.1240, -0.1295, -0.1259, -0.1502, -0.1492, -0.1813, -0.1325, -0.1649,
         -0.1644, -0.1883, -0.1906, -0.2350, -0.2268, -0.2131, -0.1751, -0.2488,
         -0.2019],
        [-0.0953, -0.0860, -0.1286, -0.1442, -0.0561, -0.1788, -0.0941, -0.1251,
         -0.1152, -0.1297, -0.1180, -0.1512, -0.1539, -0.1808, -0.1314, -0.1633,
         -0.1587, -0.1824, -0.1909, -0.2349, -0.2239, -0.2108, -0.1696, -0.2434,
         -0.2005],
        [-0.1025, -0.1032, -0.1492, -0.1515, -0.0987, -0.1464, -0.1117, -0.1349,
         -0.1223, -0.1192, -0.1289, -0.1384, -0.1360, -0.1733, -0.1277, -0.1616,
         -0.1606, -0.1808, -0.1848, -0.2272, -0.2181, -0.2054, -0.1657, -0.2450,
         -0.1991],
        [-0.1108, -0.1032, -0.1447, -0.1511, -0.0869, -0.1844, -0.0821, -0.1224,
         -0.1141, -0.1201, -0.1132, -0.1484, -0.1454, -0.1765, -0.1246, -0.1557,
         -0.1549, -0.1801, -0.1832, -0.2292, -0.2197, -0.2062, -0.1658, -0.2430,
         -0.1971],
        [-0.1088, -0.0944, -0.1575, -0.1494, -0.0993, -0.1892, -0.1039, -0.0596,
         -0.1222, -0.1233, -0.1228, -0.1411, -0.1361, -0.1664, -0.1132, -0.1437,
         -0.1423, -0.1837, -0.1852, -0.2178, -0.2179, -0.2035, -0.1635, -0.2425,
         -0.2003],
        [-0.1132, -0.1127, -0.1538, -0.1614, -0.0943, -0.1813, -0.1002, -0.1270,
         -0.0941, -0.1147, -0.1160, -0.1416, -0.1412, -0.1720, -0.1210, -0.1529,
         -0.1520, -0.1753, -0.1814, -0.2277, -0.2155, -0.2024, -0.1582, -0.2422,
         -0.1964],
        [-0.1293, -0.1252, -0.1694, -0.1725, -0.1151, -0.1848, -0.1135, -0.1348,
         -0.1215, -0.0943, -0.1176, -0.1404, -0.1310, -0.1657, -0.1117, -0.1432,
         -0.1448, -0.1712, -0.1708, -0.2177, -0.2087, -0.1937, -0.1528, -0.2390,
         -0.1931],
        [-0.1349, -0.1231, -0.1687, -0.1745, -0.1083, -0.1989, -0.1112, -0.1385,
         -0.1266, -0.1221, -0.0920, -0.1405, -0.1384, -0.1651, -0.1096, -0.1429,
         -0.1410, -0.1644, -0.1681, -0.2162, -0.2059, -0.1958, -0.1577, -0.2364,
         -0.1920],
        [-0.1382, -0.1287, -0.1817, -0.1818, -0.1253, -0.1921, -0.1296, -0.1392,
         -0.1366, -0.1282, -0.1245, -0.0988, -0.1074, -0.1494, -0.1023, -0.1386,
         -0.1395, -0.1610, -0.1688, -0.2026, -0.1963, -0.1873, -0.1560, -0.2297,
         -0.1864],
        [-0.1405, -0.1327, -0.1843, -0.1842, -0.1312, -0.1935, -0.1302, -0.1384,
         -0.1401, -0.1232, -0.1259, -0.1127, -0.0892, -0.1474, -0.0978, -0.1318,
         -0.1362, -0.1630, -0.1612, -0.1943, -0.1926, -0.1794, -0.1470, -0.2247,
         -0.1785],
        [-0.1429, -0.1321, -0.1820, -0.1836, -0.1253, -0.1972, -0.1278, -0.1363,
         -0.1377, -0.1246, -0.1195, -0.1195, -0.1130, -0.1208, -0.0907, -0.1273,
         -0.1235, -0.1496, -0.1537, -0.1936, -0.1874, -0.1761, -0.1450, -0.2221,
         -0.1750],
        [-0.1590, -0.1460, -0.1989, -0.2007, -0.1412, -0.2178, -0.1431, -0.1485,
         -0.1519, -0.1371, -0.1305, -0.1394, -0.1295, -0.1572, -0.0660, -0.1064,
         -0.1086, -0.1430, -0.1434, -0.1795, -0.1765, -0.1650, -0.1328, -0.2142,
         -0.1713],
        [-0.1641, -0.1512, -0.2052, -0.2073, -0.1464, -0.2258, -0.1478, -0.1518,
         -0.1581, -0.1428, -0.1368, -0.1501, -0.1372, -0.1680, -0.0792, -0.0838,
         -0.1035, -0.1493, -0.1407, -0.1700, -0.1690, -0.1544, -0.1166, -0.2034,
         -0.1651],
        [-0.1635, -0.1503, -0.2036, -0.2076, -0.1440, -0.2261, -0.1489, -0.1530,
         -0.1590, -0.1450, -0.1373, -0.1518, -0.1433, -0.1652, -0.0827, -0.1048,
         -0.0859, -0.1424, -0.1459, -0.1757, -0.1744, -0.1588, -0.1221, -0.2067,
         -0.1725],
        [-0.1595, -0.1495, -0.1957, -0.2039, -0.1394, -0.2186, -0.1454, -0.1668,
         -0.1542, -0.1447, -0.1329, -0.1448, -0.1427, -0.1644, -0.0905, -0.1235,
         -0.1152, -0.1016, -0.1328, -0.1820, -0.1550, -0.1474, -0.1138, -0.1886,
         -0.1433],
        [-0.1607, -0.1506, -0.1984, -0.2019, -0.1438, -0.2187, -0.1442, -0.1645,
         -0.1563, -0.1397, -0.1322, -0.1501, -0.1372, -0.1649, -0.0879, -0.1113,
         -0.1152, -0.1291, -0.0991, -0.1660, -0.1514, -0.1390, -0.1069, -0.1868,
         -0.1347],
        [-0.1721, -0.1619, -0.2145, -0.2171, -0.1580, -0.2311, -0.1617, -0.1664,
         -0.1735, -0.1571, -0.1509, -0.1531, -0.1393, -0.1741, -0.0925, -0.1100,
         -0.1142, -0.1477, -0.1349, -0.1380, -0.1451, -0.1321, -0.1048, -0.1804,
         -0.1463],
        [-0.1705, -0.1622, -0.2116, -0.2165, -0.1552, -0.2295, -0.1597, -0.1758,
         -0.1695, -0.1565, -0.1484, -0.1553, -0.1473, -0.1776, -0.0993, -0.1181,
         -0.1215, -0.1304, -0.1295, -0.1545, -0.1203, -0.1183, -0.0918, -0.1623,
         -0.1272],
        [-0.1770, -0.1693, -0.2182, -0.2223, -0.1621, -0.2374, -0.1659, -0.1806,
         -0.1761, -0.1606, -0.1576, -0.1667, -0.1545, -0.1851, -0.1065, -0.1218,
         -0.1252, -0.1414, -0.1367, -0.1614, -0.1377, -0.0933, -0.0724, -0.1483,
         -0.1115],
        [-0.1784, -0.1774, -0.2214, -0.2299, -0.1648, -0.2417, -0.1693, -0.1851,
         -0.1755, -0.1639, -0.1639, -0.1783, -0.1651, -0.1973, -0.1167, -0.1279,
         -0.1324, -0.1518, -0.1487, -0.1782, -0.1561, -0.1175, -0.0369, -0.1518,
         -0.1126],
        [-0.1703, -0.1640, -0.2116, -0.2179, -0.1544, -0.2360, -0.1613, -0.1776,
         -0.1736, -0.1655, -0.1581, -0.1673, -0.1577, -0.1889, -0.1134, -0.1298,
         -0.1314, -0.1414, -0.1429, -0.1692, -0.1403, -0.1073, -0.0663, -0.1053,
         -0.0820],
        [-0.1708, -0.1660, -0.2080, -0.2159, -0.1553, -0.2350, -0.1591, -0.1812,
         -0.1742, -0.1640, -0.1578, -0.1693, -0.1574, -0.1886, -0.1157, -0.1355,
         -0.1426, -0.1416, -0.1367, -0.1787, -0.1497, -0.1151, -0.0722, -0.1265,
         -0.0431]], device='cuda:0')
Wed 19 Nov 2025 10:14:06 INFO  Mean influence score: [-0.03562970831990242, -0.03149530664086342, -0.028329648077487946, -0.026468347758054733, -0.02711072377860546, -0.02826698310673237, -0.024085568264126778, -0.024368032813072205, -0.02395174466073513, -0.023074833676218987, -0.022841397672891617, -0.025915537029504776, -0.02437884919345379, -0.021372737362980843, -0.02450668439269066, -0.028054390102624893, -0.026239709928631783, -0.025195874273777008, -0.023539714515209198, -0.028407616540789604, -0.026909679174423218, -0.026861336082220078, -0.033279579132795334, -0.03007107600569725, -0.03220026567578316]
Wed 19 Nov 2025 10:14:06 INFO  Stage 2 selected prob: [0.03965218365192413, 0.03981645777821541, 0.03994270786643028, 0.04001712054014206, 0.03999141976237297, 0.03994521126151085, 0.040112584829330444, 0.04010125249624252, 0.040117956697940826, 0.0401531457901001, 0.040162522345781326, 0.04003924876451492, 0.0401008240878582, 0.04022155702114105, 0.040095698088407516, 0.03995370492339134, 0.04002626612782478, 0.04006807133555412, 0.0401344858109951, 0.03993959352374077, 0.03999946266412735, 0.04000139236450195, 0.039745479822158813, 0.039873212575912476, 0.03978839889168739]
Wed 19 Nov 2025 10:15:37 INFO  [Epoch 101] Train Loss: 2.012905379480766
Wed 19 Nov 2025 10:17:09 INFO  [Epoch 102] Train Loss: 2.011173618226098
Wed 19 Nov 2025 10:18:40 INFO  [Epoch 103] Train Loss: 2.0089359361602566
Wed 19 Nov 2025 10:20:11 INFO  [Epoch 104] Train Loss: 2.0078663063300852
Wed 19 Nov 2025 10:21:43 INFO  [Epoch 105] Train Loss: 2.0047177576713304
Wed 19 Nov 2025 10:23:13 INFO  [Epoch 106] Train Loss: 2.002787835632129
Wed 19 Nov 2025 10:24:44 INFO  [Epoch 107] Train Loss: 2.0009042904084127
Wed 19 Nov 2025 10:26:15 INFO  [Epoch 108] Train Loss: 1.9986665437521571
Wed 19 Nov 2025 10:27:44 INFO  [Epoch 109] Train Loss: 1.997741029508687
Wed 19 Nov 2025 10:29:15 INFO  [Epoch 110] Train Loss: 1.9954843808585931
Wed 19 Nov 2025 10:29:15 INFO  [Epoch 110] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_110.pth
Wed 19 Nov 2025 10:30:43 INFO  [Epoch 111] Train Loss: 1.993214177474458
Wed 19 Nov 2025 10:32:13 INFO  [Epoch 112] Train Loss: 1.9901831102443084
Wed 19 Nov 2025 10:33:43 INFO  [Epoch 113] Train Loss: 1.9888586176906031
Wed 19 Nov 2025 10:35:13 INFO  [Epoch 114] Train Loss: 1.9862905712889476
Wed 19 Nov 2025 10:36:44 INFO  [Epoch 115] Train Loss: 1.9838079228469458
Wed 19 Nov 2025 10:38:14 INFO  [Epoch 116] Train Loss: 1.9811925499081702
Wed 19 Nov 2025 10:39:47 INFO  [Epoch 117] Train Loss: 1.979375060285584
Wed 19 Nov 2025 10:41:19 INFO  [Epoch 118] Train Loss: 1.9786225586972384
Wed 19 Nov 2025 10:42:49 INFO  [Epoch 119] Train Loss: 1.9750753809117516
Wed 19 Nov 2025 10:44:22 INFO  [Epoch 120] Train Loss: 1.973511904635282
Wed 19 Nov 2025 10:44:22 INFO  [Epoch 120] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_120.pth
Wed 19 Nov 2025 10:44:22 INFO  Best epoch: 0, Best val score: -1
Wed 19 Nov 2025 10:44:22 INFO  [Epoch 121] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8.pth
Wed 19 Nov 2025 10:44:22 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Wed 19 Nov 2025 11:30:19 INFO  Influence scores: tensor([[ 0.0160, -0.0610, -0.0681, -0.0320, -0.0741, -0.0416, -0.1102, -0.0857,
         -0.0324, -0.0905, -0.1086, -0.0618, -0.1561, -0.0742, -0.0977, -0.1147,
         -0.0975, -0.0961, -0.0543, -0.0984, -0.0744, -0.1308, -0.2104, -0.1640,
         -0.1807],
        [-0.0128, -0.0319, -0.0722, -0.0277, -0.0695, -0.0518, -0.1083, -0.0795,
         -0.0400, -0.0940, -0.1000, -0.0588, -0.1536, -0.0683, -0.0913, -0.1077,
         -0.0887, -0.0909, -0.0487, -0.0958, -0.0721, -0.1299, -0.2159, -0.1631,
         -0.1823],
        [-0.0494, -0.1032, -0.0425, -0.0608, -0.0577, -0.0410, -0.0936, -0.0979,
         -0.0247, -0.0816, -0.0916, -0.0575, -0.1525, -0.0641, -0.0890, -0.1077,
         -0.0882, -0.0830, -0.0418, -0.0952, -0.0682, -0.1243, -0.2065, -0.1586,
         -0.1705],
        [-0.0263, -0.0706, -0.0731, -0.0073, -0.0747, -0.0418, -0.0995, -0.0768,
         -0.0315, -0.0836, -0.0961, -0.0566, -0.1491, -0.0629, -0.0889, -0.1074,
         -0.0906, -0.0902, -0.0441, -0.0945, -0.0710, -0.1279, -0.2144, -0.1644,
         -0.1784],
        [-0.0630, -0.1096, -0.0655, -0.0701, -0.0388, -0.0469, -0.0913, -0.0951,
         -0.0215, -0.0826, -0.0863, -0.0551, -0.1535, -0.0624, -0.0863, -0.1044,
         -0.0835, -0.0822, -0.0428, -0.0930, -0.0670, -0.1236, -0.2061, -0.1575,
         -0.1735],
        [-0.0718, -0.1312, -0.0907, -0.0793, -0.0877, -0.0107, -0.1127, -0.1067,
         -0.0313, -0.0742, -0.1012, -0.0440, -0.1367, -0.0552, -0.0846, -0.1055,
         -0.0884, -0.0827, -0.0389, -0.0862, -0.0615, -0.1205, -0.2047, -0.1618,
         -0.1748],
        [-0.0793, -0.1265, -0.0810, -0.0754, -0.0712, -0.0513, -0.0743, -0.0892,
         -0.0169, -0.0699, -0.0784, -0.0506, -0.1418, -0.0542, -0.0761, -0.0933,
         -0.0771, -0.0772, -0.0314, -0.0843, -0.0602, -0.1161, -0.2003, -0.1552,
         -0.1696],
        [-0.0651, -0.1077, -0.0947, -0.0629, -0.0846, -0.0547, -0.0993, -0.0196,
         -0.0257, -0.0732, -0.0874, -0.0418, -0.1299, -0.0429, -0.0636, -0.0804,
         -0.0631, -0.0802, -0.0341, -0.0714, -0.0574, -0.1132, -0.1973, -0.1526,
         -0.1723],
        [-0.0800, -0.1363, -0.0909, -0.0856, -0.0792, -0.0479, -0.0953, -0.0947,
          0.0046, -0.0633, -0.0806, -0.0428, -0.1375, -0.0510, -0.0717, -0.0902,
         -0.0730, -0.0717, -0.0297, -0.0824, -0.0551, -0.1124, -0.1920, -0.1528,
         -0.1688],
        [-0.0950, -0.1477, -0.1055, -0.0954, -0.0985, -0.0481, -0.1060, -0.0991,
         -0.0207, -0.0366, -0.0780, -0.0379, -0.1227, -0.0397, -0.0576, -0.0760,
         -0.0610, -0.0639, -0.0144, -0.0669, -0.0427, -0.0982, -0.1819, -0.1463,
         -0.1613],
        [-0.1049, -0.1476, -0.1076, -0.1000, -0.0943, -0.0663, -0.1066, -0.1057,
         -0.0299, -0.0697, -0.0524, -0.0393, -0.1318, -0.0393, -0.0570, -0.0759,
         -0.0590, -0.0577, -0.0120, -0.0671, -0.0414, -0.1026, -0.1894, -0.1453,
         -0.1612],
        [-0.1138, -0.1608, -0.1295, -0.1155, -0.1194, -0.0653, -0.1341, -0.1147,
         -0.0484, -0.0852, -0.0968,  0.0013, -0.1041, -0.0285, -0.0564, -0.0797,
         -0.0643, -0.0593, -0.0213, -0.0579, -0.0373, -0.0994, -0.1925, -0.1419,
         -0.1605],
        [-0.1180, -0.1658, -0.1336, -0.1186, -0.1266, -0.0682, -0.1358, -0.1139,
         -0.0535, -0.0811, -0.0995, -0.0160, -0.0855, -0.0279, -0.0525, -0.0725,
         -0.0623, -0.0638, -0.0134, -0.0489, -0.0339, -0.0924, -0.1836, -0.1379,
         -0.1550],
        [-0.1226, -0.1668, -0.1323, -0.1187, -0.1231, -0.0739, -0.1353, -0.1137,
         -0.0530, -0.0837, -0.0928, -0.0254, -0.1137,  0.0019, -0.0458, -0.0700,
         -0.0505, -0.0505, -0.0062, -0.0503, -0.0307, -0.0909, -0.1846, -0.1370,
         -0.1520],
        [-0.1294, -0.1721, -0.1406, -0.1276, -0.1296, -0.0855, -0.1401, -0.1168,
         -0.0571, -0.0858, -0.0941, -0.0360, -0.1211, -0.0293, -0.0094, -0.0368,
         -0.0237, -0.0342,  0.0129, -0.0264, -0.0101, -0.0694, -0.1612, -0.1194,
         -0.1389],
        [-0.1324, -0.1752, -0.1449, -0.1329, -0.1340, -0.0930, -0.1438, -0.1187,
         -0.0612, -0.0902, -0.0991, -0.0466, -0.1283, -0.0406, -0.0231, -0.0072,
         -0.0154, -0.0409,  0.0177, -0.0124,  0.0011, -0.0550, -0.1397, -0.1044,
         -0.1308],
        [-0.1286, -0.1701, -0.1396, -0.1297, -0.1272, -0.0895, -0.1412, -0.1155,
         -0.0583, -0.0894, -0.0954, -0.0441, -0.1310, -0.0333, -0.0229, -0.0290,
          0.0080, -0.0287,  0.0162, -0.0166, -0.0018, -0.0575, -0.1431, -0.1037,
         -0.1336],
        [-0.1373, -0.1828, -0.1442, -0.1383, -0.1338, -0.0934, -0.1499, -0.1424,
         -0.0657, -0.1005, -0.1033, -0.0469, -0.1419, -0.0435, -0.0432, -0.0627,
         -0.0380,  0.0072,  0.0188, -0.0344,  0.0091, -0.0560, -0.1460, -0.0963,
         -0.1124],
        [-0.1373, -0.1822, -0.1447, -0.1347, -0.1374, -0.0918, -0.1472, -0.1390,
         -0.0668, -0.0941, -0.1008, -0.0525, -0.1344, -0.0427, -0.0391, -0.0465,
         -0.0361, -0.0239,  0.0602, -0.0139,  0.0147, -0.0443, -0.1366, -0.0929,
         -0.1011],
        [-0.1444, -0.1903, -0.1599, -0.1474, -0.1488, -0.1016, -0.1619, -0.1378,
         -0.0813, -0.1095, -0.1185, -0.0529, -0.1328, -0.0497, -0.0420, -0.0405,
         -0.0313, -0.0416,  0.0226,  0.0230,  0.0268, -0.0313, -0.1293, -0.0800,
         -0.1104],
        [-0.1480, -0.1962, -0.1613, -0.1514, -0.1511, -0.1047, -0.1657, -0.1519,
         -0.0820, -0.1132, -0.1212, -0.0596, -0.1457, -0.0576, -0.0528, -0.0546,
         -0.0437, -0.0254,  0.0236, -0.0002,  0.0519, -0.0198, -0.1193, -0.0641,
         -0.0922],
        [-0.1491, -0.1980, -0.1617, -0.1523, -0.1524, -0.1072, -0.1652, -0.1511,
         -0.0829, -0.1117, -0.1246, -0.0659, -0.1473, -0.0610, -0.0555, -0.0534,
         -0.0425, -0.0326,  0.0219, -0.0022,  0.0372,  0.0155, -0.0910, -0.0410,
         -0.0672],
        [-0.1394, -0.1958, -0.1542, -0.1507, -0.1447, -0.1018, -0.1597, -0.1460,
         -0.0718, -0.1048, -0.1205, -0.0684, -0.1490, -0.0652, -0.0560, -0.0489,
         -0.0377, -0.0319,  0.0192, -0.0115,  0.0269, -0.0023, -0.0393, -0.0353,
         -0.0592],
        [-0.1507, -0.1994, -0.1641, -0.1572, -0.1535, -0.1163, -0.1718, -0.1585,
         -0.0919, -0.1280, -0.1347, -0.0762, -0.1612, -0.0748, -0.0730, -0.0709,
         -0.0574, -0.0403,  0.0043, -0.0194,  0.0252, -0.0102, -0.0926,  0.0009,
         -0.0419],
        [-0.1487, -0.2001, -0.1576, -0.1518, -0.1505, -0.1109, -0.1661, -0.1597,
         -0.0880, -0.1221, -0.1302, -0.0751, -0.1585, -0.0695, -0.0722, -0.0747,
         -0.0664, -0.0363,  0.0168, -0.0283,  0.0179, -0.0151, -0.0952, -0.0211,
          0.0075]], device='cuda:0')
Wed 19 Nov 2025 11:30:19 INFO  Mean influence score: [-0.04423477128148079, -0.040460024029016495, -0.037755027413368225, -0.03599698841571808, -0.036786340177059174, -0.038263093680143356, -0.03385157138109207, -0.03332274407148361, -0.033613432198762894, -0.032384857535362244, -0.03257370740175247, -0.035918720066547394, -0.034461911767721176, -0.03168080374598503, -0.033480942249298096, -0.036299630999565125, -0.034484900534152985, -0.03465070202946663, -0.03255986422300339, -0.03732989728450775, -0.03627907857298851, -0.03584049642086029, -0.04070880636572838, -0.0396120660007, -0.0410626120865345]
Wed 19 Nov 2025 11:30:19 INFO  Stage 3 selected prob: [0.03967750445008278, 0.03982756286859512, 0.03993543982505798, 0.04000570625066757, 0.039974141865968704, 0.03991515561938286, 0.040091630071401596, 0.04011283814907074, 0.040101177990436554, 0.0401504747569561, 0.04014289379119873, 0.04000884294509888, 0.0400671660900116, 0.040178753435611725, 0.04010649025440216, 0.03999360278248787, 0.04006624594330788, 0.04005960747599602, 0.0401434488594532, 0.03995241969823837, 0.03999442607164383, 0.040011968463659286, 0.039817653596401215, 0.039861347526311874, 0.03980356827378273]
Wed 19 Nov 2025 11:31:51 INFO  [Epoch 121] Train Loss: 1.9703712110332554
Wed 19 Nov 2025 11:33:24 INFO  [Epoch 122] Train Loss: 1.9697931057183296
Wed 19 Nov 2025 11:34:55 INFO  [Epoch 123] Train Loss: 1.9664097106268106
Wed 19 Nov 2025 11:36:28 INFO  [Epoch 124] Train Loss: 1.9637335043880575
Wed 19 Nov 2025 11:38:09 INFO  [Epoch 125] Train Loss: 1.9614260671905943
Wed 19 Nov 2025 11:39:50 INFO  [Epoch 126] Train Loss: 1.9594642484466565
Wed 19 Nov 2025 11:41:32 INFO  [Epoch 127] Train Loss: 1.956942582543667
Wed 19 Nov 2025 11:43:13 INFO  [Epoch 128] Train Loss: 1.9546117256167426
Wed 19 Nov 2025 11:44:55 INFO  [Epoch 129] Train Loss: 1.9517932736792776
Wed 19 Nov 2025 11:46:36 INFO  [Epoch 130] Train Loss: 1.9494769700775492
Wed 19 Nov 2025 11:46:36 INFO  [Epoch 130] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_130.pth
Wed 19 Nov 2025 11:48:16 INFO  [Epoch 131] Train Loss: 1.9461157418950303
Wed 19 Nov 2025 11:49:57 INFO  [Epoch 132] Train Loss: 1.944395686327827
Wed 19 Nov 2025 11:51:32 INFO  [Epoch 133] Train Loss: 1.9421669479232133
Wed 19 Nov 2025 11:53:04 INFO  [Epoch 134] Train Loss: 1.938744076500284
Wed 19 Nov 2025 11:54:32 INFO  [Epoch 135] Train Loss: 1.9364211606907502
Wed 19 Nov 2025 11:56:00 INFO  [Epoch 136] Train Loss: 1.9342819041745862
Wed 19 Nov 2025 11:57:24 INFO  [Epoch 137] Train Loss: 1.9323902705062488
Wed 19 Nov 2025 11:58:50 INFO  [Epoch 138] Train Loss: 1.9284498067214781
Wed 19 Nov 2025 12:00:16 INFO  [Epoch 139] Train Loss: 1.926269246656911
Wed 19 Nov 2025 12:01:43 INFO  [Epoch 140] Train Loss: 1.9236672405201236
Wed 19 Nov 2025 12:01:43 INFO  [Epoch 140] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_140.pth
Wed 19 Nov 2025 12:01:43 INFO  Best epoch: 0, Best val score: -1
Wed 19 Nov 2025 12:01:43 INFO  [Epoch 141] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8.pth
Wed 19 Nov 2025 12:01:43 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Wed 19 Nov 2025 12:44:13 INFO  Influence scores: tensor([[0.2615, 0.2635, 0.2148, 0.2624, 0.1784, 0.2486, 0.2277, 0.2291, 0.1948,
         0.2473, 0.2549, 0.1933, 0.2406, 0.1444, 0.2007, 0.1461, 0.1692, 0.1638,
         0.1629, 0.1391, 0.1876, 0.1277, 0.0450, 0.0795, 0.1463],
        [0.2289, 0.3059, 0.2133, 0.2713, 0.1861, 0.2372, 0.2333, 0.2423, 0.1878,
         0.2451, 0.2696, 0.1984, 0.2456, 0.1541, 0.2119, 0.1596, 0.1829, 0.1719,
         0.1712, 0.1466, 0.1922, 0.1307, 0.0402, 0.0824, 0.1454],
        [0.1957, 0.2276, 0.2471, 0.2436, 0.1970, 0.2480, 0.2474, 0.2275, 0.2033,
         0.2585, 0.2761, 0.1957, 0.2444, 0.1557, 0.2118, 0.1545, 0.1795, 0.1782,
         0.1769, 0.1434, 0.1934, 0.1341, 0.0485, 0.0840, 0.1562],
        [0.2085, 0.2523, 0.2096, 0.2928, 0.1775, 0.2456, 0.2398, 0.2402, 0.1955,
         0.2541, 0.2706, 0.1978, 0.2479, 0.1562, 0.2120, 0.1542, 0.1768, 0.1700,
         0.1748, 0.1422, 0.1896, 0.1288, 0.0382, 0.0772, 0.1464],
        [0.1715, 0.2135, 0.2128, 0.2267, 0.2142, 0.2331, 0.2417, 0.2254, 0.2010,
         0.2491, 0.2747, 0.1929, 0.2333, 0.1519, 0.2068, 0.1517, 0.1786, 0.1747,
         0.1672, 0.1375, 0.1886, 0.1290, 0.0416, 0.0809, 0.1435],
        [0.1689, 0.1921, 0.1862, 0.2189, 0.1587, 0.2851, 0.2228, 0.2159, 0.1961,
         0.2670, 0.2640, 0.2133, 0.2632, 0.1656, 0.2165, 0.1558, 0.1789, 0.1792,
         0.1806, 0.1528, 0.2009, 0.1385, 0.0500, 0.0802, 0.1488],
        [0.1564, 0.1945, 0.1945, 0.2226, 0.1754, 0.2312, 0.2671, 0.2359, 0.2105,
         0.2688, 0.2891, 0.2013, 0.2530, 0.1635, 0.2244, 0.1696, 0.1917, 0.1830,
         0.1867, 0.1523, 0.2008, 0.1412, 0.0529, 0.0855, 0.1532],
        [0.1587, 0.2058, 0.1751, 0.2215, 0.1583, 0.2255, 0.2368, 0.3116, 0.1985,
         0.2652, 0.2784, 0.2108, 0.2669, 0.1755, 0.2371, 0.1859, 0.2068, 0.1761,
         0.1822, 0.1688, 0.2022, 0.1427, 0.0555, 0.0854, 0.1456],
        [0.1503, 0.1768, 0.1770, 0.2029, 0.1598, 0.2305, 0.2348, 0.2251, 0.2323,
         0.2716, 0.2809, 0.2064, 0.2520, 0.1634, 0.2235, 0.1683, 0.1904, 0.1849,
         0.1835, 0.1508, 0.2015, 0.1418, 0.0592, 0.0848, 0.1494],
        [0.1259, 0.1579, 0.1551, 0.1858, 0.1323, 0.2253, 0.2182, 0.2145, 0.1952,
         0.3011, 0.2777, 0.2059, 0.2641, 0.1719, 0.2347, 0.1797, 0.1993, 0.1876,
         0.1968, 0.1627, 0.2095, 0.1526, 0.0662, 0.0858, 0.1518],
        [0.1230, 0.1681, 0.1610, 0.1905, 0.1468, 0.2106, 0.2253, 0.2140, 0.1928,
         0.2659, 0.3203, 0.2122, 0.2614, 0.1814, 0.2454, 0.1878, 0.2117, 0.2070,
         0.2085, 0.1697, 0.2203, 0.1570, 0.0646, 0.0976, 0.1613],
        [0.1184, 0.1568, 0.1388, 0.1746, 0.1207, 0.2178, 0.1974, 0.2067, 0.1757,
         0.2534, 0.2711, 0.2663, 0.3016, 0.1970, 0.2478, 0.1881, 0.2066, 0.2082,
         0.2030, 0.1869, 0.2300, 0.1631, 0.0635, 0.1040, 0.1640],
        [0.1003, 0.1373, 0.1240, 0.1603, 0.1012, 0.2031, 0.1831, 0.1961, 0.1592,
         0.2473, 0.2528, 0.2344, 0.3085, 0.1873, 0.2409, 0.1825, 0.1987, 0.1912,
         0.2000, 0.1834, 0.2219, 0.1611, 0.0635, 0.0989, 0.1604],
        [0.1006, 0.1416, 0.1295, 0.1642, 0.1098, 0.2006, 0.1885, 0.2008, 0.1634,
         0.2494, 0.2674, 0.2262, 0.2804, 0.2280, 0.2563, 0.1917, 0.2193, 0.2131,
         0.2155, 0.1881, 0.2323, 0.1690, 0.0686, 0.1048, 0.1707],
        [0.0824, 0.1270, 0.1098, 0.1446, 0.0923, 0.1770, 0.1745, 0.1899, 0.1486,
         0.2372, 0.2591, 0.2037, 0.2640, 0.1825, 0.2913, 0.2236, 0.2424, 0.2210,
         0.2293, 0.2081, 0.2469, 0.1844, 0.0861, 0.1151, 0.1750],
        [0.0796, 0.1268, 0.1047, 0.1387, 0.0882, 0.1672, 0.1725, 0.1892, 0.1441,
         0.2322, 0.2559, 0.1940, 0.2604, 0.1715, 0.2743, 0.2651, 0.2542, 0.2145,
         0.2364, 0.2281, 0.2620, 0.2035, 0.1132, 0.1342, 0.1853],
        [0.0829, 0.1304, 0.1100, 0.1415, 0.0957, 0.1711, 0.1729, 0.1918, 0.1470,
         0.2332, 0.2572, 0.1938, 0.2511, 0.1767, 0.2744, 0.2355, 0.2824, 0.2273,
         0.2317, 0.2208, 0.2572, 0.2007, 0.1089, 0.1335, 0.1808],
        [0.0795, 0.1206, 0.1124, 0.1375, 0.0939, 0.1742, 0.1674, 0.1631, 0.1442,
         0.2231, 0.2531, 0.1977, 0.2463, 0.1716, 0.2546, 0.1961, 0.2294, 0.2785,
         0.2407, 0.2018, 0.2725, 0.2069, 0.1084, 0.1490, 0.2107],
        [0.0792, 0.1208, 0.1097, 0.1418, 0.0878, 0.1754, 0.1717, 0.1680, 0.1431,
         0.2327, 0.2557, 0.1906, 0.2563, 0.1734, 0.2614, 0.2167, 0.2320, 0.2399,
         0.2924, 0.2290, 0.2826, 0.2224, 0.1223, 0.1536, 0.2259],
        [0.0713, 0.1108, 0.0908, 0.1242, 0.0743, 0.1645, 0.1538, 0.1685, 0.1253,
         0.2149, 0.2353, 0.1918, 0.2584, 0.1648, 0.2573, 0.2251, 0.2392, 0.2190,
         0.2465, 0.2749, 0.2982, 0.2372, 0.1306, 0.1684, 0.2161],
        [0.0650, 0.1020, 0.0899, 0.1191, 0.0724, 0.1592, 0.1465, 0.1497, 0.1230,
         0.2075, 0.2277, 0.1827, 0.2384, 0.1547, 0.2410, 0.2039, 0.2208, 0.2351,
         0.2456, 0.2411, 0.3244, 0.2497, 0.1409, 0.1879, 0.2354],
        [0.0671, 0.1042, 0.0910, 0.1200, 0.0718, 0.1574, 0.1516, 0.1541, 0.1244,
         0.2115, 0.2309, 0.1769, 0.2437, 0.1525, 0.2428, 0.2123, 0.2265, 0.2300,
         0.2480, 0.2468, 0.3111, 0.2945, 0.1772, 0.2160, 0.2667],
        [0.0643, 0.0925, 0.0872, 0.1107, 0.0680, 0.1498, 0.1445, 0.1483, 0.1241,
         0.2066, 0.2180, 0.1602, 0.2229, 0.1340, 0.2253, 0.2026, 0.2173, 0.2143,
         0.2285, 0.2189, 0.2826, 0.2593, 0.2303, 0.2092, 0.2629],
        [0.0690, 0.1053, 0.0955, 0.1213, 0.0776, 0.1526, 0.1464, 0.1484, 0.1197,
         0.1958, 0.2169, 0.1706, 0.2248, 0.1398, 0.2232, 0.1898, 0.2106, 0.2241,
         0.2276, 0.2241, 0.2978, 0.2678, 0.1799, 0.2747, 0.3037],
        [0.0670, 0.1005, 0.0978, 0.1213, 0.0738, 0.1518, 0.1484, 0.1411, 0.1176,
         0.1963, 0.2168, 0.1642, 0.2247, 0.1387, 0.2184, 0.1785, 0.1925, 0.2202,
         0.2358, 0.2080, 0.2811, 0.2528, 0.1681, 0.2372, 0.3552]],
       device='cuda:0')
Wed 19 Nov 2025 12:44:13 INFO  Mean influence score: [-0.024659914895892143, -0.020781850442290306, -0.018390245735645294, -0.016879646107554436, -0.018128257244825363, -0.019286099821329117, -0.014892269857227802, -0.014166642911732197, -0.015020444057881832, -0.014043963514268398, -0.013724065385758877, -0.0169315617531538, -0.016483906656503677, -0.013324116356670856, -0.015187107026576996, -0.017501622438430786, -0.015796752646565437, -0.01620127446949482, -0.01377893891185522, -0.018561387434601784, -0.01792646199464798, -0.01696965843439102, -0.022257089614868164, -0.020833920687437057, -0.022495441138744354]
Wed 19 Nov 2025 12:44:13 INFO  Stage 4 selected prob: [0.039709243923425674, 0.03986353799700737, 0.03995898738503456, 0.04001940041780472, 0.039969462901353836, 0.039923205971717834, 0.04009900987148285, 0.04012811928987503, 0.04009387269616127, 0.0401330403983593, 0.040145885199308395, 0.040017321705818176, 0.04003524035215378, 0.040161944925785065, 0.04008718952536583, 0.03999451547861099, 0.04006275534629822, 0.04004655033349991, 0.040143679827451706, 0.039952151477336884, 0.03997752442955971, 0.04001579433679581, 0.03980477154254913, 0.03986146301031113, 0.03979528695344925]
Wed 19 Nov 2025 12:45:52 INFO  [Epoch 141] Train Loss: 1.920942841478102
Wed 19 Nov 2025 12:47:29 INFO  [Epoch 142] Train Loss: 1.9178428961625202
Wed 19 Nov 2025 12:49:08 INFO  [Epoch 143] Train Loss: 1.915908793263985
Wed 19 Nov 2025 12:50:47 INFO  [Epoch 144] Train Loss: 1.9129318156095043
Wed 19 Nov 2025 12:52:25 INFO  [Epoch 145] Train Loss: 1.9098624757293838
Wed 19 Nov 2025 12:54:02 INFO  [Epoch 146] Train Loss: 1.9071176133842151
Wed 19 Nov 2025 12:55:39 INFO  [Epoch 147] Train Loss: 1.9030188082211343
Wed 19 Nov 2025 12:57:17 INFO  [Epoch 148] Train Loss: 1.9012839170713216
Wed 19 Nov 2025 12:58:55 INFO  [Epoch 149] Train Loss: 1.898119146786153
Wed 19 Nov 2025 13:00:33 INFO  [Epoch 150] Train Loss: 1.8951875796062927
Wed 19 Nov 2025 13:00:33 INFO  [Epoch 150] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_150.pth
Wed 19 Nov 2025 13:02:10 INFO  [Epoch 151] Train Loss: 1.8913606270507664
Wed 19 Nov 2025 13:03:46 INFO  [Epoch 152] Train Loss: 1.889303005631022
Wed 19 Nov 2025 13:05:18 INFO  [Epoch 153] Train Loss: 1.8865833843931186
Wed 19 Nov 2025 13:06:49 INFO  [Epoch 154] Train Loss: 1.8832209190211981
Wed 19 Nov 2025 13:08:20 INFO  [Epoch 155] Train Loss: 1.8805116406040436
Wed 19 Nov 2025 13:09:51 INFO  [Epoch 156] Train Loss: 1.87699156474061
Wed 19 Nov 2025 13:11:22 INFO  [Epoch 157] Train Loss: 1.8737648334733148
Wed 19 Nov 2025 13:12:51 INFO  [Epoch 158] Train Loss: 1.8704028756616704
Wed 19 Nov 2025 13:14:22 INFO  [Epoch 159] Train Loss: 1.8667868129633922
Wed 19 Nov 2025 13:15:53 INFO  [Epoch 160] Train Loss: 1.8638351543019747
Wed 19 Nov 2025 13:15:53 INFO  [Epoch 160] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_160.pth
Wed 19 Nov 2025 13:15:53 INFO  Best epoch: 0, Best val score: -1
Wed 19 Nov 2025 13:15:53 INFO  [Epoch 161] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8.pth
Wed 19 Nov 2025 13:15:53 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Wed 19 Nov 2025 14:01:03 INFO  Influence scores: tensor([[ 1.7176e-02, -2.4570e-02, -7.6356e-02, -5.8963e-02, -5.2807e-02,
         -4.4108e-02, -1.0782e-01, -5.5756e-02, -1.4211e-01, -9.3500e-02,
         -8.9333e-03, -2.3417e-02,  6.8542e-02,  2.2164e-02, -6.0932e-02,
         -1.5772e-02,  1.0002e-02, -5.7502e-02,  6.0873e-02,  1.9078e-02,
          5.8973e-02,  4.6489e-02, -7.9601e-02, -8.9262e-03, -2.5585e-02],
        [-2.2748e-02,  2.6970e-02, -7.6668e-02, -4.2826e-02, -3.9682e-02,
         -5.3696e-02, -9.9017e-02, -3.9460e-02, -1.4776e-01, -9.1929e-02,
          9.4074e-03, -1.5314e-02,  7.5681e-02,  3.6347e-02, -4.4546e-02,
          1.4639e-03,  2.9597e-02, -4.3484e-02,  7.4532e-02,  2.9139e-02,
          6.8625e-02,  5.2811e-02, -8.4775e-02, -1.6662e-03, -2.2976e-02],
        [-6.2564e-02, -6.5489e-02, -3.9531e-02, -7.7129e-02, -3.0933e-02,
         -4.6922e-02, -8.8387e-02, -5.9188e-02, -1.3465e-01, -8.2626e-02,
          1.3512e-02, -2.3532e-02,  6.9300e-02,  3.4040e-02, -5.1997e-02,
         -8.4001e-03,  1.7870e-02, -4.1744e-02,  7.5473e-02,  2.1095e-02,
          6.4650e-02,  5.1591e-02, -8.0963e-02, -4.3587e-03, -1.5813e-02],
        [-5.0503e-02, -4.0034e-02, -8.6212e-02, -2.2101e-02, -5.5844e-02,
         -4.9878e-02, -9.7774e-02, -4.5392e-02, -1.4496e-01, -8.7621e-02,
          6.6255e-03, -1.6691e-02,  7.4899e-02,  3.4956e-02, -5.0590e-02,
         -9.4911e-03,  1.4411e-02, -5.2227e-02,  7.2904e-02,  1.9490e-02,
          5.9440e-02,  4.6911e-02, -9.2733e-02, -1.3092e-02, -2.6310e-02],
        [-8.7531e-02, -7.8370e-02, -7.9114e-02, -9.4487e-02, -5.2398e-03,
         -5.9311e-02, -8.9163e-02, -5.7854e-02, -1.3306e-01, -8.8828e-02,
          1.7942e-02, -2.4682e-02,  6.3042e-02,  3.1856e-02, -5.0831e-02,
         -7.4565e-03,  2.2994e-02, -4.2953e-02,  7.0639e-02,  2.0950e-02,
          6.3164e-02,  4.9205e-02, -8.4178e-02, -6.3829e-03, -2.5163e-02],
        [-9.6943e-02, -1.1003e-01, -1.1461e-01, -1.0842e-01, -7.9444e-02,
         -1.3394e-03, -1.1956e-01, -7.5053e-02, -1.4536e-01, -7.4790e-02,
         -3.2283e-03, -1.1158e-03,  9.1466e-02,  4.3525e-02, -4.6514e-02,
         -8.3831e-03,  1.6579e-02, -4.0570e-02,  8.0455e-02,  3.1557e-02,
          7.2730e-02,  5.7740e-02, -7.7854e-02, -9.2770e-03, -2.1540e-02],
        [-1.1730e-01, -1.1110e-01, -1.1062e-01, -1.1026e-01, -6.3319e-02,
         -7.4251e-02, -7.1907e-02, -5.8939e-02, -1.3487e-01, -7.7411e-02,
          2.1153e-02, -2.4823e-02,  7.3304e-02,  3.5054e-02, -4.4138e-02,
          8.6400e-04,  2.4362e-02, -4.4719e-02,  8.0014e-02,  2.4112e-02,
          6.3569e-02,  5.2675e-02, -8.2815e-02, -1.1418e-02, -2.5885e-02],
        [-1.1677e-01, -1.0528e-01, -1.3481e-01, -1.1261e-01, -8.3491e-02,
         -8.3777e-02, -1.1208e-01,  3.7718e-02, -1.4965e-01, -8.4253e-02,
          3.6219e-03, -1.2681e-02,  8.6394e-02,  4.8517e-02, -2.8864e-02,
          1.8132e-02,  4.3341e-02, -5.3059e-02,  7.3066e-02,  3.9608e-02,
          6.4110e-02,  5.3934e-02, -8.1116e-02, -1.1134e-02, -3.3249e-02],
        [-1.2507e-01, -1.3328e-01, -1.3111e-01, -1.3247e-01, -8.1660e-02,
         -7.3944e-02, -1.0900e-01, -7.1400e-02, -1.0646e-01, -7.2749e-02,
          1.2964e-02, -1.6986e-02,  7.4187e-02,  3.6515e-02, -4.3050e-02,
          2.4407e-04,  2.4973e-02, -3.9876e-02,  7.8753e-02,  2.3018e-02,
          6.7363e-02,  5.4266e-02, -7.3356e-02, -1.0962e-02, -2.8302e-02],
        [-1.5264e-01, -1.5447e-01, -1.5758e-01, -1.5339e-01, -1.1515e-01,
         -8.0718e-02, -1.3020e-01, -8.3779e-02, -1.5163e-01, -3.5970e-02,
          1.0564e-02, -1.6740e-02,  9.2212e-02,  4.8093e-02, -2.6280e-02,
          1.6739e-02,  3.9059e-02, -3.4373e-02,  9.7726e-02,  3.9962e-02,
          7.8830e-02,  6.9590e-02, -6.2871e-02, -7.0405e-03, -2.0782e-02],
        [-1.6031e-01, -1.4579e-01, -1.5376e-01, -1.5142e-01, -1.0116e-01,
         -1.0092e-01, -1.2505e-01, -8.7808e-02, -1.5812e-01, -8.1492e-02,
          6.0487e-02, -1.2487e-02,  8.4827e-02,  5.6630e-02, -1.7287e-02,
          2.4404e-02,  5.0024e-02, -1.5707e-02,  1.0800e-01,  4.6027e-02,
          8.8305e-02,  7.0263e-02, -6.8673e-02,  2.1220e-03, -1.4545e-02],
        [-1.6651e-01, -1.6084e-01, -1.8099e-01, -1.7006e-01, -1.3279e-01,
         -9.1712e-02, -1.5940e-01, -9.5212e-02, -1.7733e-01, -9.7510e-02,
         -1.7445e-03,  5.5314e-02,  1.2842e-01,  7.3955e-02, -1.3326e-02,
          2.1824e-02,  4.3590e-02, -1.4606e-02,  9.8361e-02,  6.4045e-02,
          1.0037e-01,  7.9943e-02, -6.9471e-02,  9.7663e-03, -9.4956e-03],
        [-1.7546e-01, -1.7097e-01, -1.9004e-01, -1.7734e-01, -1.4700e-01,
         -9.9496e-02, -1.6395e-01, -9.7430e-02, -1.8832e-01, -9.3290e-02,
         -8.6885e-03,  2.6748e-02,  1.5572e-01,  7.2343e-02, -9.1221e-03,
          3.0503e-02,  4.5132e-02, -2.3252e-02,  1.0687e-01,  7.3306e-02,
          1.0141e-01,  8.7383e-02, -5.9909e-02,  1.1473e-02, -3.4130e-03],
        [-1.7721e-01, -1.6804e-01, -1.8317e-01, -1.7248e-01, -1.3522e-01,
         -1.0381e-01, -1.6002e-01, -9.2416e-02, -1.8355e-01, -9.2003e-02,
          6.8779e-03,  1.7895e-02,  1.1837e-01,  1.2410e-01,  7.8445e-03,
          4.1719e-02,  7.0529e-02,  4.5516e-03,  1.2593e-01,  7.9251e-02,
          1.1375e-01,  9.6222e-02, -5.4695e-02,  2.0467e-02,  6.4672e-03],
        [-2.0525e-01, -1.9264e-01, -2.1067e-01, -2.0140e-01, -1.6161e-01,
         -1.3683e-01, -1.8242e-01, -1.1183e-01, -2.0583e-01, -1.1089e-01,
         -9.9457e-03, -1.6003e-02,  9.2329e-02,  6.3939e-02,  4.4507e-02,
          7.3711e-02,  9.4308e-02,  1.0736e-02,  1.3844e-01,  9.7262e-02,
          1.2597e-01,  1.1062e-01, -3.7368e-02,  3.0033e-02,  9.3815e-03],
        [-2.0780e-01, -1.9542e-01, -2.1723e-01, -2.0902e-01, -1.6737e-01,
         -1.4846e-01, -1.8624e-01, -1.1395e-01, -2.1195e-01, -1.1724e-01,
         -1.8054e-02, -2.8579e-02,  8.1361e-02,  4.7762e-02,  2.3361e-02,
          1.1528e-01,  1.0761e-01,  4.4553e-04,  1.4016e-01,  1.1384e-01,
          1.3794e-01,  1.2853e-01, -8.5988e-03,  4.8383e-02,  1.8431e-02],
        [-2.0477e-01, -1.8961e-01, -2.1128e-01, -2.0550e-01, -1.5757e-01,
         -1.4418e-01, -1.8299e-01, -1.0978e-01, -2.0776e-01, -1.1627e-01,
         -1.3854e-02, -3.0573e-02,  7.6244e-02,  5.6206e-02,  2.2638e-02,
          8.6239e-02,  1.4408e-01,  1.7733e-02,  1.4055e-01,  1.1265e-01,
          1.3702e-01,  1.2891e-01, -1.0688e-02,  5.1599e-02,  1.6130e-02],
        [-2.0507e-01, -1.9621e-01, -2.0524e-01, -2.0767e-01, -1.5746e-01,
         -1.3642e-01, -1.8634e-01, -1.3947e-01, -2.0799e-01, -1.2336e-01,
         -1.2806e-02, -2.1130e-02,  7.1875e-02,  5.3616e-02,  4.3589e-03,
          4.5168e-02,  8.3224e-02,  8.4892e-02,  1.5573e-01,  9.6388e-02,
          1.6462e-01,  1.4319e-01, -4.0161e-03,  7.5098e-02,  5.8069e-02],
        [-2.1042e-01, -2.0159e-01, -2.1333e-01, -2.0684e-01, -1.6814e-01,
         -1.4026e-01, -1.8721e-01, -1.3880e-01, -2.1437e-01, -1.1651e-01,
         -1.3748e-02, -3.4720e-02,  7.7239e-02,  5.0494e-02,  7.0337e-03,
          6.0636e-02,  8.0158e-02,  3.1359e-02,  2.1028e-01,  1.1661e-01,
          1.6403e-01,  1.4958e-01,  9.5136e-04,  6.9104e-02,  6.5246e-02],
        [-2.1509e-01, -2.0903e-01, -2.2967e-01, -2.2258e-01, -1.7987e-01,
         -1.5123e-01, -2.0385e-01, -1.3379e-01, -2.3061e-01, -1.3616e-01,
         -3.6854e-02, -2.7931e-02,  8.3886e-02,  4.3381e-02,  6.4578e-03,
          7.1847e-02,  9.2382e-02,  1.0981e-02,  1.5737e-01,  1.7547e-01,
          1.8647e-01,  1.7248e-01,  1.5372e-02,  9.3017e-02,  5.8364e-02],
        [-2.1608e-01, -2.1149e-01, -2.2528e-01, -2.2331e-01, -1.7843e-01,
         -1.4959e-01, -2.0444e-01, -1.5032e-01, -2.2650e-01, -1.3751e-01,
         -3.4739e-02, -3.4528e-02,  7.0180e-02,  3.7092e-02, -5.5910e-03,
          5.5828e-02,  7.7123e-02,  3.8832e-02,  1.6388e-01,  1.4535e-01,
          2.2840e-01,  1.9496e-01,  3.5616e-02,  1.2204e-01,  8.9411e-02],
        [-2.1706e-01, -2.1572e-01, -2.2781e-01, -2.2433e-01, -1.8120e-01,
         -1.5432e-01, -2.0504e-01, -1.4903e-01, -2.2895e-01, -1.3526e-01,
         -4.1499e-02, -4.2694e-02,  6.6650e-02,  3.0986e-02, -9.2735e-03,
          5.7206e-02,  7.9042e-02,  2.8230e-02,  1.5952e-01,  1.4229e-01,
          2.0626e-01,  2.4758e-01,  7.7353e-02,  1.5375e-01,  1.2535e-01],
        [-2.1391e-01, -2.2332e-01, -2.2899e-01, -2.3181e-01, -1.8182e-01,
         -1.5807e-01, -2.0606e-01, -1.5180e-01, -2.2341e-01, -1.3629e-01,
         -4.8307e-02, -6.1875e-02,  5.1847e-02,  1.2573e-02, -2.2904e-02,
          5.4633e-02,  7.4205e-02,  1.4246e-02,  1.4310e-01,  1.1777e-01,
          1.7904e-01,  2.0952e-01,  1.4761e-01,  1.5287e-01,  1.2829e-01],
        [-2.0935e-01, -2.0591e-01, -2.1925e-01, -2.1891e-01, -1.7022e-01,
         -1.5607e-01, -2.0252e-01, -1.4775e-01, -2.2917e-01, -1.4850e-01,
         -4.5141e-02, -4.9189e-02,  5.5803e-02,  2.0484e-02, -2.5276e-02,
          4.2678e-02,  6.8859e-02,  2.4417e-02,  1.4335e-01,  1.2860e-01,
          1.9939e-01,  2.1975e-01,  8.7710e-02,  2.3499e-01,  1.7717e-01],
        [-2.0790e-01, -2.1017e-01, -2.1275e-01, -2.1404e-01, -1.7049e-01,
         -1.5001e-01, -1.9814e-01, -1.5294e-01, -2.2779e-01, -1.4284e-01,
         -4.2172e-02, -4.9933e-02,  5.8644e-02,  2.3125e-02, -2.6759e-02,
          3.2511e-02,  4.9793e-02,  2.6065e-02,  1.5841e-01,  1.1117e-01,
          1.8464e-01,  2.0870e-01,  8.0833e-02,  1.9494e-01,  2.5036e-01]],
       device='cuda:0')
Wed 19 Nov 2025 14:01:03 INFO  Mean influence score: [-0.02468523383140564, -0.020635392516851425, -0.01855076290667057, -0.017164571210741997, -0.018460892140865326, -0.019673103466629982, -0.015517248772084713, -0.014737337827682495, -0.015773765742778778, -0.014854131266474724, -0.014415028505027294, -0.017595216631889343, -0.017211440950632095, -0.013857773505151272, -0.01595527119934559, -0.018145961686968803, -0.01639704592525959, -0.016744524240493774, -0.014407477341592312, -0.01907946728169918, -0.01836317777633667, -0.017320485785603523, -0.022626986727118492, -0.020988846197724342, -0.022592060267925262]
Wed 19 Nov 2025 14:01:03 INFO  Stage 5 selected prob: [0.039726585149765015, 0.039887793362140656, 0.03997103497385979, 0.040026482194662094, 0.039974626153707504, 0.0399261973798275, 0.04009247198700905, 0.040123749524354935, 0.0400821827352047, 0.04011906683444977, 0.040136680006980896, 0.04000924527645111, 0.04002460092306137, 0.04015905782580376, 0.0400749109685421, 0.039987217634916306, 0.040057212114334106, 0.04004329442977905, 0.04013698920607567, 0.03994990512728691, 0.03997853398323059, 0.04002023860812187, 0.03980843350291252, 0.039873700588941574, 0.039809826761484146]
Wed 19 Nov 2025 14:02:35 INFO  [Epoch 161] Train Loss: 1.8611510738719201
Wed 19 Nov 2025 14:04:05 INFO  [Epoch 162] Train Loss: 1.8570695850484427
Wed 19 Nov 2025 14:05:34 INFO  [Epoch 163] Train Loss: 1.8544010177265906
Wed 19 Nov 2025 14:07:03 INFO  [Epoch 164] Train Loss: 1.8503174092775012
Wed 19 Nov 2025 14:08:33 INFO  [Epoch 165] Train Loss: 1.847887282723669
Wed 19 Nov 2025 14:10:02 INFO  [Epoch 166] Train Loss: 1.843557425882013
Wed 19 Nov 2025 14:11:32 INFO  [Epoch 167] Train Loss: 1.8405331367824702
Wed 19 Nov 2025 14:13:02 INFO  [Epoch 168] Train Loss: 1.8374296878636467
Wed 19 Nov 2025 14:14:30 INFO  [Epoch 169] Train Loss: 1.8347616561301776
Wed 19 Nov 2025 14:15:58 INFO  [Epoch 170] Train Loss: 1.830063770836066
Wed 19 Nov 2025 14:15:58 INFO  [Epoch 170] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_170.pth
Wed 19 Nov 2025 14:17:26 INFO  [Epoch 171] Train Loss: 1.8274713258772033
Wed 19 Nov 2025 14:18:55 INFO  [Epoch 172] Train Loss: 1.8242166658586907
Wed 19 Nov 2025 14:20:25 INFO  [Epoch 173] Train Loss: 1.8209810284806447
Wed 19 Nov 2025 14:21:55 INFO  [Epoch 174] Train Loss: 1.8176070287340822
Wed 19 Nov 2025 14:23:24 INFO  [Epoch 175] Train Loss: 1.8146555668982511
Wed 19 Nov 2025 14:24:54 INFO  [Epoch 176] Train Loss: 1.8121319071367978
Wed 19 Nov 2025 14:26:24 INFO  [Epoch 177] Train Loss: 1.8086167520926963
Wed 19 Nov 2025 14:27:53 INFO  [Epoch 178] Train Loss: 1.806030859961578
Wed 19 Nov 2025 14:29:23 INFO  [Epoch 179] Train Loss: 1.8023443496038614
Wed 19 Nov 2025 14:30:54 INFO  [Epoch 180] Train Loss: 1.800161915339288
Wed 19 Nov 2025 14:30:54 INFO  [Epoch 180] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_180.pth
Wed 19 Nov 2025 14:30:54 INFO  Best epoch: 0, Best val score: -1
Wed 19 Nov 2025 14:30:54 INFO  [Epoch 181] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8.pth
Wed 19 Nov 2025 14:30:54 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Wed 19 Nov 2025 15:17:39 INFO  Influence scores: tensor([[ 0.3537,  0.2994,  0.2130,  0.2954,  0.2863,  0.2926,  0.1978,  0.2601,
          0.2406,  0.1508,  0.1786,  0.1115,  0.1346,  0.0959,  0.0919,  0.1308,
          0.1099,  0.0845,  0.0363,  0.1247,  0.0714,  0.0324,  0.0250, -0.0011,
         -0.0482],
        [ 0.2976,  0.3572,  0.2064,  0.3051,  0.2964,  0.2740,  0.2021,  0.2726,
          0.2275,  0.1424,  0.1958,  0.1154,  0.1358,  0.1057,  0.1046,  0.1445,
          0.1258,  0.0938,  0.0462,  0.1301,  0.0754,  0.0310,  0.0103, -0.0004,
         -0.0542],
        [ 0.2452,  0.2381,  0.2492,  0.2572,  0.3045,  0.2785,  0.2134,  0.2456,
          0.2418,  0.1511,  0.1968,  0.1020,  0.1251,  0.0997,  0.0938,  0.1301,
          0.1111,  0.0931,  0.0457,  0.1156,  0.0678,  0.0288,  0.0159, -0.0067,
         -0.0446],
        [ 0.2614,  0.2729,  0.1944,  0.3289,  0.2757,  0.2775,  0.2040,  0.2633,
          0.2295,  0.1483,  0.1898,  0.1069,  0.1346,  0.1025,  0.0959,  0.1299,
          0.1085,  0.0807,  0.0444,  0.1163,  0.0633,  0.0219,  0.0006, -0.0169,
         -0.0570],
        [ 0.2168,  0.2246,  0.2016,  0.2369,  0.3357,  0.2639,  0.2122,  0.2473,
          0.2434,  0.1440,  0.2019,  0.1008,  0.1183,  0.0981,  0.0938,  0.1322,
          0.1162,  0.0933,  0.0392,  0.1153,  0.0672,  0.0255,  0.0113, -0.0081,
         -0.0569],
        [ 0.1971,  0.1743,  0.1496,  0.2133,  0.2375,  0.3222,  0.1663,  0.2173,
          0.2177,  0.1511,  0.1637,  0.1148,  0.1424,  0.1004,  0.0862,  0.1172,
          0.0974,  0.0803,  0.0358,  0.1159,  0.0651,  0.0215,  0.0050, -0.0247,
         -0.0649],
        [ 0.1817,  0.1838,  0.1631,  0.2188,  0.2658,  0.2453,  0.2333,  0.2461,
          0.2415,  0.1579,  0.2058,  0.0996,  0.1310,  0.1012,  0.1031,  0.1425,
          0.1200,  0.0896,  0.0504,  0.1206,  0.0678,  0.0288,  0.0128, -0.0153,
         -0.0579],
        [ 0.1795,  0.1898,  0.1332,  0.2144,  0.2382,  0.2347,  0.1853,  0.3623,
          0.2226,  0.1502,  0.1837,  0.1123,  0.1455,  0.1169,  0.1204,  0.1609,
          0.1399,  0.0769,  0.0402,  0.1367,  0.0653,  0.0272,  0.0115, -0.0186,
         -0.0713],
        [ 0.1683,  0.1535,  0.1344,  0.1876,  0.2392,  0.2421,  0.1850,  0.2287,
          0.2717,  0.1594,  0.1900,  0.1041,  0.1285,  0.0988,  0.0994,  0.1370,
          0.1161,  0.0888,  0.0424,  0.1145,  0.0663,  0.0254,  0.0186, -0.0208,
         -0.0662],
        [ 0.1373,  0.1274,  0.1034,  0.1654,  0.1986,  0.2326,  0.1615,  0.2141,
          0.2174,  0.2014,  0.1863,  0.1045,  0.1470,  0.1096,  0.1165,  0.1547,
          0.1295,  0.0912,  0.0610,  0.1309,  0.0771,  0.0390,  0.0262, -0.0188,
         -0.0607],
        [ 0.1297,  0.1428,  0.1112,  0.1698,  0.2198,  0.2116,  0.1709,  0.2114,
          0.2119,  0.1502,  0.2485,  0.1131,  0.1424,  0.1231,  0.1313,  0.1670,
          0.1459,  0.1196,  0.0792,  0.1445,  0.0936,  0.0459,  0.0223, -0.0034,
         -0.0477],
        [ 0.1174,  0.1194,  0.0750,  0.1453,  0.1775,  0.2189,  0.1242,  0.1984,
          0.1857,  0.1272,  0.1705,  0.1913,  0.1925,  0.1403,  0.1307,  0.1601,
          0.1342,  0.1158,  0.0606,  0.1599,  0.1038,  0.0524,  0.0173,  0.0017,
         -0.0478],
        [ 0.1004,  0.0994,  0.0588,  0.1309,  0.1534,  0.2029,  0.1117,  0.1883,
          0.1647,  0.1248,  0.1547,  0.1477,  0.2174,  0.1305,  0.1280,  0.1613,
          0.1275,  0.0958,  0.0625,  0.1643,  0.0969,  0.0515,  0.0203, -0.0040,
         -0.0480],
        [ 0.1010,  0.1087,  0.0703,  0.1392,  0.1715,  0.2008,  0.1217,  0.1996,
          0.1750,  0.1289,  0.1770,  0.1387,  0.1741,  0.1978,  0.1513,  0.1779,
          0.1627,  0.1316,  0.0893,  0.1734,  0.1139,  0.0666,  0.0299,  0.0093,
         -0.0340],
        [ 0.0706,  0.0805,  0.0372,  0.1049,  0.1412,  0.1625,  0.0966,  0.1781,
          0.1498,  0.1088,  0.1582,  0.1024,  0.1448,  0.1244,  0.2028,  0.2212,
          0.1963,  0.1449,  0.1089,  0.2016,  0.1351,  0.0898,  0.0576,  0.0263,
         -0.0235],
        [ 0.0660,  0.0763,  0.0284,  0.0946,  0.1327,  0.1477,  0.0912,  0.1748,
          0.1413,  0.1022,  0.1479,  0.0841,  0.1321,  0.1045,  0.1762,  0.2705,
          0.2117,  0.1326,  0.1113,  0.2217,  0.1484,  0.1106,  0.0908,  0.0478,
         -0.0142],
        [ 0.0770,  0.0896,  0.0411,  0.1044,  0.1502,  0.1575,  0.0997,  0.1854,
          0.1522,  0.1076,  0.1591,  0.0904,  0.1290,  0.1223,  0.1812,  0.2398,
          0.2591,  0.1592,  0.1166,  0.2247,  0.1525,  0.1154,  0.0938,  0.0577,
         -0.0124],
        [ 0.0727,  0.0788,  0.0479,  0.1011,  0.1494,  0.1648,  0.0947,  0.1461,
          0.1484,  0.0938,  0.1567,  0.0969,  0.1221,  0.1152,  0.1547,  0.1883,
          0.1840,  0.2374,  0.1325,  0.2013,  0.1827,  0.1295,  0.0983,  0.0832,
          0.0375],
        [ 0.0700,  0.0766,  0.0427,  0.1054,  0.1385,  0.1652,  0.0978,  0.1514,
          0.1451,  0.1069,  0.1599,  0.0866,  0.1335,  0.1154,  0.1625,  0.2115,
          0.1879,  0.1770,  0.2013,  0.2319,  0.1865,  0.1420,  0.1086,  0.0820,
          0.0517],
        [ 0.0673,  0.0705,  0.0248,  0.0910,  0.1286,  0.1565,  0.0794,  0.1622,
          0.1302,  0.0886,  0.1363,  0.0953,  0.1438,  0.1107,  0.1648,  0.2275,
          0.2031,  0.1546,  0.1388,  0.3053,  0.2148,  0.1716,  0.1286,  0.1112,
          0.0430],
        [ 0.0605,  0.0608,  0.0225,  0.0830,  0.1238,  0.1514,  0.0721,  0.1336,
          0.1276,  0.0786,  0.1313,  0.0840,  0.1214,  0.0974,  0.1437,  0.2024,
          0.1782,  0.1836,  0.1409,  0.2621,  0.2590,  0.1926,  0.1454,  0.1408,
          0.0747],
        [ 0.0587,  0.0566,  0.0220,  0.0811,  0.1206,  0.1450,  0.0721,  0.1369,
          0.1252,  0.0808,  0.1233,  0.0706,  0.1175,  0.0904,  0.1393,  0.2052,
          0.1806,  0.1687,  0.1369,  0.2594,  0.2324,  0.2540,  0.1970,  0.1779,
          0.1170],
        [ 0.0735,  0.0572,  0.0307,  0.0816,  0.1292,  0.1494,  0.0795,  0.1432,
          0.1411,  0.0910,  0.1236,  0.0591,  0.1076,  0.0771,  0.1321,  0.2085,
          0.1830,  0.1617,  0.1253,  0.2380,  0.2081,  0.2171,  0.2902,  0.1827,
          0.1256],
        [ 0.0817,  0.0806,  0.0452,  0.0996,  0.1463,  0.1578,  0.0874,  0.1502,
          0.1392,  0.0811,  0.1333,  0.0819,  0.1186,  0.0938,  0.1365,  0.2009,
          0.1822,  0.1827,  0.1350,  0.2570,  0.2412,  0.2367,  0.2229,  0.2855,
          0.1907],
        [ 0.0791,  0.0735,  0.0535,  0.1037,  0.1426,  0.1621,  0.0915,  0.1411,
          0.1382,  0.0836,  0.1327,  0.0738,  0.1191,  0.0932,  0.1291,  0.1828,
          0.1569,  0.1797,  0.1495,  0.2323,  0.2184,  0.2211,  0.2107,  0.2357,
          0.2762]], device='cuda:0')
Wed 19 Nov 2025 15:17:39 INFO  Mean influence score: [-0.023011161014437675, -0.018972160294651985, -0.01699991151690483, -0.015635013580322266, -0.016958286985754967, -0.01830100454390049, -0.014095086604356766, -0.013314919546246529, -0.014434815384447575, -0.013546790927648544, -0.013034999370574951, -0.016254469752311707, -0.015962425619363785, -0.01251302845776081, -0.014649746008217335, -0.016815626993775368, -0.01499869767576456, -0.015356224030256271, -0.012995685450732708, -0.01761903427541256, -0.01693905144929886, -0.01586897484958172, -0.021106906235218048, -0.019350124523043633, -0.02097155712544918]
Wed 19 Nov 2025 15:17:39 INFO  Stage 6 selected prob: [0.039735812693834305, 0.039896633476018906, 0.03997539356350899, 0.040029995143413544, 0.0399770587682724, 0.03992341831326485, 0.04009168967604637, 0.04012297838926315, 0.040078070014715195, 0.040113676339387894, 0.040134210139513016, 0.04000520706176758, 0.040016889572143555, 0.040155164897441864, 0.04006945341825485, 0.039982762187719345, 0.04005547612905502, 0.040041156113147736, 0.040135789662599564, 0.0399506539106369, 0.03997782990336418, 0.04002063348889351, 0.03981155529618263, 0.03988155350089073, 0.03981694579124451]
Wed 19 Nov 2025 15:19:32 INFO  [Epoch 181] Train Loss: 1.7959827409261317
Wed 19 Nov 2025 15:21:24 INFO  [Epoch 182] Train Loss: 1.7954696322529498
Wed 19 Nov 2025 15:23:14 INFO  [Epoch 183] Train Loss: 1.792578132060927
Wed 19 Nov 2025 15:24:58 INFO  [Epoch 184] Train Loss: 1.7897136593188392
Wed 19 Nov 2025 15:26:51 INFO  [Epoch 185] Train Loss: 1.7876996267264107
Wed 19 Nov 2025 15:28:45 INFO  [Epoch 186] Train Loss: 1.7861000176381598
Wed 19 Nov 2025 15:30:36 INFO  [Epoch 187] Train Loss: 1.784051169914326
Wed 19 Nov 2025 15:32:28 INFO  [Epoch 188] Train Loss: 1.7814503308966723
Wed 19 Nov 2025 15:34:18 INFO  [Epoch 189] Train Loss: 1.780085734163987
Wed 19 Nov 2025 15:36:08 INFO  [Epoch 190] Train Loss: 1.778348317879344
Wed 19 Nov 2025 15:36:08 INFO  [Epoch 190] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_190.pth
Wed 19 Nov 2025 15:38:00 INFO  [Epoch 191] Train Loss: 1.7770615074988496
Wed 19 Nov 2025 15:39:52 INFO  [Epoch 192] Train Loss: 1.7756436646388902
Wed 19 Nov 2025 15:41:43 INFO  [Epoch 193] Train Loss: 1.7742046970304188
Wed 19 Nov 2025 15:43:35 INFO  [Epoch 194] Train Loss: 1.7742901364932315
Wed 19 Nov 2025 15:45:27 INFO  [Epoch 195] Train Loss: 1.7731705718949584
Wed 19 Nov 2025 15:47:20 INFO  [Epoch 196] Train Loss: 1.7723158493739102
Wed 19 Nov 2025 15:49:13 INFO  [Epoch 197] Train Loss: 1.772077123473799
Wed 19 Nov 2025 15:51:06 INFO  [Epoch 198] Train Loss: 1.7718714514260194
Wed 19 Nov 2025 15:52:58 INFO  [Epoch 199] Train Loss: 1.7718253533644341
Wed 19 Nov 2025 15:54:51 INFO  [Epoch 200] Train Loss: 1.7710757183687258
Wed 19 Nov 2025 15:54:51 INFO  [Epoch 200] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_05-32-b9dbc8/Nov-19-2025_05-32-b9dbc8_200.pth
