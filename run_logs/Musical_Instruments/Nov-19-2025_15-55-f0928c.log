Wed 19 Nov 2025 15:55:00 INFO  Device: cuda
Wed 19 Nov 2025 15:55:00 INFO  Config: {'rand_seed': 2024, 'reproducibility': True, 'num_proc': 1, 'data_dir': 'datasets/Musical_Instruments', 'log_dir': 'run_logs/', 'tensorboard_log_dir': 'tensorboard/', 'ckpt_dir': 'ckpt/Musical_Instruments/Nov-19-2025_15-55-442e92', 'stage': 'pretrain', 'pretrained_model': '', 'epoch_per_stage': [60, 20, 20, 20, 20, 20, 20], 'tau': 3.0, 'load_best_for_next_stage': False, 'train_batch_size': 256, 'eval_batch_size': 256, 'lr': 0.005, 'weight_decay': 0.05, 'warmup_steps': 10000, 'steps': None, 'epochs': 200, 'max_grad_norm': 1.0, 'eval_interval': 1, 'save_interval': 10, 'patience': 50, 'topk': [5, 10], 'metrics': ['ndcg', 'recall'], 'val_metric': 'ndcg@10', 'val_ratio': 1.0, 'val_delay': 199, 'n_codebooks': 3, 'codebook_size': 256, 'expand_final': True, 'token_prefix': 'rqvae/sentence-t5-base_256,256,256,256', 'token_suffix': 'sem_ids', 'n_user_tokens': 1, 'max_item_seq_len': 20, 'num_beams': 20, 'test_num_beams': None, 'num_layers': 6, 'num_decoder_layers': 6, 'd_model': 128, 'd_ff': 512, 'num_heads': 4, 'd_kv': 64, 'dropout_rate': 0.1, 'activation_function': 'relu', 'feed_forward_proj': 'relu', 'results_dir': None, 'sem_id_epochs': [9976, 9977, 9978, 9979, 9980, 9981, 9982, 9983, 9984, 9985, 9986, 9987, 9988, 9989, 9990, 9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 'run_local_time': 'Nov-19-2025_15-55', 'ckpt_name': 'Nov-19-2025_15-55-442e92', 'dataset': 'Musical_Instruments', 'device': device(type='cuda'), 'use_ddp': False, 'accelerator': <accelerate.accelerator.Accelerator object at 0x78fb5cdaf9d0>}
Wed 19 Nov 2025 15:55:00 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9976.sem_ids...
Wed 19 Nov 2025 15:55:00 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9977.sem_ids...
Wed 19 Nov 2025 15:55:00 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9978.sem_ids...
Wed 19 Nov 2025 15:55:00 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9979.sem_ids...
Wed 19 Nov 2025 15:55:00 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9980.sem_ids...
Wed 19 Nov 2025 15:55:00 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9981.sem_ids...
Wed 19 Nov 2025 15:55:00 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9982.sem_ids...
Wed 19 Nov 2025 15:55:00 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9983.sem_ids...
Wed 19 Nov 2025 15:55:01 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9984.sem_ids...
Wed 19 Nov 2025 15:55:01 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9985.sem_ids...
Wed 19 Nov 2025 15:55:01 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9986.sem_ids...
Wed 19 Nov 2025 15:55:01 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9987.sem_ids...
Wed 19 Nov 2025 15:55:01 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9988.sem_ids...
Wed 19 Nov 2025 15:55:01 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9989.sem_ids...
Wed 19 Nov 2025 15:55:01 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9990.sem_ids...
Wed 19 Nov 2025 15:55:02 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9991.sem_ids...
Wed 19 Nov 2025 15:55:02 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9992.sem_ids...
Wed 19 Nov 2025 15:55:02 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9993.sem_ids...
Wed 19 Nov 2025 15:55:02 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9994.sem_ids...
Wed 19 Nov 2025 15:55:02 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9995.sem_ids...
Wed 19 Nov 2025 15:55:02 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9996.sem_ids...
Wed 19 Nov 2025 15:55:02 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9997.sem_ids...
Wed 19 Nov 2025 15:55:02 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9998.sem_ids...
Wed 19 Nov 2025 15:55:02 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_9999.sem_ids...
Wed 19 Nov 2025 15:55:03 INFO  [TOKENIZER] Loading semantic IDs from datasets/Musical_Instruments/rqvae/sentence-t5-base_256,256,256,256_10000.sem_ids...
Wed 19 Nov 2025 15:55:05 INFO  MTGRec(
  (t5): T5ForConditionalGeneration(
    (shared): Embedding(1027, 128)
    (encoder): T5Stack(
      (embed_tokens): Embedding(1027, 128)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
                (relative_attention_bias): Embedding(32, 4)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-5): 5 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (decoder): T5Stack(
      (embed_tokens): Embedding(1027, 128)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
                (relative_attention_bias): Embedding(32, 4)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerCrossAttention(
              (EncDecAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-5): 5 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerCrossAttention(
              (EncDecAttention): T5Attention(
                (q): Linear(in_features=128, out_features=256, bias=False)
                (k): Linear(in_features=128, out_features=256, bias=False)
                (v): Linear(in_features=128, out_features=256, bias=False)
                (o): Linear(in_features=256, out_features=128, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=512, bias=False)
                (wo): Linear(in_features=512, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (lm_head): Linear(in_features=128, out_features=1027, bias=False)
  )
)
Wed 19 Nov 2025 15:55:05 INFO  #Embedding parameters: 131456
#Non-embedding parameters: 3936512
#Total trainable parameters: 4067968

Wed 19 Nov 2025 15:56:56 INFO  [Epoch 1] Train Loss: 3.720107695170606
Wed 19 Nov 2025 15:58:48 INFO  [Epoch 2] Train Loss: 2.747522684534241
Wed 19 Nov 2025 16:00:42 INFO  [Epoch 3] Train Loss: 2.5393304912866106
Wed 19 Nov 2025 16:02:34 INFO  [Epoch 4] Train Loss: 2.4170190838826
Wed 19 Nov 2025 16:04:26 INFO  [Epoch 5] Train Loss: 2.3448485541181987
Wed 19 Nov 2025 16:06:20 INFO  [Epoch 6] Train Loss: 2.3182473964231214
Wed 19 Nov 2025 16:08:13 INFO  [Epoch 7] Train Loss: 2.2942707725458784
Wed 19 Nov 2025 16:10:05 INFO  [Epoch 8] Train Loss: 2.270003493782624
Wed 19 Nov 2025 16:11:59 INFO  [Epoch 9] Train Loss: 2.2443644752516816
Wed 19 Nov 2025 16:13:50 INFO  [Epoch 10] Train Loss: 2.2178103133261247
Wed 19 Nov 2025 16:13:50 INFO  [Epoch 10] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_15-55-442e92/Nov-19-2025_15-55-442e92_10.pth
Wed 19 Nov 2025 16:15:29 INFO  [Epoch 11] Train Loss: 2.204419012076889
Wed 19 Nov 2025 16:17:02 INFO  [Epoch 12] Train Loss: 2.1905502663937924
Wed 19 Nov 2025 16:18:38 INFO  [Epoch 13] Train Loss: 2.1799560284919997
Wed 19 Nov 2025 16:20:11 INFO  [Epoch 14] Train Loss: 2.1708927910940576
Wed 19 Nov 2025 16:21:38 INFO  [Epoch 15] Train Loss: 2.165569611752761
Wed 19 Nov 2025 16:23:05 INFO  [Epoch 16] Train Loss: 2.1578013302243195
Wed 19 Nov 2025 16:24:33 INFO  [Epoch 17] Train Loss: 2.1531851058088933
Wed 19 Nov 2025 16:25:58 INFO  [Epoch 18] Train Loss: 2.1505318338384103
Wed 19 Nov 2025 16:27:23 INFO  [Epoch 19] Train Loss: 2.14633678006515
Wed 19 Nov 2025 16:28:52 INFO  [Epoch 20] Train Loss: 2.1434377026719624
Wed 19 Nov 2025 16:28:52 INFO  [Epoch 20] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_15-55-442e92/Nov-19-2025_15-55-442e92_20.pth
Wed 19 Nov 2025 16:30:24 INFO  [Epoch 21] Train Loss: 2.137698792656652
Wed 19 Nov 2025 16:31:51 INFO  [Epoch 22] Train Loss: 2.1350275588915952
Wed 19 Nov 2025 16:33:18 INFO  [Epoch 23] Train Loss: 2.134971196254394
Wed 19 Nov 2025 16:34:46 INFO  [Epoch 24] Train Loss: 2.130265966787676
Wed 19 Nov 2025 16:36:14 INFO  [Epoch 25] Train Loss: 2.127564528514859
Wed 19 Nov 2025 16:37:43 INFO  [Epoch 26] Train Loss: 2.1304207406910005
Wed 19 Nov 2025 16:39:08 INFO  [Epoch 27] Train Loss: 2.1263620513852772
Wed 19 Nov 2025 16:40:40 INFO  [Epoch 28] Train Loss: 2.1231926976960676
Wed 19 Nov 2025 16:42:11 INFO  [Epoch 29] Train Loss: 2.1221987975658827
Wed 19 Nov 2025 16:43:46 INFO  [Epoch 30] Train Loss: 2.1199237705624543
Wed 19 Nov 2025 16:43:46 INFO  [Epoch 30] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_15-55-442e92/Nov-19-2025_15-55-442e92_30.pth
Wed 19 Nov 2025 16:45:20 INFO  [Epoch 31] Train Loss: 2.1183790273026766
Wed 19 Nov 2025 16:46:55 INFO  [Epoch 32] Train Loss: 2.1158793459463228
Wed 19 Nov 2025 16:48:32 INFO  [Epoch 33] Train Loss: 2.1169991101550267
Wed 19 Nov 2025 16:50:05 INFO  [Epoch 34] Train Loss: 2.112792432353114
Wed 19 Nov 2025 16:51:41 INFO  [Epoch 35] Train Loss: 2.110792346708561
Wed 19 Nov 2025 16:53:22 INFO  [Epoch 36] Train Loss: 2.112656833358339
Wed 19 Nov 2025 16:55:01 INFO  [Epoch 37] Train Loss: 2.10860333877483
Wed 19 Nov 2025 16:56:35 INFO  [Epoch 38] Train Loss: 2.108800799665185
Wed 19 Nov 2025 16:58:14 INFO  [Epoch 39] Train Loss: 2.1116164646924847
Wed 19 Nov 2025 16:59:53 INFO  [Epoch 40] Train Loss: 2.10652090205945
Wed 19 Nov 2025 16:59:53 INFO  [Epoch 40] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_15-55-442e92/Nov-19-2025_15-55-442e92_40.pth
Wed 19 Nov 2025 17:01:34 INFO  [Epoch 41] Train Loss: 2.106551451079362
Wed 19 Nov 2025 17:03:08 INFO  [Epoch 42] Train Loss: 2.10477315912412
Wed 19 Nov 2025 17:04:45 INFO  [Epoch 43] Train Loss: 2.1030492116925226
Wed 19 Nov 2025 17:06:18 INFO  [Epoch 44] Train Loss: 2.1025655001020107
Wed 19 Nov 2025 17:07:53 INFO  [Epoch 45] Train Loss: 2.1012652318281795
Wed 19 Nov 2025 17:09:32 INFO  [Epoch 46] Train Loss: 2.099064964680359
Wed 19 Nov 2025 17:11:13 INFO  [Epoch 47] Train Loss: 2.0983821945075443
Wed 19 Nov 2025 17:12:46 INFO  [Epoch 48] Train Loss: 2.096527810732763
Wed 19 Nov 2025 17:14:20 INFO  [Epoch 49] Train Loss: 2.0942003092733468
Wed 19 Nov 2025 17:16:00 INFO  [Epoch 50] Train Loss: 2.093412179199483
Wed 19 Nov 2025 17:16:00 INFO  [Epoch 50] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_15-55-442e92/Nov-19-2025_15-55-442e92_50.pth
Wed 19 Nov 2025 17:17:35 INFO  [Epoch 51] Train Loss: 2.091416919599733
Wed 19 Nov 2025 17:19:15 INFO  [Epoch 52] Train Loss: 2.0901309939911243
Wed 19 Nov 2025 17:20:50 INFO  [Epoch 53] Train Loss: 2.0916579565610216
Wed 19 Nov 2025 17:22:19 INFO  [Epoch 54] Train Loss: 2.088414252298437
Wed 19 Nov 2025 17:23:58 INFO  [Epoch 55] Train Loss: 2.0853374479584166
Wed 19 Nov 2025 17:25:39 INFO  [Epoch 56] Train Loss: 2.0849781402898357
Wed 19 Nov 2025 17:27:15 INFO  [Epoch 57] Train Loss: 2.0875635400425696
Wed 19 Nov 2025 17:28:48 INFO  [Epoch 58] Train Loss: 2.082702865704793
Wed 19 Nov 2025 17:30:23 INFO  [Epoch 59] Train Loss: 2.0800679092040704
Wed 19 Nov 2025 17:32:00 INFO  [Epoch 60] Train Loss: 2.07864716911819
Wed 19 Nov 2025 17:32:00 INFO  [Epoch 60] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_15-55-442e92/Nov-19-2025_15-55-442e92_60.pth
Wed 19 Nov 2025 17:32:00 INFO  Best epoch: 0, Best val score: -1
Wed 19 Nov 2025 17:32:00 INFO  [Epoch 61] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_15-55-442e92/Nov-19-2025_15-55-442e92.pth
Wed 19 Nov 2025 17:32:00 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
Wed 19 Nov 2025 18:19:13 INFO  Influence scores: tensor([[0.1901, 0.1851, 0.1732, 0.1481, 0.1640, 0.1333, 0.1337, 0.1206, 0.1235,
         0.1044, 0.1380, 0.1102, 0.0964, 0.1075, 0.0807, 0.0711, 0.0561, 0.0486,
         0.0597, 0.0508, 0.0669, 0.0546, 0.0365, 0.0684, 0.0678],
        [0.1786, 0.2127, 0.1790, 0.1604, 0.1755, 0.1341, 0.1442, 0.1339, 0.1279,
         0.1105, 0.1525, 0.1198, 0.1064, 0.1192, 0.0942, 0.0844, 0.0702, 0.0606,
         0.0719, 0.0610, 0.0761, 0.0643, 0.0410, 0.0771, 0.0747],
        [0.1650, 0.1764, 0.2025, 0.1507, 0.1882, 0.1462, 0.1582, 0.1304, 0.1429,
         0.1239, 0.1628, 0.1254, 0.1127, 0.1273, 0.1007, 0.0896, 0.0749, 0.0703,
         0.0806, 0.0665, 0.0830, 0.0724, 0.0504, 0.0836, 0.0858],
        [0.1750, 0.1928, 0.1850, 0.1806, 0.1796, 0.1473, 0.1563, 0.1434, 0.1406,
         0.1243, 0.1619, 0.1289, 0.1172, 0.1299, 0.1032, 0.0907, 0.0755, 0.0679,
         0.0815, 0.0683, 0.0833, 0.0712, 0.0466, 0.0815, 0.0826],
        [0.1543, 0.1711, 0.1864, 0.1438, 0.2010, 0.1410, 0.1588, 0.1316, 0.1443,
         0.1217, 0.1652, 0.1253, 0.1102, 0.1275, 0.1013, 0.0909, 0.0781, 0.0709,
         0.0791, 0.0673, 0.0838, 0.0729, 0.0499, 0.0841, 0.0818],
        [0.1483, 0.1555, 0.1701, 0.1365, 0.1663, 0.1647, 0.1438, 0.1232, 0.1366,
         0.1272, 0.1551, 0.1335, 0.1210, 0.1316, 0.1037, 0.0890, 0.0739, 0.0702,
         0.0818, 0.0710, 0.0871, 0.0739, 0.0510, 0.0806, 0.0809],
        [0.1468, 0.1627, 0.1785, 0.1427, 0.1815, 0.1414, 0.1727, 0.1376, 0.1503,
         0.1334, 0.1737, 0.1324, 0.1214, 0.1358, 0.1116, 0.1013, 0.0864, 0.0778,
         0.0899, 0.0758, 0.0912, 0.0814, 0.0569, 0.0880, 0.0883],
        [0.1443, 0.1641, 0.1644, 0.1418, 0.1668, 0.1319, 0.1507, 0.1806, 0.1382,
         0.1259, 0.1615, 0.1329, 0.1235, 0.1375, 0.1154, 0.1043, 0.0895, 0.0680,
         0.0824, 0.0792, 0.0861, 0.0760, 0.0524, 0.0824, 0.0782],
        [0.1417, 0.1511, 0.1677, 0.1311, 0.1710, 0.1392, 0.1545, 0.1298, 0.1595,
         0.1329, 0.1679, 0.1333, 0.1195, 0.1341, 0.1103, 0.0983, 0.0838, 0.0773,
         0.0874, 0.0733, 0.0898, 0.0782, 0.0574, 0.0852, 0.0842],
        [0.1310, 0.1435, 0.1590, 0.1255, 0.1591, 0.1389, 0.1478, 0.1279, 0.1423,
         0.1515, 0.1691, 0.1365, 0.1299, 0.1428, 0.1208, 0.1069, 0.0911, 0.0816,
         0.0976, 0.0829, 0.0973, 0.0881, 0.0641, 0.0882, 0.0887],
        [0.1293, 0.1490, 0.1617, 0.1270, 0.1668, 0.1316, 0.1525, 0.1273, 0.1426,
         0.1341, 0.1921, 0.1399, 0.1291, 0.1473, 0.1260, 0.1122, 0.0977, 0.0907,
         0.1035, 0.0875, 0.1026, 0.0905, 0.0639, 0.0945, 0.0938],
        [0.1176, 0.1339, 0.1420, 0.1111, 0.1441, 0.1273, 0.1280, 0.1178, 0.1246,
         0.1191, 0.1567, 0.1629, 0.1415, 0.1486, 0.1217, 0.1057, 0.0895, 0.0852,
         0.0922, 0.0899, 0.1014, 0.0872, 0.0575, 0.0916, 0.0878],
        [0.1162, 0.1325, 0.1415, 0.1114, 0.1417, 0.1273, 0.1293, 0.1199, 0.1228,
         0.1233, 0.1575, 0.1535, 0.1569, 0.1514, 0.1269, 0.1117, 0.0928, 0.0839,
         0.0992, 0.0971, 0.1051, 0.0933, 0.0649, 0.0956, 0.0936],
        [0.1163, 0.1342, 0.1448, 0.1127, 0.1476, 0.1254, 0.1319, 0.1225, 0.1266,
         0.1249, 0.1647, 0.1491, 0.1395, 0.1734, 0.1342, 0.1166, 0.1042, 0.0954,
         0.1067, 0.0999, 0.1100, 0.0981, 0.0676, 0.0991, 0.0986],
        [0.1001, 0.1200, 0.1279, 0.0962, 0.1310, 0.1072, 0.1178, 0.1098, 0.1117,
         0.1121, 0.1521, 0.1315, 0.1247, 0.1428, 0.1527, 0.1327, 0.1163, 0.1002,
         0.1143, 0.1103, 0.1182, 0.1072, 0.0777, 0.1063, 0.1028],
        [0.0940, 0.1132, 0.1200, 0.0873, 0.1235, 0.0964, 0.1109, 0.1031, 0.1036,
         0.1035, 0.1437, 0.1204, 0.1148, 0.1303, 0.1376, 0.1466, 0.1164, 0.0903,
         0.1119, 0.1127, 0.1190, 0.1094, 0.0857, 0.1102, 0.1024],
        [0.0988, 0.1186, 0.1254, 0.0921, 0.1306, 0.1012, 0.1151, 0.1076, 0.1090,
         0.1070, 0.1491, 0.1239, 0.1155, 0.1377, 0.1408, 0.1355, 0.1354, 0.1012,
         0.1137, 0.1138, 0.1204, 0.1123, 0.0870, 0.1144, 0.1042],
        [0.1007, 0.1177, 0.1296, 0.0935, 0.1315, 0.1070, 0.1147, 0.0954, 0.1108,
         0.1063, 0.1503, 0.1271, 0.1140, 0.1366, 0.1324, 0.1183, 0.1098, 0.1334,
         0.1226, 0.1078, 0.1349, 0.1215, 0.0931, 0.1267, 0.1251],
        [0.1020, 0.1191, 0.1301, 0.0972, 0.1310, 0.1081, 0.1178, 0.0990, 0.1107,
         0.1115, 0.1527, 0.1244, 0.1195, 0.1384, 0.1375, 0.1291, 0.1118, 0.1128,
         0.1501, 0.1220, 0.1394, 0.1284, 0.0982, 0.1282, 0.1317],
        [0.0909, 0.1073, 0.1157, 0.0828, 0.1183, 0.0961, 0.1034, 0.0950, 0.0955,
         0.0959, 0.1355, 0.1203, 0.1160, 0.1294, 0.1308, 0.1296, 0.1109, 0.0963,
         0.1210, 0.1430, 0.1439, 0.1323, 0.0990, 0.1329, 0.1218],
        [0.0951, 0.1105, 0.1205, 0.0858, 0.1223, 0.1003, 0.1063, 0.0897, 0.1009,
         0.0986, 0.1393, 0.1201, 0.1117, 0.1282, 0.1274, 0.1241, 0.1061, 0.1130,
         0.1279, 0.1321, 0.1665, 0.1460, 0.1121, 0.1507, 0.1410],
        [0.0928, 0.1080, 0.1191, 0.0843, 0.1206, 0.0973, 0.1058, 0.0896, 0.0993,
         0.0987, 0.1359, 0.1160, 0.1097, 0.1258, 0.1262, 0.1242, 0.1075, 0.1076,
         0.1250, 0.1295, 0.1558, 0.1700, 0.1297, 0.1649, 0.1566],
        [0.0902, 0.1003, 0.1131, 0.0758, 0.1147, 0.0909, 0.0988, 0.0827, 0.0959,
         0.0921, 0.1273, 0.1038, 0.0982, 0.1125, 0.1133, 0.1176, 0.0997, 0.0974,
         0.1120, 0.1126, 0.1375, 0.1461, 0.1543, 0.1589, 0.1519],
        [0.0933, 0.1082, 0.1185, 0.0827, 0.1210, 0.0928, 0.1026, 0.0861, 0.0950,
         0.0886, 0.1301, 0.1094, 0.1012, 0.1165, 0.1147, 0.1146, 0.0986, 0.1022,
         0.1138, 0.1197, 0.1484, 0.1531, 0.1305, 0.1973, 0.1766],
        [0.0948, 0.1074, 0.1217, 0.0848, 0.1206, 0.0948, 0.1043, 0.0831, 0.0954,
         0.0908, 0.1304, 0.1080, 0.1022, 0.1182, 0.1134, 0.1093, 0.0907, 0.1025,
         0.1197, 0.1114, 0.1412, 0.1482, 0.1271, 0.1800, 0.2071]],
       device='cuda:0')
Wed 19 Nov 2025 18:19:13 INFO  Mean influence score: [0.10357856750488281, 0.11320839822292328, 0.11881441622972488, 0.12060744315385818, 0.11769216507673264, 0.11505705863237381, 0.1223740205168724, 0.11912132054567337, 0.11833376437425613, 0.12050054222345352, 0.12373340129852295, 0.11539925634860992, 0.11796867847442627, 0.12176143378019333, 0.11694019287824631, 0.11227689683437347, 0.11641000211238861, 0.11842936277389526, 0.12203168869018555, 0.11453739553689957, 0.11904200911521912, 0.11999429762363434, 0.11191253364086151, 0.11662331968545914, 0.11627774685621262]
Wed 19 Nov 2025 18:19:13 INFO  Stage 0 selected prob: [0.039817363023757935, 0.03994537889957428, 0.040020089596509933, 0.040044017136096954, 0.04000512883067131, 0.03997000306844711, 0.040067609399557114, 0.04002418369054794, 0.04001367837190628, 0.04004259034991264, 0.04008576273918152, 0.03997455909848213, 0.04000881314277649, 0.04005942866206169, 0.03999509662389755, 0.0399329774081707, 0.03998803347349167, 0.04001495987176895, 0.040063031017780304, 0.03996307775378227, 0.04002312943339348, 0.04003584012389183, 0.0399281270802021, 0.039990875869989395, 0.0399862676858902]
Wed 19 Nov 2025 18:20:53 INFO  [Epoch 61] Train Loss: 2.077818961995117
Wed 19 Nov 2025 18:22:27 INFO  [Epoch 62] Train Loss: 2.0772116726830028
Wed 19 Nov 2025 18:24:04 INFO  [Epoch 63] Train Loss: 2.073660905233612
Wed 19 Nov 2025 18:25:37 INFO  [Epoch 64] Train Loss: 2.0744088376116374
Wed 19 Nov 2025 18:27:12 INFO  [Epoch 65] Train Loss: 2.072435737554526
Wed 19 Nov 2025 18:28:53 INFO  [Epoch 66] Train Loss: 2.0704495477424856
Wed 19 Nov 2025 18:30:34 INFO  [Epoch 67] Train Loss: 2.0696622668663722
Wed 19 Nov 2025 18:32:05 INFO  [Epoch 68] Train Loss: 2.0683161686844813
Wed 19 Nov 2025 18:33:39 INFO  [Epoch 69] Train Loss: 2.0654611592016097
Wed 19 Nov 2025 18:35:20 INFO  [Epoch 70] Train Loss: 2.0639447147179655
Wed 19 Nov 2025 18:35:20 INFO  [Epoch 70] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_15-55-442e92/Nov-19-2025_15-55-442e92_70.pth
Wed 19 Nov 2025 18:36:54 INFO  [Epoch 71] Train Loss: 2.0623277129314856
Wed 19 Nov 2025 18:38:35 INFO  [Epoch 72] Train Loss: 2.065061035601825
Wed 19 Nov 2025 18:40:11 INFO  [Epoch 73] Train Loss: 2.059037137588524
Wed 19 Nov 2025 18:41:42 INFO  [Epoch 74] Train Loss: 2.059102078263887
Wed 19 Nov 2025 18:43:22 INFO  [Epoch 75] Train Loss: 2.0567250523067724
Wed 19 Nov 2025 18:45:03 INFO  [Epoch 76] Train Loss: 2.056205309596202
Wed 19 Nov 2025 18:46:38 INFO  [Epoch 77] Train Loss: 2.0537116960555695
Wed 19 Nov 2025 18:48:11 INFO  [Epoch 78] Train Loss: 2.0525737536429642
Wed 19 Nov 2025 18:49:47 INFO  [Epoch 79] Train Loss: 2.050581613517652
Wed 19 Nov 2025 18:51:23 INFO  [Epoch 80] Train Loss: 2.0497545612064987
Wed 19 Nov 2025 18:51:23 INFO  [Epoch 80] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_15-55-442e92/Nov-19-2025_15-55-442e92_80.pth
Wed 19 Nov 2025 18:51:23 INFO  Best epoch: 0, Best val score: -1
Wed 19 Nov 2025 18:51:23 INFO  [Epoch 81] Saved model checkpoint to ckpt/Musical_Instruments/Nov-19-2025_15-55-442e92/Nov-19-2025_15-55-442e92.pth
Wed 19 Nov 2025 18:51:23 INFO  Validation scores for all tokenizers: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
